[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Building regression models to predict dissolved inorganic carbon in water samples\n\n\n\n\n\n\n\nMachine Learning\n\n\nPython\n\n\n\n\nFor this blog post, I build and compare four regression models that predict dissolved inorganic carbon (DIC) in water samples. I also analyze feature importances in the best performing model.\n\n\n\n\n\n\nApr 3, 2024\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nUsing deep learning to predict dissolved inorganic carbon (DIC) in water samples\n\n\n\n\n\n\n\nMachine Learning\n\n\nPython\n\n\n\n\nMy streneuous journey to build a deep learning model…\n\n\n\n\n\n\nApr 2, 2024\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nClustering analysis of biological contaminating algae based on metal content\n\n\n\n\n\n\n\nMachine Learning\n\n\nR\n\n\n\n\nTo practice clustering analysis, I’ll use data from Roberts et al. 2008 on biological contaminants in Port Jackson Bay (located in Sydney, Australia). The data are measurements of metal content (Cd, Cr, Cu, Mn, and Ni) in two types of co-occurring algae at 10 sample sites around the bay.\n\n\n\n\n\n\nMar 29, 2024\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nBuilding predictive user classification models with data from Spotify Web API\n\n\n\n\n\n\n\nMachine Learning\n\n\nR\n\n\n\n\nIn this blog post, I build predictive models using a single decision tree, bagged decision trees, a random forest, and Stochastic Gradient Boosting (SGB) for predicting whether a given song was in my Spotify collection or that of my friend Maxwell. Then, I compare the performance of these four models.\n\n\n\n\n\n\nMar 29, 2024\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nCreating an infographic on anthropogenic methane emissions in 2021\n\n\n\n\n\n\n\nData Visualization\n\n\nMethane\n\n\nR\n\n\n\n\nThis blog post explains the process of creating an infographic on anthropogenic methane emissions in 2021, with a particular focus on the data visualization considerations and choices made.\n\n\n\n\n\n\nMar 12, 2024\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nUsing propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy\n\n\n\n\n\n\n\nPolicy Analysis\n\n\nCausal Inference\n\n\nR\n\n\n\n\nDisclaimer: The data used in this blog was synthetically generated for an assignment in my Master’s program class on Environmental Policy Evaluation (i.e., data is fake so results have no real implications).\n\n\n\n\n\n\nMar 11, 2024\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nUsing the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program\n\n\n\n\n\n\n\nPolicy Analysis\n\n\nCausal Inference\n\n\nR\n\n\n\n\nFor this analysis, I estimate the Average Treatment Effect (ATE) of the 1998 Prospera cash-transfer program on the value of animals owned by a household.\n\n\n\n\n\n\nMar 6, 2024\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\n2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions\n\n\n\n\n\n\n\nStatistical Modeling\n\n\nR\n\n\n\n\nThis analysis seeks to better understand the seasonality and trends of nitrogen and phosphorus concentration in Chesapeake Bay tidal regions since the 2010 introduction of federal water quality requirements under the Clean Water Act.\n\n\n\n\n\n\nDec 12, 2023\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nVisualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona\n\n\n\n\n\n\n\nGeospatial Analysis\n\n\nPython\n\n\n\n\nIn this analysis, I retrieve raster data of Biodiversity Intactness Index (BII) from the Microsoft Planetary Computer (MPC) catalog. This allows me to calculate areas of interest based on changes in biodiversity and show my results on a map.\n\n\n\n\n\n\nDec 11, 2023\n\n\nLinus Ghanadan\n\n\n\n\n\n\n  \n\n\n\n\nLand cover analysis around Mount Whitney\n\n\n\n\n\n\n\nGeospatial Analysis\n\n\nPython\n\n\n\n\nThis analysis uses Python to extract land cover statistics from a USGS raster dataset on land cover classification in the area surrounding Mount Whitney in California.\n\n\n\n\n\n\nDec 11, 2023\n\n\nLinus Ghanadan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Linus Ghanadan",
    "section": "",
    "text": "Bio\nI’m currently pursuing a Master’s degree in Environmental Data Science from the Bren School of Environmental Science & Management at UC Santa Barbara. I finished my undergraduate studies in 2023, receiving a Bachelor of Science in Environmental Economics from the University of Maryland. While at UMD, I also gained experience working on policies affecting offshore wind energy supply chains at the U.S. Department of Transportation, analyzing transport electrification policies at the World Resources Institute, and researching nature-based carbon sequestration at The Nature Conservancy. Moving forward, my career goal is to implement data-driven solutions that advance sustainability within the public and private sectors."
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html",
    "href": "blog/2023-10-23-my-first-post/index.html",
    "title": "My first blog post",
    "section": "",
    "text": "Interesting insights here.1\nI want to cite something here (Csik 2022).\nI’m citing another resources here(Liu et al. 2023)."
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#first-section",
    "href": "blog/2023-10-23-my-first-post/index.html#first-section",
    "title": "My first blog post",
    "section": "",
    "text": "Interesting insights here.1\nI want to cite something here (Csik 2022).\nI’m citing another resources here(Liu et al. 2023)."
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#second-section",
    "href": "blog/2023-10-23-my-first-post/index.html#second-section",
    "title": "My first blog post",
    "section": "Second section",
    "text": "Second section\nIn conclusion, this is a blog.2"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#footnotes",
    "href": "blog/2023-10-23-my-first-post/index.html#footnotes",
    "title": "My first blog post",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a footnote↩︎\nThis is another footnote↩︎"
  },
  {
    "objectID": "STAC-search.html",
    "href": "STAC-search.html",
    "title": "Access",
    "section": "",
    "text": "import numpy as np\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\n\nfrom shapely.geometry import Polygon\n\n# used to access STAC catalogs\nfrom pystac_client import Client\n# used to sign items from the MPC STAC catalog\nimport planetary_computer\n\n# other libraries for nice outputs\nfrom IPython.display import Image\nWe use the Client function from the pystac_client package to access the catalog:\n# access catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier = planetary_computer.sign_inplace)\nThe modifier parameter is needed to access the data in the MPC catalog."
  },
  {
    "objectID": "STAC-search.html#exploration",
    "href": "STAC-search.html#exploration",
    "title": "Access",
    "section": "Exploration",
    "text": "Exploration\nLet’s check out some of the catalog’s metadata:\n\n# metadata from the catalog\nprint('Title: ', catalog.title)\nprint('Description: ', catalog.description)\n\nTitle:  Microsoft Planetary Computer STAC API\nDescription:  Searchable spatiotemporal metadata describing Earth science datasets hosted by the Microsoft Planetary Computer\n\n\nWe can access the catalog’s collections by using the get_collections() method:\n\ncatalog.get_collections()\n\n&lt;generator object Client.get_collections at 0x16765edf0&gt;\n\n\nNotice the output of get_collections() is a generator.\nThis is a special kind of lazy obkect in Python over which you can loop over like a list. Unlike a list, the items in the generator do not exist in memory until you explicitely iterate over them or convert them to a list. Let’s try getting the collections from the catalog again:\n\n# get collections and print their names\ncollections = list(catalog.get_collections())\n\nprint('Number of collections: ', len(collections))\nprint('Collections IDs:')\n\nfor collection in collections:\n    print('- ', collection.id)\n\nNumber of collections:  122\nCollections IDs:\n-  daymet-annual-pr\n-  daymet-daily-hi\n-  3dep-seamless\n-  3dep-lidar-dsm\n-  fia\n-  sentinel-1-rtc\n-  gridmet\n-  daymet-annual-na\n-  daymet-monthly-na\n-  daymet-annual-hi\n-  daymet-monthly-hi\n-  daymet-monthly-pr\n-  gnatsgo-tables\n-  hgb\n-  cop-dem-glo-30\n-  cop-dem-glo-90\n-  goes-cmi\n-  terraclimate\n-  nasa-nex-gddp-cmip6\n-  gpm-imerg-hhr\n-  gnatsgo-rasters\n-  3dep-lidar-hag\n-  3dep-lidar-intensity\n-  3dep-lidar-pointsourceid\n-  mtbs\n-  noaa-c-cap\n-  3dep-lidar-copc\n-  modis-64A1-061\n-  alos-fnf-mosaic\n-  3dep-lidar-returns\n-  mobi\n-  landsat-c2-l2\n-  era5-pds\n-  chloris-biomass\n-  kaza-hydroforecast\n-  planet-nicfi-analytic\n-  modis-17A2H-061\n-  modis-11A2-061\n-  daymet-daily-pr\n-  3dep-lidar-dtm-native\n-  3dep-lidar-classification\n-  3dep-lidar-dtm\n-  gap\n-  modis-17A2HGF-061\n-  planet-nicfi-visual\n-  gbif\n-  modis-17A3HGF-061\n-  modis-09A1-061\n-  alos-dem\n-  alos-palsar-mosaic\n-  deltares-water-availability\n-  modis-16A3GF-061\n-  modis-21A2-061\n-  us-census\n-  jrc-gsw\n-  deltares-floods\n-  modis-43A4-061\n-  modis-09Q1-061\n-  modis-14A1-061\n-  hrea\n-  modis-13Q1-061\n-  modis-14A2-061\n-  sentinel-2-l2a\n-  modis-15A2H-061\n-  modis-11A1-061\n-  modis-15A3H-061\n-  modis-13A1-061\n-  daymet-daily-na\n-  nrcan-landcover\n-  modis-10A2-061\n-  ecmwf-forecast\n-  noaa-mrms-qpe-24h-pass2\n-  sentinel-1-grd\n-  nasadem\n-  io-lulc\n-  landsat-c2-l1\n-  drcog-lulc\n-  chesapeake-lc-7\n-  chesapeake-lc-13\n-  chesapeake-lu\n-  noaa-mrms-qpe-1h-pass1\n-  noaa-mrms-qpe-1h-pass2\n-  noaa-nclimgrid-monthly\n-  goes-glm\n-  usda-cdl\n-  eclipse\n-  esa-cci-lc\n-  esa-cci-lc-netcdf\n-  fws-nwi\n-  usgs-lcmap-conus-v13\n-  usgs-lcmap-hawaii-v10\n-  noaa-climate-normals-tabular\n-  noaa-climate-normals-netcdf\n-  noaa-climate-normals-gridded\n-  aster-l1t\n-  cil-gdpcir-cc-by-sa\n-  io-lulc-9-class\n-  io-biodiversity\n-  naip\n-  noaa-cdr-sea-surface-temperature-whoi\n-  noaa-cdr-ocean-heat-content\n-  cil-gdpcir-cc0\n-  cil-gdpcir-cc-by\n-  noaa-cdr-sea-surface-temperature-whoi-netcdf\n-  noaa-cdr-sea-surface-temperature-optimum-interpolation\n-  modis-10A1-061\n-  sentinel-5p-l2-netcdf\n-  sentinel-3-olci-wfr-l2-netcdf\n-  noaa-cdr-ocean-heat-content-netcdf\n-  sentinel-3-synergy-aod-l2-netcdf\n-  sentinel-3-synergy-v10-l2-netcdf\n-  sentinel-3-olci-lfr-l2-netcdf\n-  sentinel-3-sral-lan-l2-netcdf\n-  sentinel-3-slstr-lst-l2-netcdf\n-  sentinel-3-slstr-wst-l2-netcdf\n-  sentinel-3-sral-wat-l2-netcdf\n-  ms-buildings\n-  sentinel-3-slstr-frp-l2-netcdf\n-  sentinel-3-synergy-syn-l2-netcdf\n-  sentinel-3-synergy-vgp-l2-netcdf\n-  sentinel-3-synergy-vg1-l2-netcdf\n-  esa-worldcover"
  },
  {
    "objectID": "STAC-search.html#collection",
    "href": "STAC-search.html#collection",
    "title": "Access",
    "section": "Collection",
    "text": "Collection\nWe can select a single collection for exploration using the get_child() method for the catalog and the collection id as the parameter:\n\nnaip_collection = catalog.get_child('naip')\nnaip_collection\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR).  NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA).  Data are captured at least once every three years for each state.  This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\"\n        \n    \n                \n            \n                \n                    \n        \n            links\n            [] 6 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"license\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://www.fsa.usda.gov/help/policies-and-links/\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Public Domain\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"describedby\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/dataset/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Human readable dataset overview and reference\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/item-assets/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/table/v1.2.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            item_assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            msft:region\n            \"westeurope\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:container\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:storage_account\n            \"naipeuwest\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:short_description\n            \"NAIP provides US-wide, high-resolution aerial imagery.  This dataset includes NAIP images from 2010 to the present.\"\n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"NAIP: National Agriculture Imagery Program\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        \n            bbox\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -124.784\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            24.744\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -66.951\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            49.346\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        \n            interval\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"2010-01-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"2021-12-31T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"proprietary\"\n        \n    \n                \n            \n                \n                    \n        \n            keywords\n            [] 7 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"NAIP\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"Aerial\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"Imagery\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"USDA\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"AFPO\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"Agriculture\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"United States\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            providers\n            [] 3 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"USDA Farm Service Agency\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"producer\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Esri\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.esri.com/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Microsoft\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"host\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://planetarycomputer.microsoft.com\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            summaries\n            \n        \n            \n                \n        \n            gsd\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_thumbnails/naip.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"NAIP thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geoparquet-items\n            \n        \n            \n                \n        \n            href\n            \"abfs://items/naip.parquet\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/x-parquet\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"GeoParquet STAC items\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Snapshot of the collection's STAC items exported to GeoParquet format.\"\n        \n    \n            \n        \n            \n                \n        \n            msft:partition_info\n            \n        \n            \n                \n        \n            is_partitioned\n            True\n        \n    \n            \n        \n            \n                \n        \n            partition_frequency\n            \"AS\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            table:storage_options\n            \n        \n            \n                \n        \n            account_name\n            \"pcstacitems\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"stac-items\""
  },
  {
    "objectID": "STAC-search.html#catalog-search",
    "href": "STAC-search.html#catalog-search",
    "title": "Access",
    "section": "Catalog search",
    "text": "Catalog search\nWe can narrow the search within the catalog by specifying a time range, an area of interest, and the collection name. The simplest way to define the are of interest to look for in the catalog are:\n\na GeoJSON-type dictionary with coordinates of the bounding box\nas a list [xmin, ymin, xmax, ymax] with the coordinate values definind the four corners of the bounding box.\n\nYou could also use a point, or some more complex polygon.\nIn this lesson we will look for NAIP scenes over Santa Barbara from 2018 to 2020. We’ll use the GeoJSON method: to define the area of interest:\n\n# temporal range of interest\n# CHECK: how to get open/close time ranges\ntime_range = \"2018-01-01/2023-01-01\"\n\n# NCEAS bounding box (as a GeoJSON)\n# NCEAS bounding box (as a GeoJSON)\nbbox = {\n    \"type\": \"Polygon\",\n    \"coordinates\":[\n        [\n            [-119.70608227128903, 34.426300194372274],\n            [-119.70608227128903, 34.42041139020533],\n            [-119.6967885126002, 34.42041139020533],\n            [-119.6967885126002, 34.426300194372274],\n            [-119.70608227128903, 34.426300194372274]\n        ]\n    ]\n}\n\n# catalog search\nsearch = catalog.search(\n    collections = ['naip'], # list with collection id\n    intersects = bbox,\n    datetime=time_range\n) \nsearch\n\n&lt;pystac_client.item_search.ItemSearch at 0x1680d6810&gt;\n\n\nTo get the items found in the search (or check if there were any matches in the search) we use the item_collection() method:\n\nitems = search.item_collection()\n\n# number of items in search\nlen(items)\n\n2\n\n\n\nitems\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        \n            features\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            gsd\n            0.6\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            \"2020-05-21T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            naip:year\n            \"2020\"\n        \n    \n            \n        \n            \n                \n        \n            proj:bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3806808.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            253260.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            3814296.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            26911\n        \n    \n            \n        \n            \n                \n        \n            naip:state\n            \"ca\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            12480\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10550\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            3814296.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.685448\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.439192\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.752061\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"naip\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            gsd\n            0.6\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            \"2018-07-24T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            naip:year\n            \"2018\"\n        \n    \n            \n        \n            \n                \n        \n            proj:bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            246978.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3806856.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            253212.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            3814248.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            26911\n        \n    \n            \n        \n            \n                \n        \n            naip:state\n            \"ca\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            12320\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10390\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            246978.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            3814248.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.37369\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.685956\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.44028\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.753736\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.438772\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.751554\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.372185\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.37369\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.tif?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_fgdc_2018/34119/m_3411935_sw_11_060_20180724.txt?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.200.jpg?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.753736\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.372185\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            34.44028\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"naip\""
  },
  {
    "objectID": "STAC-search.html#item",
    "href": "STAC-search.html#item",
    "title": "Access",
    "section": "Item",
    "text": "Item\nLet’s get the first item in the search\n\n# get first item in the catalog search\nitem = items[0]\ntype(item)\n\npystac.item.Item\n\n\nRemember the STAC item is the core object in the catalog.\nThe item does not contain the data itslef, but rather metadata about it and links to access the actual data (assets). Some of the metadta:\n\nprint('id', item.id)\nitem.properties\n\nid ca_m_3411935_sw_11_060_20200521\n\n\n{'gsd': 0.6,\n 'datetime': '2020-05-21T00:00:00Z',\n 'naip:year': '2020',\n 'proj:bbox': [246930.0, 3806808.0, 253260.0, 3814296.0],\n 'proj:epsg': 26911,\n 'naip:state': 'ca',\n 'proj:shape': [12480, 10550],\n 'proj:transform': [0.6, 0.0, 246930.0, 0.0, -0.6, 3814296.0, 0.0, 0.0, 1.0]}\n\n\nJust as the item properties, the item assets are given in a dictionary, with each vlaue being a pystac.asset. Let’s check the assets in the item:\n\nitem.assets\n\n{'image': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D&gt;,\n 'thumbnail': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;}\n\n\n\nfor key in item.assets.keys():\n    print(key, '--', item.assets[key].title)\n\nimage -- RGBIR COG tile\nthumbnail -- Thumbnail\ntilejson -- TileJSON with default rendering\nrendered_preview -- Rendered preview\n\n\nNotice each asset has an href, which is a link to the asset object (i.e. the data). For example, we can use the URL for the rendered preview asset to plot it:\n\nImage(url=item.assets['rendered_preview'].href, width=500)"
  },
  {
    "objectID": "STAC-search.html#load-data",
    "href": "STAC-search.html#load-data",
    "title": "Access",
    "section": "Load data",
    "text": "Load data\nThe raster data in our current item is in the image asset. Again, we access this data via its URL. This time we open it using rioxr.open_rasterio() directly:\n\nsb = rioxr.open_rasterio(item.assets['image'].href)\nsb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 4, y: 12480, x: 10550)&gt;\n[526656000 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3 4\n  * x            (x) float64 2.469e+05 2.469e+05 ... 2.533e+05 2.533e+05\n  * y            (y) float64 3.814e+06 3.814e+06 ... 3.807e+06 3.807e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:             Area\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    _FillValue:                0\n    scale_factor:              1.0\n    add_offset:                0.0xarray.DataArrayband: 4y: 12480x: 10550...[526656000 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3 4array([1, 2, 3, 4])x(x)float642.469e+05 2.469e+05 ... 2.533e+05array([246930.3, 246930.9, 246931.5, ..., 253258.5, 253259.1, 253259.7])y(y)float643.814e+06 3.814e+06 ... 3.807e+06array([3814295.7, 3814295.1, 3814294.5, ..., 3806809.5, 3806808.9, 3806808.3])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :246930.0 0.6 0.0 3814296.0 0.0 -0.6array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3, 4], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          246930.3,           246930.9,           246931.5,\n       246932.09999999998, 246932.69999999998,           246933.3,\n                 246933.9,           246934.5, 246935.09999999998,\n       246935.69999999998,\n       ...\n                 253254.3,           253254.9,           253255.5,\n       253256.09999999998, 253256.69999999998,           253257.3,\n                 253257.9,           253258.5, 253259.09999999998,\n       253259.69999999998],\n      dtype='float64', name='x', length=10550))yPandasIndexPandasIndex(Index([         3814295.7,          3814295.1,          3814294.5,\n       3814293.9000000004, 3814293.3000000003,          3814292.7,\n                3814292.1,          3814291.5, 3814290.9000000004,\n       3814290.3000000003,\n       ...\n                3806813.7,          3806813.1,          3806812.5,\n       3806811.9000000004, 3806811.3000000003,          3806810.7,\n                3806810.1,          3806809.5, 3806808.9000000004,\n       3806808.3000000003],\n      dtype='float64', name='y', length=12480))Attributes: (9)AREA_OR_POINT :AreaTIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1_FillValue :0scale_factor :1.0add_offset :0.0\n\n\n\n# plot raster with correct ratio\nsize = 6 # height in in of plot\naspect = sb.rio.width/sb.rio.height\nsb.sel(band=[1,2,3]).plot.imshow(size=size)#, aspect=aspect)\n\n&lt;matplotlib.image.AxesImage at 0x16784e250&gt;"
  },
  {
    "objectID": "STAC-search.html#exercise",
    "href": "STAC-search.html#exercise",
    "title": "Access",
    "section": "Exercise",
    "text": "Exercise\nThe ‘cop-dem-glo-90’ (id of collection) collection contains the Copernicus DEM at 90m resolution (the one we used for Grand Canyon).\n\nUse the bbox for Santa Barbara to look for items in this collection/\nGet the first item in the search and check its assets.\nPlot the item’s rendered preview asset\nOpen the item’s data using rioxarray.\n\n\n# catalog search\n\nsearch = catalog.search(\ncollections = ['cop-dem-glo-90'],\nintersects = bbox)\n\nsearch\n\n&lt;pystac_client.item_search.ItemSearch at 0x1677d43d0&gt;\n\n\n\nsb_items = search.item_collection()\n\n# number of items in search \nlen(sb_items)\n\n1\n\n\n\n# first item in catalog\nsb_item = sb_items[0]\ntype(sb_item)\n\npystac.item.Item\n\n\n\nsb_item.assets\n\n{'data': &lt;Asset href=https://elevationeuwest.blob.core.windows.net/copernicus-dem/COP90_hh/Copernicus_DSM_COG_30_N34_00_W120_00_DEM.tif?st=2023-11-28T05%3A50%3A18Z&se=2023-11-29T06%3A35%3A18Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-29T00%3A21%3A36Z&ske=2023-12-06T00%3A21%3A36Z&sks=b&skv=2021-06-08&sig=8YM0NGC%2BhTB%2BFH2E4fCofKTZsCNnhaSAl1aCpgaQNuk%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=cop-dem-glo-90&item=Copernicus_DSM_COG_30_N34_00_W120_00_DEM&assets=data&colormap_name=terrain&rescale=-1000%2C4000&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=cop-dem-glo-90&item=Copernicus_DSM_COG_30_N34_00_W120_00_DEM&assets=data&colormap_name=terrain&rescale=-1000%2C4000&format=png&gt;}\n\n\n\nImage(url=sb_item.assets['rendered_preview'].href, width=500)\n\n\n\n\n\ndem = rioxr.open_rasterio(sb_item.assets['data'].href)\ndem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 1200, x: 1200)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * band         (band) int64 1\n  * x            (x) float64 -120.0 -120.0 -120.0 ... -119.0 -119.0 -119.0\n  * y            (y) float64 35.0 35.0 35.0 35.0 35.0 ... 34.0 34.0 34.0 34.0\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Point\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 1y: 1200x: 1200...[1440000 values with dtype=float32]Coordinates: (4)band(band)int641array([1])x(x)float64-120.0 -120.0 ... -119.0 -119.0array([-120.      , -119.999167, -119.998333, ..., -119.0025  , -119.001667,\n       -119.000833])y(y)float6435.0 35.0 35.0 ... 34.0 34.0 34.0array([35.      , 34.999167, 34.998333, ..., 34.0025  , 34.001667, 34.000833])spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-120.00041666666667 0.0008333333333333334 0.0 35.000416666666666 0.0 -0.0008333333333333334array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([             -120.0, -119.99916666666667, -119.99833333333333,\n                 -119.9975, -119.99666666666667, -119.99583333333334,\n                  -119.995, -119.99416666666667, -119.99333333333334,\n                 -119.9925,\n       ...\n       -119.00833333333334,           -119.0075, -119.00666666666666,\n       -119.00583333333333,            -119.005, -119.00416666666666,\n       -119.00333333333333,           -119.0025, -119.00166666666667,\n       -119.00083333333333],\n      dtype='float64', name='x', length=1200))yPandasIndexPandasIndex(Index([              35.0,  34.99916666666667, 34.998333333333335,\n                  34.9975,  34.99666666666667,  34.99583333333333,\n                   34.995, 34.994166666666665,  34.99333333333333,\n                  34.9925,\n       ...\n        34.00833333333333,            34.0075,  34.00666666666667,\n       34.005833333333335,             34.005,  34.00416666666667,\n        34.00333333333333,            34.0025, 34.001666666666665,\n        34.00083333333333],\n      dtype='float64', name='y', length=1200))Attributes: (3)AREA_OR_POINT :Pointscale_factor :1.0add_offset :0.0"
  },
  {
    "objectID": "blog/STAC-search.html",
    "href": "blog/STAC-search.html",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "Code\n# General libraries and functions\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\n# Geospatial libraries and functions\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nfrom shapely.geometry import box\nfrom shapely.geometry import Point"
  },
  {
    "objectID": "blog/STAC-search.html#exploration",
    "href": "blog/STAC-search.html#exploration",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Exploration",
    "text": "Exploration\nLet’s check out some of the catalog’s metadata:\n\n\nCode\n# metadata from the catalog\nprint('Title: ', catalog.title)\nprint('Description: ', catalog.description)\n\n\nTitle:  Microsoft Planetary Computer STAC API\nDescription:  Searchable spatiotemporal metadata describing Earth science datasets hosted by the Microsoft Planetary Computer\n\n\nWe can access the catalog’s collections by using the get_collections() method:\n\n\nCode\ncatalog.get_collections()\n\n\n&lt;generator object Client.get_collections at 0x16765edf0&gt;\n\n\nNotice the output of get_collections() is a generator.\nThis is a special kind of lazy obkect in Python over which you can loop over like a list. Unlike a list, the items in the generator do not exist in memory until you explicitely iterate over them or convert them to a list. Let’s try getting the collections from the catalog again:\n\n\nCode\n# get collections and print their names\ncollections = list(catalog.get_collections())\n\nprint('Number of collections: ', len(collections))\nprint('Collections IDs:')\n\nfor collection in collections:\n    print('- ', collection.id)\n\n\nNumber of collections:  122\nCollections IDs:\n-  daymet-annual-pr\n-  daymet-daily-hi\n-  3dep-seamless\n-  3dep-lidar-dsm\n-  fia\n-  sentinel-1-rtc\n-  gridmet\n-  daymet-annual-na\n-  daymet-monthly-na\n-  daymet-annual-hi\n-  daymet-monthly-hi\n-  daymet-monthly-pr\n-  gnatsgo-tables\n-  hgb\n-  cop-dem-glo-30\n-  cop-dem-glo-90\n-  goes-cmi\n-  terraclimate\n-  nasa-nex-gddp-cmip6\n-  gpm-imerg-hhr\n-  gnatsgo-rasters\n-  3dep-lidar-hag\n-  3dep-lidar-intensity\n-  3dep-lidar-pointsourceid\n-  mtbs\n-  noaa-c-cap\n-  3dep-lidar-copc\n-  modis-64A1-061\n-  alos-fnf-mosaic\n-  3dep-lidar-returns\n-  mobi\n-  landsat-c2-l2\n-  era5-pds\n-  chloris-biomass\n-  kaza-hydroforecast\n-  planet-nicfi-analytic\n-  modis-17A2H-061\n-  modis-11A2-061\n-  daymet-daily-pr\n-  3dep-lidar-dtm-native\n-  3dep-lidar-classification\n-  3dep-lidar-dtm\n-  gap\n-  modis-17A2HGF-061\n-  planet-nicfi-visual\n-  gbif\n-  modis-17A3HGF-061\n-  modis-09A1-061\n-  alos-dem\n-  alos-palsar-mosaic\n-  deltares-water-availability\n-  modis-16A3GF-061\n-  modis-21A2-061\n-  us-census\n-  jrc-gsw\n-  deltares-floods\n-  modis-43A4-061\n-  modis-09Q1-061\n-  modis-14A1-061\n-  hrea\n-  modis-13Q1-061\n-  modis-14A2-061\n-  sentinel-2-l2a\n-  modis-15A2H-061\n-  modis-11A1-061\n-  modis-15A3H-061\n-  modis-13A1-061\n-  daymet-daily-na\n-  nrcan-landcover\n-  modis-10A2-061\n-  ecmwf-forecast\n-  noaa-mrms-qpe-24h-pass2\n-  sentinel-1-grd\n-  nasadem\n-  io-lulc\n-  landsat-c2-l1\n-  drcog-lulc\n-  chesapeake-lc-7\n-  chesapeake-lc-13\n-  chesapeake-lu\n-  noaa-mrms-qpe-1h-pass1\n-  noaa-mrms-qpe-1h-pass2\n-  noaa-nclimgrid-monthly\n-  goes-glm\n-  usda-cdl\n-  eclipse\n-  esa-cci-lc\n-  esa-cci-lc-netcdf\n-  fws-nwi\n-  usgs-lcmap-conus-v13\n-  usgs-lcmap-hawaii-v10\n-  noaa-climate-normals-tabular\n-  noaa-climate-normals-netcdf\n-  noaa-climate-normals-gridded\n-  aster-l1t\n-  cil-gdpcir-cc-by-sa\n-  io-lulc-9-class\n-  io-biodiversity\n-  naip\n-  noaa-cdr-sea-surface-temperature-whoi\n-  noaa-cdr-ocean-heat-content\n-  cil-gdpcir-cc0\n-  cil-gdpcir-cc-by\n-  noaa-cdr-sea-surface-temperature-whoi-netcdf\n-  noaa-cdr-sea-surface-temperature-optimum-interpolation\n-  modis-10A1-061\n-  sentinel-5p-l2-netcdf\n-  sentinel-3-olci-wfr-l2-netcdf\n-  noaa-cdr-ocean-heat-content-netcdf\n-  sentinel-3-synergy-aod-l2-netcdf\n-  sentinel-3-synergy-v10-l2-netcdf\n-  sentinel-3-olci-lfr-l2-netcdf\n-  sentinel-3-sral-lan-l2-netcdf\n-  sentinel-3-slstr-lst-l2-netcdf\n-  sentinel-3-slstr-wst-l2-netcdf\n-  sentinel-3-sral-wat-l2-netcdf\n-  ms-buildings\n-  sentinel-3-slstr-frp-l2-netcdf\n-  sentinel-3-synergy-syn-l2-netcdf\n-  sentinel-3-synergy-vgp-l2-netcdf\n-  sentinel-3-synergy-vg1-l2-netcdf\n-  esa-worldcover"
  },
  {
    "objectID": "blog/STAC-search.html#collection",
    "href": "blog/STAC-search.html#collection",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Collection",
    "text": "Collection\nWe can select a single collection for exploration using the get_child() method for the catalog and the collection id as the parameter:\n\n\nCode\nnaip_collection = catalog.get_child('naip')\nnaip_collection\n\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR).  NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA).  Data are captured at least once every three years for each state.  This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\"\n        \n    \n                \n            \n                \n                    \n        \n            links\n            [] 6 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"license\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://www.fsa.usda.gov/help/policies-and-links/\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Public Domain\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"describedby\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/dataset/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Human readable dataset overview and reference\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/item-assets/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/table/v1.2.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            item_assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            msft:region\n            \"westeurope\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:container\n            \"naip\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:storage_account\n            \"naipeuwest\"\n        \n    \n                \n            \n                \n                    \n        \n            msft:short_description\n            \"NAIP provides US-wide, high-resolution aerial imagery.  This dataset includes NAIP images from 2010 to the present.\"\n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"NAIP: National Agriculture Imagery Program\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        \n            bbox\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -124.784\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            24.744\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -66.951\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            49.346\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        \n            interval\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"2010-01-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"2021-12-31T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"proprietary\"\n        \n    \n                \n            \n                \n                    \n        \n            keywords\n            [] 7 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"NAIP\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"Aerial\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"Imagery\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"USDA\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"AFPO\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"Agriculture\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"United States\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            providers\n            [] 3 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"USDA Farm Service Agency\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"producer\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Esri\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.esri.com/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Microsoft\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"host\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"processor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://planetarycomputer.microsoft.com\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            summaries\n            \n        \n            \n                \n        \n            gsd\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"visible blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_thumbnails/naip.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"NAIP thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geoparquet-items\n            \n        \n            \n                \n        \n            href\n            \"abfs://items/naip.parquet\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/x-parquet\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"GeoParquet STAC items\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Snapshot of the collection's STAC items exported to GeoParquet format.\"\n        \n    \n            \n        \n            \n                \n        \n            msft:partition_info\n            \n        \n            \n                \n        \n            is_partitioned\n            True\n        \n    \n            \n        \n            \n                \n        \n            partition_frequency\n            \"AS\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            table:storage_options\n            \n        \n            \n                \n        \n            account_name\n            \"pcstacitems\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"stac-items\""
  },
  {
    "objectID": "blog/STAC-search.html#catalog-search",
    "href": "blog/STAC-search.html#catalog-search",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Catalog search",
    "text": "Catalog search\nWe can narrow the search within the catalog by specifying a time range, an area of interest, and the collection name. The simplest way to define the are of interest to look for in the catalog are:\n\na GeoJSON-type dictionary with coordinates of the bounding box\nas a list [xmin, ymin, xmax, ymax] with the coordinate values definind the four corners of the bounding box.\n\nYou could also use a point, or some more complex polygon.\nIn this lesson we will look for NAIP scenes over Santa Barbara from 2018 to 2020. We’ll use the GeoJSON method: to define the area of interest:\n\n\nCode\n# temporal range of interest\n# CHECK: how to get open/close time ranges\ntime_range = \"2018-01-01/2023-01-01\"\n\n# NCEAS bounding box (as a GeoJSON)\n# NCEAS bounding box (as a GeoJSON)\nbbox = {\n    \"type\": \"Polygon\",\n    \"coordinates\":[\n        [\n            [-119.70608227128903, 34.426300194372274],\n            [-119.70608227128903, 34.42041139020533],\n            [-119.6967885126002, 34.42041139020533],\n            [-119.6967885126002, 34.426300194372274],\n            [-119.70608227128903, 34.426300194372274]\n        ]\n    ]\n}\n\n# catalog search\nsearch = catalog.search(\n    collections = ['naip'], # list with collection id\n    intersects = bbox,\n    datetime=time_range\n) \nsearch\n\n\n&lt;pystac_client.item_search.ItemSearch at 0x1680d6810&gt;\n\n\nTo get the items found in the search (or check if there were any matches in the search) we use the item_collection() method:\n\n\nCode\nitems = search.item_collection()\n\n# number of items in search\nlen(items)\n\n\n2\n\n\n\n\nCode\nitems\n\n\n\n\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"FeatureCollection\"\n        \n    \n                \n            \n                \n                    \n        \n            features\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            gsd\n            0.6\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            \"2020-05-21T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            naip:year\n            \"2020\"\n        \n    \n            \n        \n            \n                \n        \n            proj:bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3806808.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            253260.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            3814296.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            26911\n        \n    \n            \n        \n            \n                \n        \n            naip:state\n            \"ca\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            12480\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10550\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            246930.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            3814296.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.685448\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.439192\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.752061\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.373269\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20200521\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.754272\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.371741\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.683292\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            34.440724\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"naip\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            type\n            \"Feature\"\n        \n    \n            \n        \n            \n                \n        \n            stac_version\n            \"1.0.0\"\n        \n    \n            \n        \n            \n                \n        \n            id\n            \"ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            properties\n            \n        \n            \n                \n        \n            gsd\n            0.6\n        \n    \n            \n        \n            \n                \n        \n            datetime\n            \"2018-07-24T00:00:00Z\"\n        \n    \n            \n        \n            \n                \n        \n            naip:year\n            \"2018\"\n        \n    \n            \n        \n            \n                \n        \n            proj:bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            246978.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            3806856.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            253212.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            3814248.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:epsg\n            26911\n        \n    \n            \n        \n            \n                \n        \n            naip:state\n            \"ca\"\n        \n    \n            \n        \n            \n                \n        \n            proj:shape\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            12320\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            10390\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            proj:transform\n            [] 9 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            246978.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            -0.6\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            3814248.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            0.0\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            1.0\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            geometry\n            \n        \n            \n                \n        \n            type\n            \"Polygon\"\n        \n    \n            \n        \n            \n                \n        \n            coordinates\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.37369\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.685956\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.44028\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.753736\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.438772\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.751554\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.372185\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.37369\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            links\n            [] 5 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"collection\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Microsoft Planetary Computer STAC API\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Map of item\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            assets\n            \n        \n            \n                \n        \n            image\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.tif?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff; profile=cloud-optimized\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"RGBIR COG tile\"\n        \n    \n            \n        \n            \n                \n        \n            eo:bands\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"Red\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"red\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"Green\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"green\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"Blue\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"blue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"NIR\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"nir\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"near-infrared\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"data\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            metadata\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_fgdc_2018/34119/m_3411935_sw_11_060_20180724.txt?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/plain\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"FGDC Metdata\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"metadata\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.200.jpg?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/jpeg\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            tilejson\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"TileJSON with default rendering\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"tiles\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            rendered_preview\n            \n        \n            \n                \n        \n            href\n            \"https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Rendered preview\"\n        \n    \n            \n        \n            \n                \n        \n            rel\n            \"preview\"\n        \n    \n            \n        \n            \n                \n        \n            roles\n            [] 1 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"overview\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            bbox\n            [] 4 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            -119.753736\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            34.372185\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            -119.683827\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            34.44028\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            stac_extensions\n            [] 2 items\n        \n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/projection/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            collection\n            \"naip\""
  },
  {
    "objectID": "blog/STAC-search.html#item",
    "href": "blog/STAC-search.html#item",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Item",
    "text": "Item\nLet’s get the first item in the search\n\n\nCode\n# get first item in the catalog search\nitem = items[0]\ntype(item)\n\n\npystac.item.Item\n\n\nRemember the STAC item is the core object in the catalog.\nThe item does not contain the data itslef, but rather metadata about it and links to access the actual data (assets). Some of the metadta:\n\n\nCode\nprint('id', item.id)\nitem.properties\n\n\nid ca_m_3411935_sw_11_060_20200521\n\n\n{'gsd': 0.6,\n 'datetime': '2020-05-21T00:00:00Z',\n 'naip:year': '2020',\n 'proj:bbox': [246930.0, 3806808.0, 253260.0, 3814296.0],\n 'proj:epsg': 26911,\n 'naip:state': 'ca',\n 'proj:shape': [12480, 10550],\n 'proj:transform': [0.6, 0.0, 246930.0, 0.0, -0.6, 3814296.0, 0.0, 0.0, 1.0]}\n\n\nJust as the item properties, the item assets are given in a dictionary, with each vlaue being a pystac.asset. Let’s check the assets in the item:\n\n\nCode\nitem.assets\n\n\n{'image': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D&gt;,\n 'thumbnail': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-28T05%3A48%3A51Z&se=2023-11-29T06%3A33%3A51Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-28T18%3A08%3A50Z&ske=2023-12-05T18%3A08%3A50Z&sks=b&skv=2021-06-08&sig=nP0oBdGTDhtG1t5h6ZgijAUbeAOX1x0QDgtunpDgI1E%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;}\n\n\n\n\nCode\nfor key in item.assets.keys():\n    print(key, '--', item.assets[key].title)\n\n\nimage -- RGBIR COG tile\nthumbnail -- Thumbnail\ntilejson -- TileJSON with default rendering\nrendered_preview -- Rendered preview\n\n\nNotice each asset has an href, which is a link to the asset object (i.e. the data). For example, we can use the URL for the rendered preview asset to plot it:\n\n\nCode\nImage(url=item.assets['rendered_preview'].href, width=500)"
  },
  {
    "objectID": "blog/STAC-search.html#load-data",
    "href": "blog/STAC-search.html#load-data",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Load data",
    "text": "Load data\nThe raster data in our current item is in the image asset. Again, we access this data via its URL. This time we open it using rioxr.open_rasterio() directly:\n\n\nCode\nsb = rioxr.open_rasterio(item.assets['image'].href)\nsb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 4, y: 12480, x: 10550)&gt;\n[526656000 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3 4\n  * x            (x) float64 2.469e+05 2.469e+05 ... 2.533e+05 2.533e+05\n  * y            (y) float64 3.814e+06 3.814e+06 ... 3.807e+06 3.807e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:             Area\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    _FillValue:                0\n    scale_factor:              1.0\n    add_offset:                0.0xarray.DataArrayband: 4y: 12480x: 10550...[526656000 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3 4array([1, 2, 3, 4])x(x)float642.469e+05 2.469e+05 ... 2.533e+05array([246930.3, 246930.9, 246931.5, ..., 253258.5, 253259.1, 253259.7])y(y)float643.814e+06 3.814e+06 ... 3.807e+06array([3814295.7, 3814295.1, 3814294.5, ..., 3806809.5, 3806808.9, 3806808.3])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :246930.0 0.6 0.0 3814296.0 0.0 -0.6array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3, 4], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          246930.3,           246930.9,           246931.5,\n       246932.09999999998, 246932.69999999998,           246933.3,\n                 246933.9,           246934.5, 246935.09999999998,\n       246935.69999999998,\n       ...\n                 253254.3,           253254.9,           253255.5,\n       253256.09999999998, 253256.69999999998,           253257.3,\n                 253257.9,           253258.5, 253259.09999999998,\n       253259.69999999998],\n      dtype='float64', name='x', length=10550))yPandasIndexPandasIndex(Index([         3814295.7,          3814295.1,          3814294.5,\n       3814293.9000000004, 3814293.3000000003,          3814292.7,\n                3814292.1,          3814291.5, 3814290.9000000004,\n       3814290.3000000003,\n       ...\n                3806813.7,          3806813.1,          3806812.5,\n       3806811.9000000004, 3806811.3000000003,          3806810.7,\n                3806810.1,          3806809.5, 3806808.9000000004,\n       3806808.3000000003],\n      dtype='float64', name='y', length=12480))Attributes: (9)AREA_OR_POINT :AreaTIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1_FillValue :0scale_factor :1.0add_offset :0.0\n\n\n\n\nCode\n# plot raster with correct ratio\nsize = 6 # height in in of plot\naspect = sb.rio.width/sb.rio.height\nsb.sel(band=[1,2,3]).plot.imshow(size=size)#, aspect=aspect)\n\n\n&lt;matplotlib.image.AxesImage at 0x16784e250&gt;"
  },
  {
    "objectID": "blog/STAC-search.html#exercise",
    "href": "blog/STAC-search.html#exercise",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Exercise",
    "text": "Exercise\nThe ‘cop-dem-glo-90’ (id of collection) collection contains the Copernicus DEM at 90m resolution (the one we used for Grand Canyon).\n\nUse the bbox for Santa Barbara to look for items in this collection/\nGet the first item in the search and check its assets.\nPlot the item’s rendered preview asset\nOpen the item’s data using rioxarray.\n\n\n\nCode\n# catalog search\n\nsearch = catalog.search(\ncollections = ['cop-dem-glo-90'],\nintersects = bbox)\n\nsearch\n\n\n&lt;pystac_client.item_search.ItemSearch at 0x1677d43d0&gt;\n\n\n\n\nCode\nsb_items = search.item_collection()\n\n# number of items in search \nlen(sb_items)\n\n\n1\n\n\n\n\nCode\n# first item in catalog\nsb_item = sb_items[0]\ntype(sb_item)\n\n\npystac.item.Item\n\n\n\n\nCode\nsb_item.assets\n\n\n{'data': &lt;Asset href=https://elevationeuwest.blob.core.windows.net/copernicus-dem/COP90_hh/Copernicus_DSM_COG_30_N34_00_W120_00_DEM.tif?st=2023-11-28T05%3A50%3A18Z&se=2023-11-29T06%3A35%3A18Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-29T00%3A21%3A36Z&ske=2023-12-06T00%3A21%3A36Z&sks=b&skv=2021-06-08&sig=8YM0NGC%2BhTB%2BFH2E4fCofKTZsCNnhaSAl1aCpgaQNuk%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=cop-dem-glo-90&item=Copernicus_DSM_COG_30_N34_00_W120_00_DEM&assets=data&colormap_name=terrain&rescale=-1000%2C4000&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=cop-dem-glo-90&item=Copernicus_DSM_COG_30_N34_00_W120_00_DEM&assets=data&colormap_name=terrain&rescale=-1000%2C4000&format=png&gt;}\n\n\n\n\nCode\nImage(url=sb_item.assets['rendered_preview'].href, width=500)\n\n\n\n\n\n\n\nCode\ndem = rioxr.open_rasterio(sb_item.assets['data'].href)\ndem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 1200, x: 1200)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * band         (band) int64 1\n  * x            (x) float64 -120.0 -120.0 -120.0 ... -119.0 -119.0 -119.0\n  * y            (y) float64 35.0 35.0 35.0 35.0 35.0 ... 34.0 34.0 34.0 34.0\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:  Point\n    scale_factor:   1.0\n    add_offset:     0.0xarray.DataArrayband: 1y: 1200x: 1200...[1440000 values with dtype=float32]Coordinates: (4)band(band)int641array([1])x(x)float64-120.0 -120.0 ... -119.0 -119.0array([-120.      , -119.999167, -119.998333, ..., -119.0025  , -119.001667,\n       -119.000833])y(y)float6435.0 35.0 35.0 ... 34.0 34.0 34.0array([35.      , 34.999167, 34.998333, ..., 34.0025  , 34.001667, 34.000833])spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :-120.00041666666667 0.0008333333333333334 0.0 35.000416666666666 0.0 -0.0008333333333333334array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([             -120.0, -119.99916666666667, -119.99833333333333,\n                 -119.9975, -119.99666666666667, -119.99583333333334,\n                  -119.995, -119.99416666666667, -119.99333333333334,\n                 -119.9925,\n       ...\n       -119.00833333333334,           -119.0075, -119.00666666666666,\n       -119.00583333333333,            -119.005, -119.00416666666666,\n       -119.00333333333333,           -119.0025, -119.00166666666667,\n       -119.00083333333333],\n      dtype='float64', name='x', length=1200))yPandasIndexPandasIndex(Index([              35.0,  34.99916666666667, 34.998333333333335,\n                  34.9975,  34.99666666666667,  34.99583333333333,\n                   34.995, 34.994166666666665,  34.99333333333333,\n                  34.9925,\n       ...\n        34.00833333333333,            34.0075,  34.00666666666667,\n       34.005833333333335,             34.005,  34.00416666666667,\n        34.00333333333333,            34.0025, 34.001666666666665,\n        34.00083333333333],\n      dtype='float64', name='y', length=1200))Attributes: (3)AREA_OR_POINT :Pointscale_factor :1.0add_offset :0.0"
  },
  {
    "objectID": "blog/STAC-search.html#access",
    "href": "blog/STAC-search.html#access",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Access",
    "text": "Access\nWe use the Client function from the pystac_client package to access the catalog:\n\n\nCode\n# access catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier = planetary_computer.sign_inplace)\n\n\nThe modifier parameter is needed to access the data in the MPC catalog."
  },
  {
    "objectID": "blog/STAC-search.html#import-libraries-and-functions",
    "href": "blog/STAC-search.html#import-libraries-and-functions",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "Code\n# General libraries and functions\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\n# Geospatial libraries and functions\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nfrom shapely.geometry import box\nfrom shapely.geometry import Point"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html",
    "href": "blog/2023-12-11-post/STAC-search.html",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "In this analysis, I’ll use a raster dataset from the U.S. Geological Survey (USGS) to extract land cover statistics in a small region surrounding Mount Whitney in California. The numbers contained in the raster represent land cover classification, so I will also have to use an accompanying CSV file from USGS that tells us what classes of land cover correspond to these numbers. I’ll also be creating a simple map showing the area of analysis relative to Mount Whitney. An analysis of this kind has potential use for government agencies seeking to better understand land cover in a region.\n\n\n\nMount Whitney\n\n\n\n\n\nAt an elevation of 14,505 feet above sea level, Mount Whitney is the tallest mountain in the contiguous United States. Located in the Sierra Nevada mountain range, Mount Whitney’s western slope and summit are located in Sequoia National Park, and the summit is also the southern terminus of the popular John Muir trail, which stretches over 200 miles from Yosemite Valley down to Mount Whitney. The eastern slope is part of the Inyo National Forest and is managed by the U.S. Forest Service.\n\n\n\n\nExracting pixels per land cover class from raster dataset\nMarging extracted pixels with tabular dataset matching numeric codes to character strings\nCreating horizontal bar plot showing percent area of different land cover classes\nExtracting bounding box of raster dataset\nCreating map that shows area of land cover analysis relative to Mount Whitney with California boundaries as a basemap\n\n\n\n\n\n\nThe primary dataset that we will be working with comes from the 2011 National Terrestrial Ecosystems data, which was collected as part of the USGS Gap Analysis Project (GAP) by the U.S. Forest Service and Department of the Interior (2). For the purposes of this analysis, the full, nationwide dataset was pre-processed in Microsoft Planetary Computer to only include the area around Mount Whitney. With 30 meter by 30 meter pixel resolution, this raster dataset is a TIF file and contains numbers representing land cover classification.\nU.S. Geological Survey (USGS) Gap Analysis Project (GAP), 2016, GAP/LANDFIRE National Terrestrial Ecosystems 2011: U.S. Geological Survey data release, https://doi.org/10.5066/F7ZS2TM0.\n\n\nCode\nimport os\nimport xarray as xr\nimport rioxarray as rioxr\n\n# Import land cover TIF as xarray.DataArray\nlulc_fp = os.path.join(os.getcwd(),'..','data','2023-12-11-post-data','land_cover.tif')\nlulc = rioxr.open_rasterio(lulc_fp)\n\n\n\n\n\nOur second dataset is also from the 2011 National Terrestrial Ecosystems data and helps us make sense of data in the raster dataset. This tabular dataset is a CSV file and has the land cover classification names associated with each code used in the raster dataset. This dataset was accessed from the same online source as the raster dataset.\n\n\nCode\nimport pandas as pd\n\n# Import accompanying CSV as pandas.DataFrame\nclass_names = pd.read_csv('../data/2023-12-11-post-data/GAP_National_Terrestrial_Ecosystems.csv')\n\n\n\n\n\nThe final dataset that we will be using is a shapefile of California geographic boundaries, included in the U.S. Census Bureau’s 2016 Topologically Integrated Geographic Encoding and Referencing (TIGER) database. We will use this shapefile to plot our basemap when visualizing our area of analysis.\nCitation\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\n\n# Import CA shapefile as geopandas.GeoDataFrame\nca = gpd.read_file('https://data.ca.gov/dataset/e212e397-1277-4df3-8c22-40721b095f33/resource/3db1e426-fb51-44f5-82d5-a54d7c6e188b/download/ca-state-boundary.zip')\n\n\n\n\n\n\nWe’ll start by importing all our necessary libraries and functions for our analysis. Some of these packages we already imported before reading in our data, but we will again include them here just to remind us of all the packages that we are using.\n\n\nCode\n# General libraries and functions\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\n# Geospatial libraries and functions\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nfrom shapely.geometry import box\nfrom shapely.geometry import Point\n\n\n\n\n\nNext, we reduce the size of the raster, which is stored in our Python environment as a xarray.DataArray named lulc. We want to remove these unnecessary raster componenets to simplify our Python environment, often helping our code run faster as well.\n\n\nCode\n# Remove band dimension\nlulc = lulc.squeeze()\n\n# Remove coordinates associated to band\nlulc = lulc.drop('band')"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#purpose",
    "href": "blog/2023-12-11-post/STAC-search.html#purpose",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "In this analysis, I’ll use a raster dataset from the U.S. Geological Survey (USGS) to extract land cover statistics in a small region surrounding Mount Whitney in California. The numbers contained in the raster represent land cover classification, so I will also have to use an accompanying CSV file from USGS that tells us what classes of land cover correspond to these numbers. I’ll also be creating a simple map showing the area of analysis relative to Mount Whitney. An analysis of this kind has potential use for government agencies seeking to better understand land cover in a region.\n\n\n\nMount Whitney"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#about",
    "href": "blog/2023-12-11-post/STAC-search.html#about",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "At an elevation of 14,505 feet above sea level, Mount Whitney is the tallest mountain in the contiguous United States. Located in the Sierra Nevada mountain range, Mount Whitney’s western slope and summit are located in Sequoia National Park, and the summit is also the southern terminus of the popular John Muir trail, which stretches over 200 miles from Yosemite Valley down to Mount Whitney. The eastern slope is part of the Inyo National Forest and is managed by the U.S. Forest Service."
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#highlights-of-analysis",
    "href": "blog/2023-12-11-post/STAC-search.html#highlights-of-analysis",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "Exracting pixels per land cover class from raster dataset\nMarging extracted pixels with tabular dataset matching numeric codes to character strings\nCreating horizontal bar plot showing percent area of different land cover classes\nExtracting bounding box of raster dataset\nCreating map that shows area of land cover analysis relative to Mount Whitney with California boundaries as a basemap"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#data",
    "href": "blog/2023-12-11-post/STAC-search.html#data",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "The primary dataset that we will be working with comes from the 2011 National Terrestrial Ecosystems data, which was collected as part of the USGS Gap Analysis Project (GAP) by the U.S. Forest Service and Department of the Interior (2). For the purposes of this analysis, the full, nationwide dataset was pre-processed in Microsoft Planetary Computer to only include the area around Mount Whitney. With 30 meter by 30 meter pixel resolution, this raster dataset is a TIF file and contains numbers representing land cover classification.\nU.S. Geological Survey (USGS) Gap Analysis Project (GAP), 2016, GAP/LANDFIRE National Terrestrial Ecosystems 2011: U.S. Geological Survey data release, https://doi.org/10.5066/F7ZS2TM0.\n\n\nCode\nimport os\nimport xarray as xr\nimport rioxarray as rioxr\n\n# Import land cover TIF as xarray.DataArray\nlulc_fp = os.path.join(os.getcwd(),'..','data','2023-12-11-post-data','land_cover.tif')\nlulc = rioxr.open_rasterio(lulc_fp)\n\n\n\n\n\nOur second dataset is also from the 2011 National Terrestrial Ecosystems data and helps us make sense of data in the raster dataset. This tabular dataset is a CSV file and has the land cover classification names associated with each code used in the raster dataset. This dataset was accessed from the same online source as the raster dataset.\n\n\nCode\nimport pandas as pd\n\n# Import accompanying CSV as pandas.DataFrame\nclass_names = pd.read_csv('../data/2023-12-11-post-data/GAP_National_Terrestrial_Ecosystems.csv')\n\n\n\n\n\nThe final dataset that we will be using is a shapefile of California geographic boundaries, included in the U.S. Census Bureau’s 2016 Topologically Integrated Geographic Encoding and Referencing (TIGER) database. We will use this shapefile to plot our basemap when visualizing our area of analysis.\nCitation\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\n\n# Import CA shapefile as geopandas.GeoDataFrame\nca = gpd.read_file('https://data.ca.gov/dataset/e212e397-1277-4df3-8c22-40721b095f33/resource/3db1e426-fb51-44f5-82d5-a54d7c6e188b/download/ca-state-boundary.zip')"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#import-libraries-and-functions",
    "href": "blog/2023-12-11-post/STAC-search.html#import-libraries-and-functions",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "We’ll start by importing all our necessary libraries and functions for our analysis. Some of these packages we already imported before reading in our data, but we will again include them here just to remind us of all the packages that we are using.\n\n\nCode\n# General libraries and functions\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\n# Geospatial libraries and functions\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nfrom shapely.geometry import box\nfrom shapely.geometry import Point"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#raster-reduction",
    "href": "blog/2023-12-11-post/STAC-search.html#raster-reduction",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "",
    "text": "Next, we reduce the size of the raster, which is stored in our Python environment as a xarray.DataArray named lulc. We want to remove these unnecessary raster componenets to simplify our Python environment, often helping our code run faster as well.\n\n\nCode\n# Remove band dimension\nlulc = lulc.squeeze()\n\n# Remove coordinates associated to band\nlulc = lulc.drop('band')"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#calculate-percent-area-of-land-cover-classes",
    "href": "blog/2023-12-11-post/STAC-search.html#calculate-percent-area-of-land-cover-classes",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Calculate percent area of land cover classes",
    "text": "Calculate percent area of land cover classes\nNow that we are working with a reduced raster, we can move on to calculating percent area of the different land cover classes. To do this, we must extract the unique values contained in the lulc xarray.DataArray, in addition to the count of how many times each unique value appears in our raster. Since these codes correspond to land cover classes specified in our class_names pandas.DataFrame, we need to merge the extracted codes and counts with class_names, which requires storing our codes and counts as a pandas.DataFrame. Once we have this merged pandas.DataFrame, which we stored as classes, performing the actual calculation can be easily accomplished. We just use the count column in classes and size of lulc as object attributes.\n\n\nCode\n# Extract pixels per land cover class\ncodes, counts = np.unique(lulc, return_counts = True)\n\n# Create extracted pixels DataFrame\npix_counts = pd.DataFrame({'code': codes, 'count': counts})\n\n# Merge extracted pixels DataFrame with class names DataFrame\nclasses = pd.merge(pix_counts, class_names, on='code', how='inner')\n\n# Calculate the percentage of area covered by each class\nclasses['percentage'] = (classes['count'] / lulc.size) * 100"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#create-horizontal-bar-plot",
    "href": "blog/2023-12-11-post/STAC-search.html#create-horizontal-bar-plot",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Create horizontal bar plot",
    "text": "Create horizontal bar plot\nNext, we will our percent values with a horizontal bar plot, which shows us the percent for each land cover classification that takes up at least 1% of the area. We filter for just these land cover classes to reduce the amount of output, as it is likely irrelevant for an audience to see the percent for land cover classes that only take up a very small area. We also use the sort_values function, so we can plot our horizontal bars in ascending order, making our plot easier to interpret.\n\n\nCode\n# Filter for classes with more than 1% land cover\nfiltered_classes = classes[classes['percentage'] &gt; 1]\n\n# Sort classes in decreasing order of percentage\nsorted_classes = filtered_classes.sort_values(by='percentage', ascending=True)\n\n# Create a horizontal bar plot with axis label and title\nplt.barh(sorted_classes['class_label'], sorted_classes['percentage'], color='skyblue')\nplt.xlabel('Percent Area')\nplt.title('Land Cover Classes near Mount Whitney')\n\n# Show plot\nplt.show()"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#create-geodataframes-for-area-of-analysis-and-mount-whitney",
    "href": "blog/2023-12-11-post/STAC-search.html#create-geodataframes-for-area-of-analysis-and-mount-whitney",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Create GeoDataFrames for area of analysis and Mount Whitney",
    "text": "Create GeoDataFrames for area of analysis and Mount Whitney\nTo better understand our area of analysis relative to Mount Whitney, we want to plot the geographic coordinates of lulc and a point for Mount Whitney on the same map. To do this, we first extract the bounding box of lulc, which gives us four coordinate points that make up a rectangle denoting the area analyzed from our raster. In this case, we know that our raster area was a square, which means that extracting the bounding box does not include additional area that was not part of the analysis. Next, we convert these points into a shapely.Polygon, which then allows us to create a geopandas.GeoDataFrame containing this polygon. Lastley, we make another geopandas.GeoDataFrame that just contains a single point for Mount Whitney. We know to provide the coordinates for Mount Whitney in the EPSG:4326 Coordinate Reference System because this is the same CRS that is set for the USGS data that we read in as lulc.\n\n\nCode\n# Extract bounding box of LULC tile\nbbox_coords = lulc.rio.bounds()\n\n# Create shapely polygon from bounding box coordinates\nbbox_polygon = box(bbox_coords[0], bbox_coords[1], bbox_coords[2], bbox_coords[3])\n\n# Create GeoDataFrame for bounding box of LULC tile\nbbox = gpd.GeoDataFrame(geometry=[bbox_polygon], crs=lulc.rio.crs)\n\n# Create GeoDataFrame with a single point for Mount Whitney\nmt_whitney = gpd.GeoDataFrame(geometry=[Point(-118.2929, 36.5786)], crs='EPSG:4326')"
  },
  {
    "objectID": "blog/2023-12-11-post/STAC-search.html#plot-map-showing-area-of-land-cover-analysis-relative-to-mount-whitney",
    "href": "blog/2023-12-11-post/STAC-search.html#plot-map-showing-area-of-land-cover-analysis-relative-to-mount-whitney",
    "title": "Land Cover Analysis of Mount Whitney surrounding area",
    "section": "Plot map showing area of land cover analysis relative to Mount Whitney",
    "text": "Plot map showing area of land cover analysis relative to Mount Whitney\nAfter changing the CRS of bbox and ca to also match lulc, we can finally create our map showing the area of analysis relative to Mount Whitney!\n\n\nCode\n# Change CRS of LULC tile bounding box to EPSG:4326\nbbox.to_crs('EPSG:4326', inplace=True)\n\n# Change CRS of CA boundaries to EPSG:4326\nca.to_crs('EPSG:4326', inplace = True)\n\n# Initialize figure and axis\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot CA basemap, LULC tile bounding box, and Mount Whitney point\nca.plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.5, label='California, US')\nbbox.plot(ax=ax, color='skyblue', edgecolor='black', alpha=0.5, label='LULC tile')\nmt_whitney.plot(ax=ax, marker='^', color='red', markersize=100, label='Mount Whitney')\n\n# Specify legend elements\nlegend_elements = [plt.Line2D([0], [0], color='lightgray', lw=5, label='California'),\n                   plt.Line2D([0], [0], color='skyblue', lw=5, label='LULC tile'),\n                   mlines.Line2D([0], [0], marker='^', color='w', markerfacecolor='red', markersize=10, label='Mount Whitney', linestyle='None')]\n\n# Add legend, title, and labels\nax.legend(handles=legend_elements, loc='upper right')\nplt.title('Area of Land Cover Analysis')\nplt.xlabel('Latitude')\nplt.ylabel('Longitude')\n\n# Show plot\nplt.show()"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html",
    "title": "Land cover analysis around Mount Whitney",
    "section": "",
    "text": "In this analysis, we will use a raster dataset from the U.S. Geological Survey (USGS) to extract land cover statistics in a small region surrounding Mount Whitney in California. We will also be creating a simple map showing the area of analysis relative to Mount Whitney. An analysis of this kind has potential use for government agencies seeking to better understand land cover in a region.\n\nPenny Higgins, CC BY-SA 2.0, via Wikimedia Commons\n\n\n\nAt an elevation of 14,505 feet above sea level, Mount Whitney is the tallest mountain in the contiguous United States (Sierra Nevada Geotourism 2023). Located in the Sierra Nevada mountain range, Mount Whitney’s western slope and summit are located in Sequoia National Park, and the summit is also the southern terminus of the popular John Muir trail, which stretches over 200 miles from Yosemite Valley down to Mount Whitney. The eastern slope is part of the Inyo National Forest and is managed by the U.S. Forest Service.\n\n\n\n\nExracting pixels per land cover class from raster dataset\nMarging extracted pixels with tabular dataset matching numeric codes to character strings\nCreating horizontal bar plot showing percent area of different land cover classes\nExtracting bounding box of raster dataset\nCreating map that shows area of land cover analysis relative to Mount Whitney with California boundaries as a basemap\n\n\n\n\n\n\nThe primary dataset that we will be working with comes from the 2011 National Terrestrial Ecosystems data, which was collected as part of the USGS Gap Analysis Project (GAP) by the U.S. Forest Service and Department of the Interior (U.S. Geological Survey 2016). For the purposes of this analysis, the full, nationwide dataset was pre-processed in Microsoft Planetary Computer to only include the area around Mount Whitney. With 30 meter by 30 meter pixel resolution, this raster dataset is a TIF file and contains numbers representing land cover classification.\n\n\nCode\nimport os\nimport xarray as xr\nimport rioxarray as rioxr\n\n# Import land cover TIF as xarray.DataArray\nlulc_fp = os.path.join(os.getcwd(),'..','..','data','2023-12-11-post-data','land_cover.tif')\nlulc = rioxr.open_rasterio(lulc_fp)\n\n\n\n\n\nOur second dataset is also from the 2011 National Terrestrial Ecosystems data and helps us make sense of data in the raster dataset. This tabular dataset is a CSV file and has the land cover classification names associated with each code used in the raster dataset. This dataset was accessed from the same online source as the raster dataset (U.S. Geological Survey 2016).\n\n\nCode\nimport pandas as pd\n\n# Import accompanying CSV as pandas.DataFrame\nclass_names = pd.read_csv('../../data/2023-12-11-post-data/GAP_National_Terrestrial_Ecosystems.csv')\n\n\n\n\n\nThe final dataset that we will be using is a shapefile of California geographic boundaries, included in the U.S. Census Bureau’s 2016 Topologically Integrated Geographic Encoding and Referencing (TIGER) database (California Open Data 2019). We will use this shapefile to plot our basemap when visualizing our area of analysis.\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\n\n# Import CA shapefile as geopandas.GeoDataFrame\nca = gpd.read_file('https://data.ca.gov/dataset/e212e397-1277-4df3-8c22-40721b095f33/resource/3db1e426-fb51-44f5-82d5-a54d7c6e188b/download/ca-state-boundary.zip')\n\n\n\n\n\n\nWe’ll start by importing all our necessary libraries and functions for our analysis. Some of these packages we already imported before reading in our data, but we will again include them here just to remind us of all the packages that we are using.\n\n\nCode\n# General libraries and functions\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\n# Geospatial libraries and functions\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nfrom shapely.geometry import box\nfrom shapely.geometry import Point\n\n\n\n\n\nNext, we reduce the size of the raster, which is stored in our Python environment as a xarray.DataArray named lulc. We want to remove these unnecessary raster componenets to simplify our Python environment, often helping our code run faster as well.\n\n\nCode\n# Remove band dimension\nlulc = lulc.squeeze()\n\n# Remove coordinates associated to band\nlulc = lulc.drop('band')"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#purpose",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#purpose",
    "title": "Land cover analysis around Mount Whitney",
    "section": "Purpose",
    "text": "Purpose\nIn this analysis, we will use a raster dataset from the U.S. Geological Survey (USGS) to extract land cover statistics in a small region surrounding Mount Whitney in California. We will also be creating a simple map showing the area of analysis relative to Mount Whitney. An analysis of this kind has potential use for environmental planners seeking to better understand land cover in a region.\n\nPenny Higgins, CC BY-SA 2.0, via Wikimedia Commons"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#about",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#about",
    "title": "Land cover analysis around Mount Whitney",
    "section": "About",
    "text": "About\nAt an elevation of 14,505 feet above sea level, Mount Whitney is the tallest mountain in the contiguous United States (Sierra Nevada Geotourism 2023). Located in the Sierra Nevada mountain range, Mount Whitney’s western slope and summit are located in Sequoia National Park, and the summit is also the southern terminus of the popular John Muir trail, which stretches over 200 miles from Yosemite Valley down to Mount Whitney. The eastern slope is part of the Inyo National Forest and is managed by the U.S. Forest Service."
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#highlights-of-analysis",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#highlights-of-analysis",
    "title": "Land cover analysis around Mount Whitney",
    "section": "Highlights of analysis",
    "text": "Highlights of analysis\n\nExracting pixels per land cover class from raster dataset\nMerging extracted pixels with tabular dataset matching numeric codes to character strings\nCreating horizontal bar plot showing percent area of different land cover classes\nExtracting bounding box of raster dataset\nCreating map that shows area of land cover analysis relative to Mount Whitney with California boundaries as a basemap"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#data",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#data",
    "title": "Land cover analysis around Mount Whitney",
    "section": "",
    "text": "The primary dataset that we will be working with comes from the 2011 National Terrestrial Ecosystems data, which was collected as part of the USGS Gap Analysis Project (GAP) by the U.S. Forest Service and Department of the Interior (U.S. Geological Survey 2016). For the purposes of this analysis, the full, nationwide dataset was pre-processed in Microsoft Planetary Computer to only include the area around Mount Whitney. With 30 meter by 30 meter pixel resolution, this raster dataset is a TIF file and contains numbers representing land cover classification.\n\n\nCode\nimport os\nimport xarray as xr\nimport rioxarray as rioxr\n\n# Import land cover TIF as xarray.DataArray\nlulc_fp = os.path.join(os.getcwd(),'..','..','data','2023-12-11-post-data','land_cover.tif')\nlulc = rioxr.open_rasterio(lulc_fp)\n\n\n\n\n\nOur second dataset is also from the 2011 National Terrestrial Ecosystems data and helps us make sense of data in the raster dataset. This tabular dataset is a CSV file and has the land cover classification names associated with each code used in the raster dataset. This dataset was accessed from the same online source as the raster dataset (U.S. Geological Survey 2016).\n\n\nCode\nimport pandas as pd\n\n# Import accompanying CSV as pandas.DataFrame\nclass_names = pd.read_csv('../../data/2023-12-11-post-data/GAP_National_Terrestrial_Ecosystems.csv')\n\n\n\n\n\nThe final dataset that we will be using is a shapefile of California geographic boundaries, included in the U.S. Census Bureau’s 2016 Topologically Integrated Geographic Encoding and Referencing (TIGER) database (California Open Data 2019). We will use this shapefile to plot our basemap when visualizing our area of analysis.\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\n\n# Import CA shapefile as geopandas.GeoDataFrame\nca = gpd.read_file('https://data.ca.gov/dataset/e212e397-1277-4df3-8c22-40721b095f33/resource/3db1e426-fb51-44f5-82d5-a54d7c6e188b/download/ca-state-boundary.zip')"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#import-libraries-and-functions",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#import-libraries-and-functions",
    "title": "Land cover analysis around Mount Whitney",
    "section": "2) Import libraries and functions",
    "text": "2) Import libraries and functions\nWe’ll start by importing all our necessary libraries and functions for our analysis. Some of these packages we already imported before reading in our data, but we will again include them here just to remind us of all the packages that we are using.\n\n\nCode\n# General libraries and functions\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\n# Geospatial libraries and functions\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nfrom shapely.geometry import box\nfrom shapely.geometry import Point"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#raster-reduction",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#raster-reduction",
    "title": "Land cover analysis around Mount Whitney",
    "section": "3) Raster reduction",
    "text": "3) Raster reduction\nNext, we reduce the size of the raster, which is stored in our Python environment as a xarray.DataArray named lulc. We want to remove these unnecessary raster componenets to simplify our Python environment, often helping our code run faster as well.\n\n\nCode\n# Remove band dimension\nlulc = lulc.squeeze()\n\n# Remove coordinates associated to band\nlulc = lulc.drop('band')"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#calculate-percent-area-of-land-cover-classes",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#calculate-percent-area-of-land-cover-classes",
    "title": "Land cover analysis around Mount Whitney",
    "section": "4) Calculate percent area of land cover classes",
    "text": "4) Calculate percent area of land cover classes\nNow that we are working with a reduced raster, we can move on to calculating percent area of the different land cover classes. To do this, we must extract the unique values contained in the lulc xarray.DataArray, in addition to the count of how many times each unique value appears in our raster. Since these codes correspond to land cover classes specified in our class_names pandas.DataFrame, we need to merge the extracted codes and counts with class_names, which requires storing our codes and counts as a pandas.DataFrame. Once we have this merged pandas.DataFrame, which we stored as classes, performing the actual calculation can be easily accomplished. We just use the count column in classes and size of lulc as object attributes.\n\n\nCode\n# Extract pixels per land cover class\ncodes, counts = np.unique(lulc, return_counts = True)\n\n# Create extracted pixels DataFrame\npix_counts = pd.DataFrame({'code': codes, 'count': counts})\n\n# Merge extracted pixels DataFrame with class names DataFrame\nclasses = pd.merge(pix_counts, class_names, on='code', how='inner')\n\n# Calculate the percentage of area covered by each class\nclasses['percentage'] = (classes['count'] / lulc.size) * 100"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#create-horizontal-bar-plot",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#create-horizontal-bar-plot",
    "title": "Land cover analysis around Mount Whitney",
    "section": "5) Create horizontal bar plot",
    "text": "5) Create horizontal bar plot\nNext, we will visualize our percent values with a horizontal bar plot, which shows us the percent for each land cover classification that takes up at least 1% of the area. We filter for just these land cover classes to reduce the amount of output, as it is likely irrelevant for an audience to see the percent for land cover classes that only take up a very small area. We also use the sort_values function, so we can plot our horizontal bars in ascending order, making our plot easier to interpret.\n\n\nCode\n# Filter for classes with more than 1% land cover\nfiltered_classes = classes[classes['percentage'] &gt; 1]\n\n# Sort classes in decreasing order of percentage\nsorted_classes = filtered_classes.sort_values(by='percentage', ascending=True)\n\n# Create a horizontal bar plot with axis label and title\nplt.barh(sorted_classes['class_label'], sorted_classes['percentage'], color='skyblue')\nplt.xlabel('Percent Area')\nplt.title('Land Cover Classes around Mount Whitney')\n\n# Show plot\nplt.show()\n\n\n\n\n\nThe horizontal bar plot shows the percent area of different land cover classes in the area around Mount Whitney. Of any one class, Mediterrabean California Alpine Bedrock and Scree takes up the most land, constituting just over 15% of the analysis area. California Central Valley and Southern Coastal Grassland, Sierra Nevada Subalpine Lodgepole Pine Forest and Woodland, and Mediterranean California Mesic Mixed Conifer Forest and Woodland each make up about 8-10% of the area. Several other land cover classifications make up less than 8% of the area."
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#create-geodataframes-for-area-of-analysis-and-mount-whitney",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#create-geodataframes-for-area-of-analysis-and-mount-whitney",
    "title": "Land cover analysis around Mount Whitney",
    "section": "6) Create GeoDataFrames for area of analysis and Mount Whitney",
    "text": "6) Create GeoDataFrames for area of analysis and Mount Whitney\nTo better understand our area of analysis relative to Mount Whitney, we want to plot the geographic coordinates of lulc and a point for Mount Whitney on the same map. To do this, we first extract the bounding box of lulc, which gives us four coordinate points that make up a rectangle denoting the area analyzed from our raster. In this case, we know that our raster area was a square, which means that extracting the bounding box does not include additional area that was not part of the analysis. Next, we convert these points into a shapely.Polygon, which then allows us to create a geopandas.GeoDataFrame containing this polygon. Lastley, we make another geopandas.GeoDataFrame that just contains a single point for Mount Whitney. We know to provide the coordinates for Mount Whitney in the EPSG:4326 Coordinate Reference System because this is the same CRS that is set for the USGS data that we read in as lulc.\n\n\nCode\n# Extract bounding box of LULC tile\nbbox_coords = lulc.rio.bounds()\n\n# Create shapely polygon from bounding box coordinates\nbbox_polygon = box(bbox_coords[0], bbox_coords[1], bbox_coords[2], bbox_coords[3])\n\n# Create GeoDataFrame for bounding box of LULC tile\nbbox = gpd.GeoDataFrame(geometry=[bbox_polygon], crs=lulc.rio.crs)\n\n# Create GeoDataFrame with a single point for Mount Whitney\nmt_whitney = gpd.GeoDataFrame(geometry=[Point(-118.2929, 36.5786)], crs='EPSG:4326')"
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#plot-map-showing-area-of-land-cover-analysis-relative-to-mount-whitney",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#plot-map-showing-area-of-land-cover-analysis-relative-to-mount-whitney",
    "title": "Land cover analysis around Mount Whitney",
    "section": "7) Plot map showing area of land cover analysis relative to Mount Whitney",
    "text": "7) Plot map showing area of land cover analysis relative to Mount Whitney\nAfter changing the CRS of bbox and ca to also match lulc, we can finally create our map showing the area of analysis relative to Mount Whitney!\n\n\nCode\n# Change CRS of LULC tile bounding box to EPSG:4326\nbbox.to_crs('EPSG:4326', inplace=True)\n\n# Change CRS of CA boundaries to EPSG:4326\nca.to_crs('EPSG:4326', inplace = True)\n\n# Initialize figure and axis\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot CA basemap, LULC tile bounding box, and Mount Whitney point\nca.plot(ax=ax, color='lightgray', edgecolor='black', alpha=0.5, label='California, US')\nbbox.plot(ax=ax, color='skyblue', edgecolor='black', alpha=0.5, label='Area of analysis')\nmt_whitney.plot(ax=ax, marker='^', color='red', markersize=100, label='Mount Whitney')\n\n# Specify legend elements\nlegend_elements = [plt.Line2D([0], [0], color='lightgray', lw=5, label='California'),\n                   plt.Line2D([0], [0], color='skyblue', lw=5, label='Area of analysis'),\n                   mlines.Line2D([0], [0], marker='^', color='w', markerfacecolor='red', markersize=10, label='Mount Whitney', linestyle='None')]\n\n# Add legend, title, and labels\nax.legend(handles=legend_elements, loc='upper right')\nplt.xlabel('Latitude')\nplt.ylabel('Longitude')\n\n# Show plot\nplt.show()\n\n\n\n\n\nThis map shows our area of land cover analysis in relation to Mount Whitney."
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#link-to-github-repository",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#link-to-github-repository",
    "title": "Land Cover Analysis around Mount Whitney",
    "section": "",
    "text": "https://github.com/linusghanadan/mt_whitney_land_cover ## Purpose In this analysis, I’ll use a raster dataset from the U.S. Geological Survey (USGS) to extract land cover statistics in a small region surrounding Mount Whitney in California. The numbers contained in the raster represent land cover classification, so I will also have to use an accompanying CSV file from USGS that tells us what classes of land cover correspond to these numbers. I’ll also be creating a simple map showing the area of analysis relative to Mount Whitney. An analysis of this kind has potential use for government agencies seeking to better understand land cover in a region.\n\n\n\nMount Whitney"
  },
  {
    "objectID": "blog/2023-12-12-post/index.html",
    "href": "blog/2023-12-12-post/index.html",
    "title": "Time series analysis of nitrogen and phosphorus concentrations in Chesapeake Bay tidal regions since 2010 introduction of TMDL requirements",
    "section": "",
    "text": "Since the 2010 introduction of TMDL requirements, what seasonal and non-seasonal trends are present for nitrogen and phosphorus concentrations in Chesapeake Bay tidal regions?"
  },
  {
    "objectID": "blog/2023-12-12-post/index.html#question",
    "href": "blog/2023-12-12-post/index.html#question",
    "title": "2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions",
    "section": "Question",
    "text": "Question\nSince the 2010 introduction of federal water quality requirements, what seasonal and non-seasonal trends are present for nitrogen and phosphorus concentrations in Chesapeake Bay tidal regions?"
  },
  {
    "objectID": "blog/2023-12-12-post/index.html#introduction",
    "href": "blog/2023-12-12-post/index.html#introduction",
    "title": "2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions",
    "section": "Introduction",
    "text": "Introduction\nThe Chesapeake Bay is the largest estuary in the United States, and the largest body of water that is regulated under the Clean Water Act (U.S. Environmental Protection Agency 2023). Federal regulation pertaining to the Bay took decades to implement, and this is in large part because of the Bay’s large size and the many stakeholders involved. In the 1970s, the Bay was identified as one of the first areas in the world to have a marine dead zone, a phenomenon that literally suffocates aquatic life due to lack of oxygen in the water. Despite dead zones being identified in the 1970s, it was not until 2000 that the Bay was designated as an “impaired water” under the Clean Water Act. Then, it took another ten years, until 2010, for the EPA to take the next step of issuing Total Maximum Daily Load (TMDL) requirements, the regulatory action mandating water quality improvement.\nSpecifically, a TMDL is the maximum amount of a particular pollutant that a body of water can receive and still meet applicable water quality standards (U.S. Environmental Protection Agency 2023). This maximum amount is calculated in pounds based on measurements taken at areas where pollution is likely to end up in the Bay. In their 2010 regulation, the EPA established TMDL requirements for nitrogen, phosphorus, and sediment. Nitrogen and phosphorus, referred to as nutrients because of their role in providing nutrition to many animals and plants, cause algal blooms, which cause marine dead zones through taking in dissolved oxygen and blocking sunlight. Sediment contributes to dead zones by blocking sunlight as well, leading it to also be included in the 2010 TMDL requirements.\nThis analysis will focus on nitrogen and phosphorus, the two pollutants responsible for algal blooms in the Chesapeake Bay. A 2022 study found that agricultural runoff was the largest source of nutrient pollution, accounting for 48% of nitrogen and 27% of phosphorus in the Chesapeake Bay (Chesapeake Progress, n.d.). Both of these pollutants also get to the Bay as a result of urban and suburban runoff, wastewater treatment plants releasing treated water, and natural sources (e.g., runoff from forests, wetlands, etc.). In addition, about 25% of nitrogen that ends up in the Bay comes from air pollution that is originally emitted to the atmosphere by sources such as cars and factories (Burns et al. 2021). Through a process called atmospheric deposition, these nitrogen compounds react with other chemicals to become nitrous oxides, which can be deposited back to Earth’s surface through precipitation or as dry deposition.\nThrough conducting a time series analysis of post-2010 nitrogen and phosphorus concentration measurements, my goal is to better understand how concentrations have changed since the introduction of TMDL requirements. I’m also interested in the nature of any seasonality and whether the three time series components (i.e., seasonal, trend, and random) are consistent across both nitrogen and phosphorus."
  },
  {
    "objectID": "blog/2023-12-12-post/index.html#data",
    "href": "blog/2023-12-12-post/index.html#data",
    "title": "2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions",
    "section": "Data",
    "text": "Data\nYearly water quality data on the Chesapeake Bay’s tidal and non-tidal regions going back to 1984 is publicly available on the Chesapeake Bay Program (CBP) DataHub (Chesapeake Bay Program DataHub, n.d.). Data is organized into either Tier 1, 2, or 3 depending on how it was collected. While Tier 1 and 2 data can be collected by any interested group, Tier 3 data is collected by monitoring stations overseen by experienced professionals. Only Tier 3 data can be used for governmental regulatory assessments.\nFor my analysis, I will be using 2010 to 2019 Tier 3 data collected at 143 different monitoring stations positioned throughout the Chesapeake Bay tidal regions, which includes the mainstem Bay and tributary components. Across the 10 years that we are looking at, we’ll have a total of 43,809 nitrogen observations and 43,590 phosphorus observations.\nBelow, we import the R packages used in this analysis. Then, we read in the yearly water quality data using their CBP DataHub URL. We also process the data by creating separate data.frames for total nitrogen and phosphorus measurements.\n\n\nCode\n# Import necessary R packages\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(generics)\nlibrary(stargazer)\n\n# Create a vector of data URLs\nexcel_urls &lt;- c(\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2019_CEDR_tidal_data_01jun21.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2018_CEDR_tidal_data_01jun21.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2017_CEDR_tidal_data_11oct18.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2016_CEDR_tidal_data_15jun17.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2015_CEDR_tidal_data_15jun17.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2014_CEDR_tidal_data_15jun17.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2013_CEDR_tidal_data_15jun17.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2012_CEDR_tidal_data_15jun17.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2011_CEDR_tidal_data_15jun17.xlsx',\n  'https://datahub-content.chesapeakebay.net/traditional_annual_tidal_02jun21/2010_CEDR_tidal_data_15jun17.xlsx')\n\n# Create a temporary directory to store downloaded files\ntemp_dir &lt;- tempdir()\n\n# Create an empty list to store data frames\ndfs &lt;- list()\n\n# Loop through each URL, extract file name, define local file path, download file, read into R, and append to list of data frames\nfor (url in excel_urls) {\n  file_name &lt;- basename(url)\n  local_path &lt;- file.path(temp_dir, file_name)\n  download.file(url, destfile = local_path, mode = \"wb\")\n  wq_data &lt;- readxl::read_excel(local_path, sheet = 1)\n  dfs[[file_name]] &lt;- wq_data\n}\n\n# Combine all data frames into a single data frame\nwq_data_combined &lt;- bind_rows(dfs)\n\n# Wrangle data for relevant column variables, and filter for TN (total nitrogen)\nnitr_data &lt;- wq_data_combined %&gt;%\n  dplyr::select(\"MonitoringLocation\", \"SampleDate\", \"Parameter\", \"MeasureValue\", \"Unit\", \"Latitude\", \"Longitude\") %&gt;% \n  filter(Parameter==\"TN\")\n\n# Wrangle data for relevant column variables, and filter for TP (total phosphorus)\nphos_data &lt;- wq_data_combined %&gt;%\n  dplyr::select(\"MonitoringLocation\", \"SampleDate\", \"Parameter\", \"MeasureValue\", \"Unit\", \"Latitude\", \"Longitude\") %&gt;% \n  filter(Parameter==\"TP\")\n\n# Remove unnecessary data and values from environment\nrm(wq_data, wq_data_combined, dfs)\nrm(excel_urls, file_name, local_path, temp_dir, url)"
  },
  {
    "objectID": "blog/2023-12-12-post/index.html#methods",
    "href": "blog/2023-12-12-post/index.html#methods",
    "title": "2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions",
    "section": "Methods",
    "text": "Methods\n\nAutocorrelation function\nThe autocorrelation function calculates the correlation between the dependent variable at a given point in time and various time lags for this same variable. Thus, the autocorrelation function provides us with a tool that allows us to better understand any seasonal trends present in our data. This will be useful for us in subsequent steps of our time series analysis.\n\n\nSTL decomposition\nAs a core part of this time series analysis, I’ll be constructing a seasonal trend decomposition using locally estimated scatterplot smoothing (LOESS), which is often abbreviated as a STL decomposition model. STL allows us to separate our monthly average concentrations into three components: seasonal trend, non-seasonal trend, and remainder. Through plotting these components next to each other, we gain a more intuitive understanding of the underlying forces contributing to variation in our dependent variable, which in this case is the monthly average concentration.\nAs opposed to other decomposition methods, one thing that is particular to STL models is the ability to specify the length of a season. It can be helpful to adjust this input depending on our desired level of smoothing for the non-seasonal trend. We will use our results from the autocorrelation function to inform our chosen length of seasons. The autocorrelation function is useful in this context because it can tell us after how many lags we see a drop-off in correlation, indicating there is a drop in the significance of the seasonal trend."
  },
  {
    "objectID": "blog/2023-12-12-post/index.html#results",
    "href": "blog/2023-12-12-post/index.html#results",
    "title": "2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions",
    "section": "Results",
    "text": "Results\n\nAutocorrelation function\n\n\nCode\n# Plot autocorrelation function for nitrogen with lags going back three years\nacf(nitr_monthly_avgs_ts, lag.max = 36, i=2)\n\n\n\n\n\nLooking at this autocorrelation plot for nitrogen, I see that the t-16 lag is significant at the alpha equals 0.05 level, indicated by the black line extending beyond the blue dashed line. Meanwhile, the t-4 lag is not statistically significant. The rest of the lags remain the same or slightly decrease when comparing from the first and second year of lags. In the third year, there is a drop off in the t-28 lag compared to t-12, and there continues to be what seems like a marginal decrease in correlation across most lags. Considering all of this, I decided to set the seasonality of my STL model for nitrogen to 24 months.\n\n\nCode\n# Plot autocorrelation function for phosphorus with lags going back three years\nacf(phos_monthly_avgs_ts, lag.max = 36, i = 2)\n\n\n\n\n\nFor phosphorus, there is a very consistent marginal decline for each set of lags over the course of the three years. This is good news for our STL because it means that the seasonal trend will be easier to separate from the non-seasonal trend. Like I did with nitrogen, I’m also going to use two-year seasons for phosphorus. Similar to the case with nitrogen, it seems to me like the drop-off in lag correlations from year two to year three is a bit larger than from year one to year two. This suggests that a two-year seasonal cycle will give us an informative non-seasonal trend component that is neither too eager nor too hesitant to categorize differences as non-seasonal trends.\n\n\nSTL decomposition\n\n\nCode\n# Conduct STL for nitrogen with two-year seasons, and extract components\nnitr_decomp &lt;- nitr_monthly_avgs_ts %&gt;%\n  fabletools::model(feasts::STL(monthly_avg, t.window = 24)) %&gt;% \n  generics::components()\n\n# Plot STL model\nautoplot(nitr_decomp) +\n  labs(title = \"STL model of nitrogen concentration\", x = \"Year Month\")\n\n\n\n\n\nIn this plot of the three STL components for nitrogen, it is still difficult to see a long-term trend, despite the line being fairly smooth. There does seem to be a slight downward trend until 2018. From 2018 to 2019, there is a clear increase, but this change is then offset by an equivalent decrease over the course of 2019 to 2020. In addition the grey bars on the left all represent the same range, implying that the remainder components of our STL model contributed the most to variation in nitrogen concentration. However, this seems to be very influenced by the high spike in 2014.\n\n\nCode\n# Conduct STL for phosphorus with two-year seasons, and extract components\nphos_decomp &lt;- phos_monthly_avgs_ts %&gt;%\n  fabletools::model(feasts::STL(monthly_avg, t.window = 24)) %&gt;% \n  generics::components()\n\n# Plot STL model\nautoplot(phos_decomp) +\n  labs(title = \"STL model of phosphorus concentration\", x = \"Year Month\")\n\n\n\n\n\nThe STL plot for phosphorus does make it seem like there is a long-term downward trend, but it is difficult to tell how significant it is because of the long grey bar, which indicates it is least influential of the three components in our STL model. In this case, the grey bars show us that seasonality contributes the most to the variation in phosphorus concentration.\n\n\nCode\n# For nitrogen, plot monthly mean, seasonally adjusted monthly mean, STL seasonality, and STL trend\nggplot(nitr_monthly_avgs_df, aes(yr_mo)) +\n  scale_x_date(date_breaks = \"1 year\", date_minor_breaks = \"6 months\", date_labels = \"%Y-%m\") +\n  geom_line(aes(y=nitr_decomp$monthly_avg, color = \"Monthly mean\")) +\n  geom_line(aes(y=nitr_decomp$season_adjust, color = \"Seasonally adjusted monthly mean\"), linewidth=2) +\n  geom_line(aes(y=nitr_decomp$trend, color = \"STL trend\"), linewidth = 2) +\n  geom_line(aes(y=nitr_decomp$season_year, color = \"STL seasonality\")) +\n  labs(x = 'Year-Month',\n       y = 'Concentration (mg/L)',\n       title = \"Nitrogen in Chesapeake Bay (2010-2019)\") +\n  scale_color_manual(name = \"\", values = c(\"Monthly mean\" = \"black\", \"Seasonally adjusted monthly mean\" = \"cornflowerblue\", \"STL seasonality\" = \"seagreen\", \"STL trend\" = \"red\"), breaks = c(\"Monthly mean\", \"Seasonally adjusted monthly mean\", \"STL seasonality\", \"STL trend\")) +\n  theme_bw() +\n  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nI decided to make this visualization to get a better idea of exactly how these components map on to each other. This plot seems to confirm the idea of negligible trend for nitrogen. Since the x-axis is labeled for each year here, it is also easier to see the seasonal trend. Each year, nitrogen concentrations increase sharply around December. They then peak around February to March, before decreasing substantially and reaching their minimum around July.\n\n\nCode\n# For phosphorus, plot monthly mean, seasonally adjusted monthly mean, STL seasonality, and STL trend\nggplot(phos_monthly_avgs_df, aes(yr_mo)) +\n  scale_x_date(date_breaks = \"1 year\", date_minor_breaks = \"6 months\", date_labels = \"%Y-%m\") +\n  geom_line(aes(y=phos_decomp$monthly_avg, color = \"Monthly mean\")) +\n  geom_line(aes(y=phos_decomp$season_adjust, color = \"Seasonally adjusted monthly mean\"), linewidth=2) +\n  geom_line(aes(y=phos_decomp$trend, color = \"STL trend\"), linewidth = 2) +\n  geom_line(aes(y=phos_decomp$season_year, color = \"STL seasonality\")) +\n  labs(x = 'Year-Month',\n       y = 'Concentration (mg/L)',\n       title = \"Phosphorus in Chesapeake Bay (2010-2019)\") +\n  scale_color_manual(name = \"\", values = c(\"Monthly mean\" = \"black\", \"Seasonally adjusted monthly mean\" = \"cornflowerblue\", \"STL seasonality\" = \"seagreen\", \"STL trend\" = \"red\"), breaks = c(\"Monthly mean\", \"Seasonally adjusted monthly mean\", \"STL seasonality\", \"STL trend\")) +\n  theme_bw() +\n  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nOur plot for phosphorus further supports the idea that there is a slight downward trend over the decade. If you independently trace the maximums or minimums, the line does seem to be moving downward at an oscillating but fairly consistent rate. Unlike nitrogen, phosphorus concentrations shoot up in the middle of the year around May, have a relatively flat peak lasting from June to August, and then shoot down at the end of Summer.\n\n\nSimple linear regressions based on STL model parameters\n\nCode\n# Run regression of season component on monthly average nitrogen\nnitr_season_reg &lt;- lm(monthly_avg ~ season_year, data = nitr_decomp)\n\n# Print the formatted regression table\nstargazer(nitr_season_reg, title = \"Regression of monthly nitrogen concentration against seasonal trend component\", align = TRUE, digits = 3, type = 'html', notes.append = FALSE, notes = \"[***]p&lt;0.01\")\n\n\n\n\nRegression of monthly nitrogen concentration against seasonal trend component\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nmonthly_avg\n\n\n\n\n\n\n\n\nseason_year\n\n\n1.038***\n\n\n\n\n\n\n(0.086)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.898***\n\n\n\n\n\n\n(0.010)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n120\n\n\n\n\nR2\n\n\n0.551\n\n\n\n\nAdjusted R2\n\n\n0.547\n\n\n\n\nResidual Std. Error\n\n\n0.113 (df = 118)\n\n\n\n\nF Statistic\n\n\n144.981*** (df = 1; 118)\n\n\n\n\n\n\n\n\nNote:\n\n\n[***]p&lt;0.01\n\n\n\n\nThe adjusted R-squared of 0.55 indicates that seasonal trends can explain a bit over half (55%) of the variation in nitrogen monthly mean.\n\nCode\n# Run regression of season component on monthly average phosphorus\nphos_season_reg &lt;- lm(monthly_avg ~ season_year, data = phos_decomp)\n\n# Print the formatted regression table\nstargazer(phos_season_reg, title = \"Regression of monthly phosphorus concentration against seasonal trend component\", align = TRUE, digits = 3, type = 'html', notes.append = FALSE, notes = \"[***]p&lt;0.01\")\n\n\n\n\nRegression of monthly phosphorus concentration against seasonal trend component\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nmonthly_avg\n\n\n\n\n\n\n\n\nseason_year\n\n\n0.984***\n\n\n\n\n\n\n(0.051)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.057***\n\n\n\n\n\n\n(0.001)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n120\n\n\n\n\nR2\n\n\n0.759\n\n\n\n\nAdjusted R2\n\n\n0.757\n\n\n\n\nResidual Std. Error\n\n\n0.006 (df = 118)\n\n\n\n\nF Statistic\n\n\n371.062*** (df = 1; 118)\n\n\n\n\n\n\n\n\nNote:\n\n\n[***]p&lt;0.01\n\n\n\n\nFor phosphorus, adjusted R-squared of this regression is 0.76, confirming our idea that seasonality is more pronounced with phosphorus.\n\nCode\n# Run regression of year-month on trend component for nitrogen\nnitr_trend_reg &lt;- lm(trend ~ yr_mo, data = nitr_decomp)\n\n# Print the formatted regression table\nstargazer(nitr_trend_reg, title = \"Regression of nitrogen non-seasonal trend component against year-month\", align = TRUE, digits = 3, type = 'html', notes.append = FALSE, notes = \"[***]p&lt;0.01\")\n\n\n\n\nRegression of nitrogen non-seasonal trend component against year-month\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ntrend\n\n\n\n\n\n\n\n\nyr_mo\n\n\n-0.00001***\n\n\n\n\n\n\n(0.00000)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n1.121***\n\n\n\n\n\n\n(0.079)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n120\n\n\n\n\nR2\n\n\n0.065\n\n\n\n\nAdjusted R2\n\n\n0.057\n\n\n\n\nResidual Std. Error\n\n\n0.055 (df = 118)\n\n\n\n\nF Statistic\n\n\n8.176*** (df = 1; 118)\n\n\n\n\n\n\n\n\nNote:\n\n\n[***]p&lt;0.01\n\n\n\n\n\n\nCode\n# Compute the confidence interval for the coefficient of yr_mo\n# Multiply by 120 to estimate 10-year change in trend component\nnitr_trend_10_yr &lt;- 120 * confint(nitr_trend_reg, \"yr_mo\")\ncat('95% confidence interval for 10-year change in nitrogen non-seasonal trend component:',\n    '\\n[',\n    sprintf(\"%.4f\", nitr_trend_10_yr[1]),\n    ',',\n    sprintf(\"%.4f\", nitr_trend_10_yr[2]),\n    ']')\n\n\n95% confidence interval for 10-year change in nitrogen non-seasonal trend component: \n[ -0.0028 , -0.0005 ]\n\n\n\n\nCode\n# Convert to percent change since January 2010 observation\nnitr_percent_trend_10_yr &lt;- (nitr_trend_10_yr / nitr_decomp$trend[1]) * 100\ncat('95% confidence interval for 10-year percent change in nitrogen non-seasonal trend component:',\n    '\\n[',\n    sprintf(\"%.2f\", nitr_percent_trend_10_yr[1]),\n    ',',\n    sprintf(\"%.2f\", nitr_percent_trend_10_yr[2]),\n    ']')\n\n\n95% confidence interval for 10-year percent change in nitrogen non-seasonal trend component: \n[ -0.28 , -0.05 ]\n\n\nIn this linear regression, we look at the influence of year-month on our non-seasonal trend component for nitrogen. The regression output tells us that we can say at an alpha equals 0.01 significance level that the 10-year change in non-seasonal trend component was negative. However, the low adjusted R-squared also tells us that variation in year-month explains very little of the variation in trend component. Then, the first interval tells us that there is a 95% chance that the interval from -0.0028 mg/L to -0.0005 mg/L contains the true 10-year change in non-seasonal trend component. The second interval is telling us that this represents a -0.28% to -0.05% change as compared to the non-seasonal trend component in January 2010.\n\nCode\n# Run regression of year-month on trend component for phosphorus\nphos_trend_reg &lt;- lm(trend ~ yr_mo, data = phos_decomp)\n\n# Print the formatted regression table\nstargazer(phos_trend_reg, title = \"Regression of phosphorus non-seasonal trend component against year-month\", align = TRUE, digits = 3, type = 'html', notes.append = FALSE, notes = \"[***]p&lt;0.01\")\n\n\n\n\nRegression of phosphorus non-seasonal trend component against year-month\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ntrend\n\n\n\n\n\n\n\n\nyr_mo\n\n\n-0.00000***\n\n\n\n\n\n\n(0.00000)\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.092***\n\n\n\n\n\n\n(0.003)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n120\n\n\n\n\nR2\n\n\n0.565\n\n\n\n\nAdjusted R2\n\n\n0.561\n\n\n\n\nResidual Std. Error\n\n\n0.002 (df = 118)\n\n\n\n\nF Statistic\n\n\n153.180*** (df = 1; 118)\n\n\n\n\n\n\n\n\nNote:\n\n\n[***]p&lt;0.01\n\n\n\n\n\n\nCode\n# Compute the confidence interval for the coefficient of yr_mo\n# Multiply by 120 to estimate 10-year change in trend component\nphos_trend_10_yr &lt;- 120 * confint(phos_trend_reg, \"yr_mo\")\ncat('95% confidence interval for 10-year change in phosphorus non-seasonal trend component:',\n    '\\n[',\n    sprintf(\"%.5f\", phos_trend_10_yr[1]),\n    ',',\n    sprintf(\"%.5f\", phos_trend_10_yr[2]),\n    ']')\n\n\n95% confidence interval for 10-year change in phosphorus non-seasonal trend component: \n[ -0.00030 , -0.00022 ]\n\n\n\n\nCode\n# Convert to percent change since January 2010 observation\nphos_percent_trend_10_yr &lt;- (phos_trend_10_yr / phos_decomp$trend[1]) * 100\ncat('95% confidence interval for 10-year percent change in phosphorus non-seasonal trend component:',\n    '\\n[',\n    sprintf(\"%.2f\", phos_percent_trend_10_yr[1]),\n    ',',\n    sprintf(\"%.2f\", phos_percent_trend_10_yr[2]),\n    ']')\n\n\n95% confidence interval for 10-year percent change in phosphorus non-seasonal trend component: \n[ -0.52 , -0.38 ]\n\n\nFor phosphorus, the linear regression output tells us that we are confident at the alpha equals 0.01 level that the 10-year change in non-seasonal trend component was negative. It is also worth noting that the adjusted R-squared tells us that over half (56%) of the the variation in trend component can be explained by variation in year-month. Lastly, we find that there is a 95% chance that the interval between -0.00030 mg/L and -0.00022 mg/L contains the true 10-year change in non-seasonal trend component. This represents a -0.52% to -0.38% change as compared to the non-seasonal trend component in January 2010."
  },
  {
    "objectID": "blog/2023-12-12-post/index.html#conclusion",
    "href": "blog/2023-12-12-post/index.html#conclusion",
    "title": "2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions",
    "section": "Conclusion",
    "text": "Conclusion\nMy time series analysis suggests that seasonality plays a substantial role in contributing to variation in the monthly mean concentration of nitrogen and phosphorus in tidal regions of the Chesapeake Bay. For nitrogen, seasonal trends explained 55% of the variation in monthly means, and the relationship was even stronger for phosphorus, with seasonal trends explaining 76% of the variation. While the seasonal component for nitrogen was highest during Winter, the seasonal component for phosphorus was highest during Summer.\nThis analysis was also interested in any non-seasonal trend that has occurred since the introduction of TMDL requirements in 2010. For both nitrogen and phosphorus, we find evidence at an alpha level of 0.01 that the 10-year change in non-seasonal trend is negative. However, our confidence intervals suggest that, for both nutrient pollutants, these changes in trend represent a less than 1% decrease in concentration over the decade. It was also notable how the non-seasonal trend was much more consistent for phosphorus than nitrogen. This can be seen in our STL visualization and is also reflected by the larger adjusted R-squared for phosphorus (0.56) compared to nitrogen (0.06) computed in the linear regression of non-seasonal trend component against year-month.\nThe main limitation of this analysis was that no form of spatial interpolation was employed to estimate concentrations across the tidal region based on the location of measurements. It would be interesting to compare such an analysis to what we did here, as any significant differences would imply that sampled areas are not spread throughout the region in a representative manner. Further analysis might also investigate what happened at the beginning of 2014 that could have led to the high spike in nitrogen levels at that time, in addition to factors that might have fueled the increase seen over the course of 2018."
  },
  {
    "objectID": "blog/2023-12-11-post/mt-whitney-land-cover.html#read-in-data",
    "href": "blog/2023-12-11-post/mt-whitney-land-cover.html#read-in-data",
    "title": "Land cover analysis around Mount Whitney",
    "section": "1) Read in data",
    "text": "1) Read in data\n\nUSGS land cover raster dataset\nThe primary dataset that we will be working with comes from the 2011 National Terrestrial Ecosystems data, which was collected as part of the USGS Gap Analysis Project (GAP) by the U.S. Forest Service and Department of the Interior (U.S. Geological Survey 2016). For the purposes of this analysis, the full, nationwide dataset was pre-processed in Microsoft Planetary Computer to only include the area around Mount Whitney. With 30 meter by 30 meter pixel resolution, this raster dataset is a TIF file and contains numbers representing land cover classification.\n\n\nCode\nimport os\nimport xarray as xr\nimport rioxarray as rioxr\n\n# Import land cover TIF as xarray.DataArray\nlulc_fp = os.path.join(os.getcwd(),'..','..','data','2023-12-11-post-data','land_cover.tif')\nlulc = rioxr.open_rasterio(lulc_fp)\n\n\n\n\nUSGS land cover tabular dataset\nOur second dataset is also from the 2011 National Terrestrial Ecosystems data and helps us make sense of values in the raster dataset. This tabular dataset is a CSV file and has the land cover classification names associated with each code used in the raster dataset. This dataset was accessed from the same online source as the raster dataset (U.S. Geological Survey 2016).\n\n\nCode\nimport pandas as pd\n\n# Import accompanying CSV as pandas.DataFrame\nclass_names = pd.read_csv('../../data/2023-12-11-post-data/GAP_National_Terrestrial_Ecosystems.csv')\n\n\n\n\nShapefile of California geographic boundaries\nThe final dataset that we will be using is a shapefile of California geographic boundaries, included in the U.S. Census Bureau’s 2016 Topologically Integrated Geographic Encoding and Referencing (TIGER) database (California Open Data 2019). We will use this shapefile to plot our basemap when visualizing our area of analysis.\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\n\n# Import CA shapefile as geopandas.GeoDataFrame\nca = gpd.read_file('https://data.ca.gov/dataset/e212e397-1277-4df3-8c22-40721b095f33/resource/3db1e426-fb51-44f5-82d5-a54d7c6e188b/download/ca-state-boundary.zip')"
  },
  {
    "objectID": "blog/2023-12-13-post/index.html",
    "href": "blog/2023-12-13-post/index.html",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "",
    "text": "Marine aquaculture has the potential to be an important solution to meet the future demand for protein-rich food while simultaneously ensuring environmental sustainability (Costello et al. 2020). Increases in the demand for seafood have already resulted in an industry shift from wild fisheries to terrestrial aquaculture, with farmed seafood products currently making up about 50% of the global seafood supply. However, concerns about the sustainability of further expanding terrestrial aquaculture suggest that increasing the development of marine aquaculture farms might play a substantial role in a comprehensive solution.\nFurthermore, the U.S. West Coast represents an area where such marine aquaculture expansion could take place. In fact, the State of Washington currently leads the nation in marine aquaculture development. From 2005 to 2018, Washington generated over $200 million from these sea-based farms, about 40% of nationwide revenue during that same period (Froehlich et al. 2022).\nThis analysis seeks to build on knowledge regarding the potential for marine aquaculture expansion in the four Exclusive Economic Zones (EEZs) adjacent to the U.S. West Coast. Using raster data on mean sea surface temperature and depth, I’ll estimate the total and percent area within each of these four EEZs that would be suitable for oyster aquaculture. After visualizing oyster suitability, I’ll create a generalized model that can be used for any species based on their ideal temperature and depth ranges."
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#purpose",
    "href": "blog/2023-12-13-post/index.html#purpose",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Purpose",
    "text": "Purpose\nMarine aquaculture has the potential to be an important solution to meet the future demand for protein-rich food while simultaneously ensuring environmental sustainability (Costello et al. 2020). Increases in the demand for seafood have already resulted in an industry shift from wild fisheries to terrestrial aquaculture, with farmed seafood products currently making up about 50% of the global seafood supply. However, concerns about the sustainability of further expanding terrestrial aquaculture suggest that increasing the development of marine aquaculture farms might play a substantial role in a comprehensive solution.\nFurthermore, the U.S. West Coast represents an area where such marine aquaculture expansion could take place. In fact, the State of Washington currently leads the nation in marine aquaculture development. From 2005 to 2018, Washington generated over $200 million from these sea-based farms, about 40% of nationwide revenue during that same period (Froehlich et al. 2022).\nThis analysis seeks to build on knowledge regarding the potential for marine aquaculture expansion in the four Exclusive Economic Zones (EEZs) adjacent to the U.S. West Coast. Using raster data on mean sea surface temperature and depth, I’ll estimate the total and percent area within each of these four EEZs that would be suitable for oyster aquaculture. After visualizing oyster suitability, I’ll create a generalized model that can be used for any species based on their ideal temperature and depth ranges."
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#load-required-r-packages",
    "href": "blog/2023-12-13-post/index.html#load-required-r-packages",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Load required R packages",
    "text": "Load required R packages\n\n\nCode\n# Load required packages\nlibrary(sf)\nlibrary(terra)\nlibrary(here)\nlibrary(dplyr)\nlibrary(raster)\nlibrary(tmap)\nlibrary(spData)"
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#read-in-data",
    "href": "blog/2023-12-13-post/index.html#read-in-data",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Read in data",
    "text": "Read in data\n\n2008-2012 global sea surface temperature TIFs (1 km grid cells)\nFor temperature, we will use a stacked 1 km by 1 km gridded raster with data collected by the National Oceanic and Atmospheric Association (National Oceanic and Atmospheric Association (NOAA) 2018). There are a total of five layers, one for each year from 2008 through 2012. The values in each grid cell correspond to the area’s mean sea surface temperature for that year.\n\n\nCode\n# Store list of SST tif files\nsst_files &lt;- list.files(here(\"data/2023-12-13-post-data\"), pattern = \"\\\\d\\\\.tif$\", full.names = TRUE)\n\n# Store first raster to use as reference raster\nreference_raster &lt;- raster(sst_files[1])\n\n# Create an empty list\nsst_processed &lt;- list()\n\n# Loop through each raster file\nfor (file in sst_files) {\n  # Read the raster\n  r &lt;- raster(file)\n  # Resample the raster using the reference raster\n  r_resampled &lt;- resample(r, reference_raster)\n  # Crop the raster using the extent of reference raster\n  r_cropped &lt;- crop(r_resampled, extent(reference_raster))\n  # Add the processed raster to the list\n  sst_processed[[file]] &lt;- r_cropped\n}\n\n# Stack the processed rasters\nsst_stacked &lt;- stack(sst_processed)\n\n# Create new SST raster for mean SST from 2008 to 2012\nmean_sst &lt;- mean(sst_stacked, na.rm = TRUE)\n\n# Convert SST data from Kelvin to Celsius\nmean_sst &lt;- mean_sst - 273.15\n\n\n\n\n2022 global Bathymetry TIF (1 meter grid cells)\nThe bathymetry raster that we will be using characterizes ocean depth at a spatial resolution of 1 meter grid cells. We get this data from the General Bathymetric Chart of the Oceans (General Bathymetric Chart of the Oceans (GEBCO) 2023).\n\n\nCode\n# Load bathymetry raster\ndepth &lt;- raster(here(\"data/2023-12-13-post-data/depth.tif\"))\n\n# Resample the depth data to match the resolution of SST data\ndepth &lt;- resample(depth, mean_sst, method = \"ngb\")\n\n\n\n\nShapefile for West Coast EEZs\nThis data comes from Marine Regions, which is managed by the Flanders Marine Institute (Marine Regions, n.d.).\n\n\nCode\n# Load shapefile for West Coast EEZ\neez &lt;- st_read(here(\"data/2023-12-13-post-data/wc_regions_clean.shp\"))\n\n\nReading layer `wc_regions_clean' from data source \n  `/Users/linusghanadan/Documents/MEDS/other/linusghanadan.github.io/data/2023-12-13-post-data/wc_regions_clean.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -129.1635 ymin: 30.542 xmax: -117.097 ymax: 49.00031\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#process-data",
    "href": "blog/2023-12-13-post/index.html#process-data",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Process data",
    "text": "Process data"
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#oyster-suitability-analysis",
    "href": "blog/2023-12-13-post/index.html#oyster-suitability-analysis",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Oyster suitability analysis",
    "text": "Oyster suitability analysis\nNow that we have processed the data, we can move on to figuring out where oyster aquaculture is suitable in West Coast EEZs. Oysters generally reside in waters with a sea surface temperature of 11 to 30 degrees Celsius and at a depth of 0 to 70 meters below sea level (Froese and Pauly 2023). Thus, we will use these ranges to build a suitability raster and then crop to only include areas in West Coast EEZs.\n\nCreate and crop suitability mask\n\n\nCode\n# Make binary raster with values of 1 where SST is 11-30 degrees Celsius (otherwise NA)\nrcl = matrix(c(-Inf, 11, NA,\n                 11, 30, 1, \n                 30, Inf, NA), ncol = 3, byrow = TRUE)\nsst_binary &lt;- reclassify(mean_sst, rcl = rcl)\n\n# Make binary raster with values of 1 where depth is 0-70 meters below sea level (otherwise NA)\nrcl = matrix(c(-Inf, 0, NA,\n                 0, 70, 1, \n                 70, Inf, NA), ncol = 3, byrow = TRUE)\ndepth_binary &lt;- reclassify(depth, rcl = rcl)\n\n\n# Multiply cell values in both binary rasters to create mask raster of suitable locations for oysters \noyster_mask &lt;- overlay(sst_binary, depth_binary, fun = '*')\n\n# Crop mask based on EEZ data\noyster_mask &lt;- crop(oyster_mask, eez)\n\n\n\n\nCreate cell areas raster and EEZ raster\nNext, we calculate the total number of cells that are suitable. In this case, this is equivalent to the cell areas in meters squared, as the grid cell resolution is one meter by one meter. We also convert the cell areas data and EEZ area data to raster form, so we can perform our calculation in the next step.\n\n\nCode\n# Calculate total number of cells that are suitable\ncell_areas &lt;- cellStats(oyster_mask, stat = \"sum\", na.rm = TRUE)\n\n# Create raster for cell areas and populate\ncell_areas_raster &lt;- raster(oyster_mask)\ncell_areas_raster[] &lt;- cell_areas\n\n# Convert EEZ data to raster\neez_raster &lt;- rasterize(eez, oyster_mask)\n\n\n\n\nCalculate total and percent suitable area for each EEZ\nTo calculate total and percent suitable area for each EEZ, we use the zonal() function from the raster package in R. This function allows us to calculate the sum of suitable grid cells within each EEZ, as our EEZ raster labels each grid cell as part of one of the five West Coast EEZs.\n\n\nCode\n# Calculate total suitable area within each EEZ\ntotal_suitable_area &lt;- raster::zonal(cell_areas_raster, eez_raster, fun = sum, na.rm = TRUE)\n\n# Calculate percentage of suitable area within each EEZ\npercent_suitable_area &lt;- (total_suitable_area / eez$area_m2) * 100\n\n\n\n\nVisualize results\n\n\nCode\n# Bind EEZ data with total area and percent calculations\neez_joined &lt;- cbind(eez, total_suitable_area, percent_suitable_area) %&gt;%\n  mutate(\"Suitable area (km^2)\" = value / 1000000) %&gt;%\n  mutate(\"Percent suitable\" = value.1) %&gt;% \n  dplyr::select(-value, -value.1, -zone, -zone.1)\n\n# Store polygons for U.S. West Coast States from spData package\nCA &lt;- us_states %&gt;%\n  filter(NAME == \"California\")\nOR &lt;- us_states %&gt;%\n  filter(NAME == \"Oregon\")\nWA &lt;- us_states %&gt;%\n  filter(NAME == \"Washington\")\n\n# Initialize new bbox using EEZ bbox\nbbox_new &lt;- st_bbox(eez)\n\n# Create variable for x range of bbox\nxrange &lt;- bbox_new$xmax - bbox_new$xmin\n\n# Set new x range for bbox\nbbox_new[3] &lt;- bbox_new[3] + (0.9 * xrange)\n\n# Convert bbox to sfc\nbbox_new &lt;- bbox_new %&gt;%\n  st_as_sfc()\n\n# Create plot of total suitable area for oysters in U.S. West Coast EEZs\ntotal_area_map &lt;- \n  tm_shape(eez_joined, bbox = bbox_new) +\n  tm_fill(\"Suitable area (km^2)\", palette=\"Reds\", style = \"equal\", n=6) +\n  tm_borders() +\n  tm_shape(CA) +\n  tm_borders() +\n  tm_shape(OR) +\n  tm_borders() +\n  tm_shape(WA) +\n  tm_borders() +\n  tm_compass(position = c(\"left\", \"bottom\")) +\n  tm_scale_bar(position = c(\"left\", \"bottom\")) +\n  tm_layout(title = \"Suitable area for oyster aquaculture\") +\n  tm_layout(legend.position = c(\"right\", \"center\")) +\n  tm_layout(inner.margins = 0.15)\n\n# Create plot of percent suitable area for oysters in U.S. West Coast EEZs\ntmap_mode(\"plot\")\npercent_area_map &lt;- \n  tm_shape(eez_joined, bbox = bbox_new) +\n  tm_fill(\"Percent suitable\", palette=\"BuPu\", style = \"equal\", n=6) +\n  tm_borders() +\n  tm_shape(CA) +\n  tm_borders() +\n  tm_shape(OR) +\n  tm_borders() +\n  tm_shape(WA) +\n  tm_borders() +\n  tm_compass(position = c(\"left\", \"bottom\")) +\n  tm_scale_bar(position = c(\"left\", \"bottom\")) +\n  tm_layout(title = \"Suitable area for oyster aquaculture\") +\n  tm_layout(legend.position = c(\"right\", \"center\")) +\n  tm_layout(inner.margins = 0.15)\ntmap_mode(\"plot\")\ntmap_arrange(total_area_map, percent_area_map)"
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#generalized-suitability-model",
    "href": "blog/2023-12-13-post/index.html#generalized-suitability-model",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Generalized suitability model",
    "text": "Generalized suitability model\nNow that we have performed a suitability analysis for oysters in West Coast EEZs, we can broaden our workflow by building a function that provides us the same type of data visualizations for any species based on inputs of desired range for sea surface temperature and depth. We will first build our function and then test it out using suitability parameters for the Common carp.\n\nBuild function\n\n\nCode\n# Reproducible workflow function for any species\nsuitable_aqua &lt;- function(species, tempmin, tempmax, depthmin, depthmax) {\n  rcl_fun &lt;- matrix(c(-Inf, tempmin, NA,\n                  tempmin, tempmax, 1,\n                  tempmax, Inf, NA), ncol = 3, byrow = TRUE)\n  sst_binary_fun &lt;- reclassify(mean_sst, rcl = rcl_fun)\n  rcl_fun = matrix(c(-Inf, depthmin, NA,\n                 depthmin, depthmax, 1, \n                 depthmax, Inf, NA), ncol = 3, byrow = TRUE)\n  depth_binary_fun &lt;- reclassify(depth, rcl = rcl_fun)\n  raster_mask_fun &lt;- overlay(sst_binary_fun, depth_binary_fun, fun = '*')\n  raster_mask_fun &lt;- crop(raster_mask_fun, eez)\n  if (all(unique(raster_mask_fun) %in% c(1, NA))) {\n  } else {stop(\"Error in code. Mask contains values other than 1 or NA.\")}\n  cell_areas_fun &lt;- cellStats(raster_mask_fun, stat = \"sum\", na.rm = TRUE)\n  cell_areas_raster_fun &lt;- raster(raster_mask_fun)\n  cell_areas_raster_fun[] &lt;- cell_areas_fun\n  eez_raster_fun &lt;- rasterize(eez, raster_mask_fun)\n  total_suitable_area_fun &lt;- zonal(cell_areas_raster_fun, eez_raster_fun, fun = sum, na.rm = TRUE)\n  percent_suitable_area_fun &lt;- (total_suitable_area_fun / eez$area_m2) * 100\n  eez_joined_fun &lt;- cbind(eez, total_suitable_area_fun, percent_suitable_area_fun) %&gt;%\n    mutate(\"Suitable area (km^2)\" = value / 1000000) %&gt;%\n    mutate(\"Percent suitable\" = value.1) %&gt;% \n    dplyr::select(-value, -value.1, -zone, -zone.1)\n  if (any(eez_joined_fun$`Percent suitable` &lt; 0 | eez_joined_fun$`Percent suitable` &gt; 100)) {\n    stop(\"Error in code. At least one percent area is not between 0 and 100.\")\n  } else {}\n  CA &lt;- us_states %&gt;%\n    filter(NAME == \"California\")\n  OR &lt;- us_states %&gt;%\n    filter(NAME == \"Oregon\")\n  WA &lt;- us_states %&gt;%\n    filter(NAME == \"Washington\")\n  bbox_new_fun &lt;- st_bbox(eez)\n  xrange_fun &lt;- bbox_new_fun$xmax - bbox_new_fun$xmin\n  bbox_new_fun[3] &lt;- bbox_new_fun[3] + (0.9 * xrange_fun)\n  bbox_new_fun &lt;- bbox_new_fun %&gt;%\n    st_as_sfc()\n  total_area_map_fun &lt;-\n    tm_shape(eez_joined_fun, bbox = bbox_new_fun) +\n    tm_fill(\"Suitable area (km^2)\", palette=\"Reds\", style = \"equal\", n=6) +\n    tm_borders() +\n    tm_shape(CA) +\n    tm_borders() +\n    tm_shape(OR) +\n    tm_borders() +\n    tm_shape(WA) +\n    tm_borders() +\n    tm_compass(position = c(\"left\", \"bottom\")) +\n    tm_scale_bar(position = c(\"left\", \"bottom\")) +\n    tm_layout(title = paste(\"Suitable area for\", species,\"aquaculture\")) +\n    tm_layout(legend.position = c(\"right\", \"center\")) +\n    tm_layout(inner.margins = 0.15)\n  percent_area_map_fun &lt;- \n    tm_shape(eez_joined_fun, bbox = bbox_new_fun) +\n    tm_fill(\"Percent suitable\", palette=\"BuPu\", style = \"equal\", n=6) +\n    tm_borders() +\n    tm_shape(CA) +\n    tm_borders() +\n    tm_shape(OR) +\n    tm_borders() +\n    tm_shape(WA) +\n    tm_borders() +\n    tm_compass(position = c(\"left\", \"bottom\")) +\n    tm_scale_bar(position = c(\"left\", \"bottom\")) +\n    tm_layout(title = paste(\"Suitable area for\", species,\"aquaculture\")) +\n    tm_layout(legend.position = c(\"right\", \"center\")) +\n    tm_layout(inner.margins = 0.15)\n  return(tmap_arrange(total_area_map_fun, percent_area_map_fun))}\n\n\n\n\nUse function to analyze suitable area for Common carp\nCompared to oysters, the Common carp can handle slightly more extreme temperatures (3 to 35 degrees Celsius) (Froese and Pauly 2023). However, unlike oysters who thrive in depths of up to 70 meters below sea level, the Common carp can only handle up to 29 meters. We can apply our generalized function to see what this means in term of how suitability differs for the Common carp.\n\n\nCode\n# Run function for Common carp species\nsuitable_aqua(\"Common carp\", tempmin=3, tempmax=35, depthmin=0, depthmax=29)\n\n\n\n\n\nThe two maps are very similar in terms of how the different EEZs compare to each other, but a closer inspection of the legend values does show us that the Common carp has a consistently higher amount of suitable area. Hence, the larger temperature range was more important for suitability than the narrower depth range."
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#conclusions",
    "href": "blog/2023-12-13-post/index.html#conclusions",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Conclusions",
    "text": "Conclusions"
  },
  {
    "objectID": "blog/2023-12-12-post/index.html#exploratory-analysis",
    "href": "blog/2023-12-12-post/index.html#exploratory-analysis",
    "title": "2010-2019 time series analysis of nutrient concentration in Chesapeake Bay tidal regions",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\nTo get an idea of what is going on with the data, we’ll first calculate moving averages for each year-month, storing the resulting output as both a tsibble and data.frame. We’ll plot these moving averages just to get a general idea of what types of trends we might be looking at.\n\n\nCode\n# Compute nitrogen monthly moving average, and store as tsibble\nnitr_monthly_avgs_ts &lt;- nitr_data %&gt;% \n  mutate(yr_mo = tsibble::yearmonth(SampleDate)) %&gt;%\n  group_by(yr_mo) %&gt;%\n  summarize(monthly_avg = mean(MeasureValue, na.rm = TRUE)) %&gt;% \n  tsibble::as_tsibble()\n\n# Create data frame version, and convert year-months to Date class (helpful for plotting)\nnitr_monthly_avgs_df &lt;- as.data.frame(nitr_monthly_avgs_ts)\nnitr_monthly_avgs_df$yr_mo &lt;- as.Date(nitr_monthly_avgs_ts$yr_mo, format = \"%Y-%m\")\n\n# Plot monthly average nitrogen concentration as a function of year-month\nnitr_monthly_avgs_df %&gt;%\n  ggplot(aes(x = yr_mo, y = monthly_avg)) +\n  stat_summary(geom = 'line', fun = 'mean') +\n  labs(x = 'Year-Month', y = 'Monthly Mean Concentration (mg/L)', title = \"Nitrogen in Chesapeake Bay (2010-2019)\") +\n  scale_x_date(date_breaks = \"1 year\", date_minor_breaks = \"6 months\", date_labels = \"%Y-%m\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nFrom this plot, there does appear to be a seasonal trend for nitrogen concentrations, but there is no clear non-seasonal trend. In addition, there is a notable spike in early 2014.\n\n\nCode\n# Compute phosphorus monthly moving average, and store as tsibble\nphos_monthly_avgs_ts &lt;- phos_data %&gt;% \n  mutate(yr_mo = tsibble::yearmonth(SampleDate)) %&gt;%\n  group_by(yr_mo) %&gt;%\n  summarize(monthly_avg = mean(MeasureValue, na.rm = TRUE)) %&gt;% \n  tsibble::as_tsibble()\n\n# Create data frame version, and convert year-months to Date class (helpful for plotting)\nphos_monthly_avgs_df &lt;- as.data.frame(phos_monthly_avgs_ts)\nphos_monthly_avgs_df$yr_mo &lt;- as.Date(phos_monthly_avgs_ts$yr_mo, format = \"%Y-%m\")\n\n# Plot monthly average phosphorus concentration as a function of year-month\nphos_monthly_avgs_df %&gt;%\n  ggplot(aes(x = yr_mo, y = monthly_avg)) +\n  stat_summary(geom = 'line', fun = 'mean') +\n  labs(x = 'Year-Month', y = 'Monthly Mean Concentration (mg/L)', title = \"Phosphorus in Chesapeake Bay (2010-2019)\") +\n  scale_x_date(date_breaks = \"1 year\", date_minor_breaks = \"6 months\", date_labels = \"%Y-%m\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nSimilar to the nitrogen plot, phosphorus also seems to exhibit a distinct seasonal trend. Again, it is unclear whether there is a non-seasonal trend."
  },
  {
    "objectID": "blog/2023-12-13-post/index.html#conclusion",
    "href": "blog/2023-12-13-post/index.html#conclusion",
    "title": "Reproducible workflow to gauge suitability of species for U.S. West Coast marine aquaculture",
    "section": "Conclusion",
    "text": "Conclusion\nThe main takeaway from this analysis is that we were able to build a model that helps us better understand which West Coast EEZs are best suited for marine aquaculture of certain species based on ideal ranges for sea surface temperature and depth. To demonstrate how this model could be used, this analysis looked at suitability for oysters and the Common carp. Specifically, our comparison showed that having a larger temperature range (3-35 degrees Celsius for carp compared to 11-30 degrees Celsius for oysters) was more important for suitability than having a narrower depth range (0-29 meters for carp compared to 0-70 meters for oysters).\nThis being said, there are certainly limitations in using our model. For one, using a sea surface temperature raster with finer resolution would give us more precise estimates. In addition, this analysis did not look at where marine aquaculture currently exists on the West Coast. This model could be improved upon by subtracting areas that are already being used for marine aquaculture. Lastly, a more robust model would look at more variables than just sea surface temperature and depth. Further analysis might include additional water variables with conditional ranges for different species, such as degree hardness (dH) and potential of hydrogen (pH)."
  },
  {
    "objectID": "blog/2024-3-12-post/index.html",
    "href": "blog/2024-3-12-post/index.html",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "",
    "text": "Infographic on anthropogenic methane emissions in 2021"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#purpose",
    "href": "blog/2024-3-12-post/index.html#purpose",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Purpose",
    "text": "Purpose\nIn my infographic, the overarching question that I will be answering is where anthropogenic methane emissions came from in 2021. This includes the countries where emissions are occurring most frequently and also the human activities (e.g., energy production, agriculture, etc.) that contribute the most to these emissions."
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#data",
    "href": "blog/2024-3-12-post/index.html#data",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Data",
    "text": "Data\nThe data set that I will use comes from the International Energy Agency (IEA), a Paris-based intergovernmental organization with 31 member countries and 13 association countries. The group was created following the 1973 oil crisis by the Organisation for Economic Co-operation and Development (OECD) to oversee and collect data on global energy markets. In the last decade, the group has increasingly played an important role in guiding and advocating for an accelerated global energy transition away from fossil fuels (International Energy Agency (IEA) 2024).\nSince 2020, the IEA has published yearly data estimating global methane emissions at a country-level. For methane emissions resulting from oil and gas processes (upstream and downstream), these figures are calculated using a combination of measurement data (mostly from satellite readings) and activity data on the specific actions being taken that release vented, fugitive, or incomplete-flare emissions. Coal mine methane emissions are estimated primarily by looking at the ash content of coal produced in different countries, mine depth, and regulatory oversight. Furthermore, estimating country-level emissions from agriculture and waste mainly relies only satellite technology. Lastly, other methane sources are estimated using manufacturing data and the emissions factors associated with the industrial processes carried out in that country (International Energy Agency (IEA) 2022b).\nI will be using the 2022 data set, which provides emissions estimates for the year 2021 (International Energy Agency (IEA) 2022a). Anyone can access this data set for free after making an account on the IEA website.\nIn addition to the methane data set, I also want data on 2021 population values of different countries for computing emissions per capita, so I downloaded a free data set from the World Bank website, which did not require me to have any sort of account (The World Bank, n.d.)."
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#setup-data-import",
    "href": "blog/2024-3-12-post/index.html#setup-data-import",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Setup & data import",
    "text": "Setup & data import\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                setup                                     ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# load packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(treemapify)\nlibrary(showtext)\n\n# import fonts\nfont_add_google(name = \"Merriweather Sans\", family = \"merri sans\")\nfont_add_google(name = \"Barlow Condensed\", regular.wt = 200, family = \"barlow\")\n\n# enable {showtext} for rendering\nshowtext_auto()\n\n# set scipen option to a high value to avoid scientific notation\noptions(scipen = 999)\n\n\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                                import data                               ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# read in methane data\nmethane_df &lt;- readr::read_csv(here(\"data\", \"2024-3-12-post-data\", \"IEA-MethaneEmissionsComparison-World.csv\")) %&gt;% \n  janitor::clean_names() %&gt;% # convert column names to lower_case_snake format\n  select('country', 'emissions', 'type') # select relevant columns\n\n# read in population data\npop_df &lt;- readr::read_csv(here(\"data\", \"2024-3-12-post-data\", \"worldbank_pop.csv\")) %&gt;% \n  janitor::clean_names() %&gt;%\n  rename('population' = 'x2021', # rename column with 2022 populations to 'population'\n         'country' = 'country_name') %&gt;% # rename columns with countries (for joining)\n  select('country', 'population') # select these two columns"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#general-data-wrangling",
    "href": "blog/2024-3-12-post/index.html#general-data-wrangling",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "General data wrangling",
    "text": "General data wrangling\nTo start, I have some general data wrangling steps that allowed me to explore the data and calculate some of the statistics that I ended up including in my infographic. In the code chunk below, I’m storing the world-level rows in the IEA data set as their own data frame, and reconfiguring the data frame to find the percent of total global emissions coming from each of the four sectors, which I ended up including in the legend of my first plot.\n\n\nCode\n# store observations regarding entire world as its own df\nworld_df &lt;- methane_df %&gt;%\n  filter(is.na(country)) %&gt;% \n  group_by(country, type) %&gt;% # group by input variables ('type' must be last to combine observations in next line)\n  summarize(total_emissions = sum(emissions, na.rm = TRUE)) %&gt;% # create summary df that combines observations with same 'type'\n  ungroup() %&gt;% \n  pivot_wider(names_from = type, values_from = total_emissions) %&gt;% # create new columns named based on 'type' and containing values from 'total_emissions'\n  janitor::clean_names() %&gt;%\n  mutate(total_emissions = agriculture + energy + waste + other) %&gt;% # re-create 'total_emissions' column\n  select(-country)\n\n# calculate percents of 'total_emissions' coming from each type of emissions (to be put in legend of treemap)\nworld_df$agriculture / world_df$total_emissions\n\n\n[1] 0.2902036\n\n\nCode\nworld_df$energy / world_df$total_emissions\n\n\n[1] 0.545233\n\n\nCode\nworld_df$waste / world_df$total_emissions\n\n\n[1] 0.1446558\n\n\nCode\nworld_df$other / world_df$total_emissions\n\n\n[1] 0.01990765\n\n\nI also perform some general data wrangling on my methane data frame, which will be important moving forward. After removing the world-level rows that I subsetted in the previous code chunk, I’m doing a ‘group_by’ command followed by a ‘summarize’ command to combine observations that are of the same type. Before doing this, there were multiple observations for energy emissions, breaking down into further levels of granularity based on other columns that are not selected here. I’m also combining all countries that are part of the European Union by changing their country names to the same string and then again using the ‘group_by’ and ‘summarize’ commands to combine rows. Lastley, I decided to make a wide form of this same data frame, which will be helpful when we get to plot 2 of my infographic.\n\n\nCode\nmethane_df &lt;- methane_df %&gt;%\n  filter(!(is.na(country))) %&gt;% # remove observations regarding entire world\n  group_by(country, type) %&gt;% # group by input variables ('type' must be last to combine observations in next line)\n  summarize(total_emissions = sum(emissions, na.rm = TRUE)) %&gt;% # create summary df that combines observations with same 'type'\n  ungroup() %&gt;% \n  mutate(country = case_when(country == \"Other EU17 countries\" ~ \"EU*\", # reassign country names for countries in EU so we can combine these observations\n                             country == \"Other EU7 countries\" ~ \"EU*\",\n                             country == \"France\" ~ \"EU*\",\n                             country == \"Italy\" ~ \"EU*\",\n                             country == \"Germany\" ~ \"EU*\",\n                             country == \"Sweden\" ~ \"EU*\",\n                             country == \"Norway\" ~ \"EU*\",\n                             country == \"Poland\" ~ \"EU*\",\n                             country == \"Denmark\" ~ \"EU*\",\n                             country == \"Estonia\" ~ \"EU*\",\n                             country == \"Netherlands\" ~ \"EU*\",\n                             country == \"Slovenia\" ~ \"EU*\",\n                             country == \"Romania\" ~ \"EU*\",\n                             country == \"United States\" ~ \"U.S.\", # shorten United States to U.S.\n                             TRUE ~ country)) %&gt;%\n  group_by(type, country) %&gt;% # group by input variables ('country' must be last to combine observations in next line)\n  summarize(total_emissions = sum(total_emissions, na.rm = TRUE)) %&gt;% # combine observations\n  ungroup()\n\n# create wide version of methane_df so that there is one observation for each 'country' (to be used for next graph)\nwide_df &lt;- methane_df %&gt;%\n  filter(!(country == \"Other\")) %&gt;% # remove observations where 'country' is other\n  filter(!(country == \"Other countries in Europe\")) %&gt;% \n  filter(!(country == \"Other countries in Southeast Asia\")) %&gt;% \n  pivot_wider(names_from = type, values_from = total_emissions) %&gt;% # create new columns named based on 'type' and containing values from 'total_emissions'\n  janitor::clean_names() %&gt;% \n  mutate(energy = ifelse(is.na(energy), 0, energy)) %&gt;% # set NA in 'energy' column to 0 so that next line works\n  mutate(total_emissions = energy + agriculture + waste + other) %&gt;%  # re-create 'total_emissions' column\n  arrange(desc(total_emissions))"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#plot-1-vizualization",
    "href": "blog/2024-3-12-post/index.html#plot-1-vizualization",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Plot 1 vizualization",
    "text": "Plot 1 vizualization\nFor my first plot, I’ll start by making a treemap of how the four different categories (energy, agriculture, waste, and other) of methane emissions and the country that they are in contribute to total global emissions. To do this, I start by taking my methane data frame and making a version of it specifically for my treemap plot with altered names of countries (I didn’t like the way that they looked when they were included) and the types of emissions (adding the percents in that I calculated from my general data wrangling). I then re-level the factors so they appear in descending order, define a custom color palette that I built using the website Coolers, and finally I’m ready to make my actual plot.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          plot 1 visualization                            ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# rename countries to empty strings so that don't show up in plot\ntreemap_df &lt;- methane_df %&gt;%\n  mutate(country = case_when(country == \"Mexico\" ~ \"\",\n                             country == \"Algeria\" ~ \"\",\n                             country == \"Libya\" ~ \"\",\n                             country == \"Venezuela\" ~ \"\",\n                             country == \"Turkmenistan\" ~ \"\",\n                             country == \"Nigeria\" ~ \"\",\n                             country == \"Pakistan\" ~ \"\",\n                             country == \"Kazakhstan\" ~ \"\",\n                             country == \"Kuwait\" ~ \"\",\n                             country == \"Qatar\" ~ \"\",\n                             country == \"Indonesia\" ~ \"\",\n                             country == \"Other\" ~ \"\",\n                             TRUE ~ country)) %&gt;%\n  mutate(type = case_when(type == \"Agriculture\" ~ \"Agriculture\\n(29%)\", # rename types of emissions to include percents (for legend in plot)\n                          type == \"Energy\" ~ \"Energy\\n(55%)\",\n                          type == \"Waste\" ~ \"Waste\\n(14%)\",\n                          type == \"Other\" ~ \"Other\\n(2%)\",\n                          TRUE ~ type))\n\n# re-order sector factors (for legend in plot)\ntreemap_df &lt;- treemap_df %&gt;%\n   mutate(type = factor(type, levels = c(\"Energy\\n(55%)\", \"Agriculture\\n(29%)\", \"Waste\\n(14%)\", \"Other\\n(2%)\")))\n\n# define custom color palette\ncustom_colors &lt;- c(\n  \"Agriculture\\n(29%)\" = \"#D2B48C\",\n  \"Energy\\n(55%)\" = \"#2F2720\",\n  \"Waste\\n(14%)\" = \"#2ca02c\",\n  \"Other\\n(2%)\" = \"#2B4690\")\n\n# create treemap\nggplot(treemap_df, aes(area = total_emissions, fill = type, label = country, subgroup = type)) + # using sector ('type') for coloring and as subgroups (appear in legend), labeling based on country\n  geom_treemap(color = \"white\", size = 0.5) + # adjust color and size of lines separating rectangles\n  labs(x = \"Data Source: International Energy Agency (IEA)\\n\\n*The EU is a group of 27 countries in Europe.\") + # use x axis title for caption\n  geom_treemap_text(color = \"white\", place = \"center\", grow = TRUE, reflow = TRUE, family = \"barlow\", min.size = 12) + # for text inside the treemap, allow to grow with grow = TRUE, flow onto next line with reflow = TRUE, and set font family to barlow\n  scale_fill_manual(values = custom_colors) +  # apply custom color palette\n  labs(title = \"Sources of Anthropogenic Methane Emissions in 2021\") +\n  theme(axis.title.x = element_text(size = 8, hjust = 1, color = \"grey30\", family = \"merri sans\", margin = margin(20, 0, 0, 0)), # adjust font, fontface, size, and color of x axis title (use hjust = 1 to move to far right since this is caption)\n        legend.position = \"top\", # set legend to top\n        legend.title = element_blank(),\n        legend.text = element_text(size = 15, family = \"barrow\", face = \"bold\"), # set legend font to merri sans\n        legend.title.align = 0.5, # center legend\n        legend.spacing.x = unit(5, \"mm\"), # set space between legend keys\n        legend.background = element_rect(fill = \"#FEF6EC\", color = NA), # change legend background color\n        legend.key.size = unit(4, \"mm\"), # set legend key size\n        plot.title = element_text(family = \"merri sans\", size = 16, hjust = 0.5), # set title font to merri sans\n        plot.background = element_rect(fill = \"#FEF6EC\", color = NA), # change the plot background color\n        panel.background = element_rect(fill = \"#FEF6EC\", color = NA)) # change the panel background color to match"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#plot-2-visualization",
    "href": "blog/2024-3-12-post/index.html#plot-2-visualization",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Plot 2 visualization",
    "text": "Plot 2 visualization\nFor plot 2, I start by creating a new version of the wide-version of my methane data frame for the scatterplot that I will make. I start by changing the names of certain countries to match to the World Bank data set that I’m joining with. After I perform my join, I change the names back.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          joining data frames                             ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# change 'country' names to match population data set and store as new data frame\nscatter_df &lt;- wide_df %&gt;%\n  mutate(country = case_when(\n    country == \"Congo\" ~ \"Congo, Rep.\",\n    country == \"Democratic Republic of Congo\" ~ \"Congo, Dem. Rep.\",\n    country == \"Egypt\" ~ \"Egypt, Arab Rep.\",\n    country == \"Gambia\" ~ \"Gambia, The\",\n    country == \"Brunei\" ~ \"Brunei Darussalam\",\n    country == \"Korea\" ~ \"Korea, Rep.\",\n    country == \"Vietnam\" ~ \"Viet Nam\",\n    country == \"U.S.\" ~ \"United States\",\n    country == \"EU*\" ~ \"European Union\",\n    country == \"Venezuela\" ~ \"Venezuela, RB\",\n    country == \"Iran\" ~ \"Iran, Islamic Rep.\",\n    country == \"Syria\" ~ \"Syrian Arab Republic\",\n    country == \"Yemen\" ~ \"Yemen, Rep.\",\n    country == \"Russia\" ~ \"Russian Federation\",\n    TRUE ~ country))\n\n# join this data frame with pop_df\nscatter_df &lt;- left_join(x = scatter_df, y = pop_df, by = \"country\")\n\n# change 'country' names back to how they were\nscatter_df &lt;- scatter_df %&gt;%\n  mutate(country = case_when(\n    country == \"Congo, Rep.\" ~ \"Congo\",\n    country == \"Congo, Dem. Rep.\" ~ \"Democratic Republic of Congo\",\n    country == \"Egypt, Arab Rep.\" ~ \"Egypt\",\n    country == \"Gambia, The\" ~ \"Gambia\",\n    country == \"Brunei Darussalam\" ~ \"Brunei\",\n    country == \"Korea, Rep.\" ~ \"Korea\",\n    country == \"Viet Nam\" ~ \"Vietnam\",\n    country == \"United States\" ~ \"U.S.\",\n    country == \"European Union\" ~ \"EU*\",\n    country == \"Venezuela, RB\" ~ \"Venezuela\",\n    country == \"Iran, Islamic Rep.\" ~ \"Iran\",\n    country == \"Syrian Arab Republic\" ~ \"Syria\",\n    country == \"Yemen, Rep.\" ~ \"Yemen\",\n    country == \"Russian Federation\" ~ \"Russia\",\n    TRUE ~ country\n  ))\n\n\nNow that the join is complete and my country names are back to normal, I create a new column in my data frame for emissions per capita, which divides total emissions by population. I also multiply this new column by 1,000,000 to convert units from million tons to tons, which produces values that are easier to understand when talking about emissions per person.\nNext, I create a new data frame only containing six countries (China, U.S., Russia, Brazil, Canada, and Australia) and the European Union, as I want to focus on the emissions from these places in my infographic. I take the sum of their emissions and populations and compare that to global emissions and populations, and the resulting percent values will also be included on my infographic as text.\n\n\nCode\n# add 'emissions_pc' column and convert column units\nscatter_df &lt;- scatter_df %&gt;% \n  mutate(emissions_pc = (total_emissions / population) * 1000000) %&gt;% # create 'emissions_pc' column (in tons)\n  mutate(population = population / 1000000) %&gt;% # convert 'population' values from people to millions of people\n  arrange(desc(emissions_pc))\n\n# create new data frame with only the 7 countries of focus (including EU)\nmain_countries &lt;- scatter_df %&gt;%\n  filter(country %in% c(\"China\", \"U.S.\", \"Russia\", \"Brazil\", \"EU*\", \"Canada\", \"Australia\")) %&gt;% \n  arrange(desc(total_emissions))\n\n# add 'population' column to world_df\nworld_df &lt;- world_df %&gt;%\n  mutate(population = 7950946801) %&gt;% # found from row 260 in pop_df\n  mutate(population = population / 1000000) # convert 'population' values from people to millions of people\n\n# calculate the percents of global population and global emissions in countries of focus\nsum(main_countries$population, na.rm = TRUE) / sum(world_df$population, na.rm = TRUE)\n\n\n[1] 0.3287581\n\n\nCode\nsum(main_countries$total_emissions, na.rm = TRUE) / sum(world_df$total_emissions, na.rm = TRUE)\n\n\n[1] 0.4664618\n\n\nAt this point, I just need to get a few more data frames in order to make my scatterplot. I create four new data frames: one for all the countries that I’m not focusing on in my infographic, one for notable countries that I want to include (but not highlight) in my infographic for the sake of comparison, one for just Australia (so I can adjust its label on the plot), and one for the remaining countries of focus. Importantly, I also make a new column that I will use to set the alpha value, which moduates transparency in ggplot, of each point in my scatter plot. I want my countries of focus to not be transparent at all, and the rest of my points to be reasonably transparent. After this, its time to make the scatterplot.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          plot 2 visualization                            ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# create new data frame excluding the countries of focus\nother_countries &lt;- scatter_df %&gt;% \n  filter(!(country %in% c(\"China\", \"U.S.\", \"Russia\", \"Brazil\", \"EU*\", \"Canada\", \"Australia\")))\n\n# create new data frame with countries to label but not highlight (for context)\nother_notable_countries &lt;- other_countries %&gt;% \n  filter(country %in% c(\"India\", \"Indonesia\", \"Iran\", \"Mexico\", \"Congo\", \"Venezuela\", \"Bangladesh\"))\n\n# create new df for just Australia (so can adjust where label is on plot)\naustralia_df &lt;- scatter_df %&gt;% subset(country == \"Australia\")\n\n# create new df for highlighted countries minus Australia (so can plot separately)\nother_main_countries &lt;- main_countries %&gt;% filter(!(country == \"Australia\"))\n\n# add new column for alpha values to scatter_df\nscatter_df$alpha_value &lt;- ifelse(scatter_df$country %in% c(\"China\", \"U.S.\", \"Russia\", \"Brazil\", \"Australia\", \"Canada\", \"EU*\"), 1, 0.2) # only countries of focus have alpha of 1, all else 0.2\n\n# create scatterplot\nggplot(scatter_df) +\n  geom_point(aes(x = population, y = emissions_pc, alpha = alpha_value), color = \"#020122\") + # use alpha values from the column\n  scale_alpha_identity() + # tell ggplot to use the alpha values as given (without scaling)\n  geom_text(data = australia_df, # add text for Australia\n            aes(label = country, x = population - 5, y = emissions_pc + 15), # position text so does not overlap\n            size = 5, hjust = 0, family = \"barlow\", fontface = \"bold\", check_overlap = TRUE) + # adjust other text features\n  geom_text(data = other_main_countries, # add text for other main countries\n            aes(label = country, x = population + 15, y = emissions_pc), # position text\n            size = 5, hjust = 0, family = \"barlow\", fontface = \"bold\", check_overlap = TRUE) + # adjust other text features\n  geom_text(data = other_notable_countries, # add text for other countries to label\n            aes(label = country, x = population + 15, y = emissions_pc), # position text\n            alpha = 0.2, size = 5, hjust = 0, family = \"barlow\", fontface = \"bold\", check_overlap = TRUE) + # adjust other text features\n  labs(x = \"Population (millions)\",\n       y = \"Per Capita Methane Emissions (tons CO2eq)\", \n       title = \"Population and Per-Capita Anthropogenic Methane Emissions in 2021\",\n       caption = \"Note: 8 countries had per capita emissions &gt;350 tons CO2eq and are not displayed.\\nData Sources: International Energy Agency (IEA), World Bank\\n\\n*The EU is a group of 27 countries in Europe.\\n**Based on calculation from BBC News in 2021 article.⁵\") +\n  scale_x_continuous(limits = c(0, 1550), expand = c(0, 0)) + # set limits on min/max x axis values, use expand to tell to have where two axis meet as origin point\n  scale_y_continuous(limits = c(0, 350), expand = c(0, 0)) + # set limits on min/max y axis values, use expand to tell to have where two axis meet as origin point\n  theme_minimal() +\n  theme(panel.grid.major.x = element_blank(), panel.grid.minor = element_blank(),\n        axis.title.x = element_text(family = \"barlow\", face = \"bold\", size = 15, color = \"grey30\", # adjust text features for x axis title\n                                    margin = margin(20, 0, 0, 0)), # set margin\n        axis.title.y = element_text(family = \"barlow\", face = \"bold\", size = 15, color = \"grey30\", # adjust text features for y axis title\n                                    margin = margin(0, 20, 0, 0)), # set margin\n        panel.grid.major.y = element_line(color = \"grey90\", size = 0.5), # add horizontal gridlines (major)\n        panel.grid.minor.y = element_line(color = \"grey90\", size = 0.25), # add horizontal gridlines (minor)\n        axis.text.x = element_text(family = \"barlow\", face = \"bold\", size = 13), # adjust x axis text\n        axis.text.y = element_text(family = \"barlow\", face = \"bold\", size = 13), # adjust y axis text\n        axis.line = element_line(color = \"black\", size = 0.5), # adjust color and size of axis lines\n        plot.title = element_text(family = \"merri sans\", size = 12.5, hjust = 0.5), # adjust plot title text\n        plot.caption = element_text(hjust = 1, size = 8, color = \"grey30\", family = \"merri sans\", # adjust caption text\n                                    margin = margin(20, 0, 0, 0)), # set margin\n        plot.background = element_rect(fill = \"#FEF6EC\", color = NA), # set plot background\n        panel.background = element_rect(fill = \"#FEF6EC\", color = NA)) + # set panel background\n  geom_hline(yintercept = 197, linetype = \"dashed\", linewidth = 0.8, color = \"cornflowerblue\") + # add dashed horizontal line at y = 197\n  annotate(\"text\", x = 700, y = 240, # position text annotation\n           label = \"Carbon footprint of a typical\\nprivate jet flying for 48 hours**\",\n           size = 5, hjust = 0, color = \"cornflowerblue\", family = \"barlow\", fontface = \"bold\") # adjust text features"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#plot-3-visualization",
    "href": "blog/2024-3-12-post/index.html#plot-3-visualization",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Plot 3 visualization",
    "text": "Plot 3 visualization\nFor my third plot, I don’t have too much extra wrangling to do. I have to make a new version of my data frame for my main countries. I can’t use the one from before because it is in wide format, and for my dodged column plot, I need it in long format. After making my new version just by filtering my original methane data frame, I re-order my country and type factors so that they are in descending order, redefine my custom color palette, and then make my dodged column plot.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          plot 3 visualization                            ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# filter methane_df to create long format of main_countries\ncols_df &lt;- methane_df %&gt;% \n  filter(country %in% c(\"China\", \"U.S.\", \"Russia\", \"Brazil\", \"EU*\", \"Canada\", \"Australia\"))\n\n# re-order countries as factors (for plotting)\ncols_df$country &lt;- factor(cols_df$country,\n                          levels = c(\"China\", \"U.S.\", \"Russia\", \"Brazil\", \"EU*\", \"Canada\", \"Australia\"))\n\n\n# re-order countries as factors (for plotting)\ncols_df$type &lt;- factor(cols_df$type,\n                          levels = c(\"Energy\", \"Agriculture\", \"Waste\", \"Other\"))\n\n# define a custom color palette\ncustom_colors &lt;- c(\n  \"Agriculture\" = \"#D2B48C\",\n  \"Energy\" = \"#2F2720\",\n  \"Waste\" = \"#2ca02c\",\n  \"Other\" = \"#2B4690\")\n\n# create dodged column plot\nggplot(cols_df, aes(x = country, y = total_emissions, fill = type)) + # fill columns based on sector\n  geom_col(position = \"stack\") + # specify dodged position to add space between countries\n  labs(x = \"\", # no x axis title\n       y = \"Methane Emissions (million tons CO2eq)\",\n       title = \"Sources of 2021 Anthropogenic Methane Emissions in selected countries\",\n       caption = \"Data Source: International Energy Agency (IEA)\\n\\n*The EU is a group of 27 countries in Europe.\") +\n  scale_fill_manual(values = custom_colors) + # apply custom color palette\n  theme_minimal() +\n  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank(), # remove major and minor vertical grid lines\n        panel.grid.major.y = element_line(color = \"grey90\", size = 0.5), # add horizontal grid lines (major)\n        panel.grid.minor.y = element_line(color = \"grey90\", size = 0.25), # add horizontal grid lines(minor)\n        plot.caption = element_text(size = 8, hjust = 1, colour = \"grey30\", family = \"merri sans\", # adjust caption text\n                                    margin = margin(20, 0, 0, 0)), # set margin\n        axis.title.y = element_text(family = \"barlow\", face = \"bold\", size = 15, color = \"grey30\", # adjust y axis title text\n                                    margin = margin(0, 20, 0, 0)), # set margin\n        axis.text.x = element_text(family = \"barlow\", face = \"bold\", size = 16), # adjust x axis text\n        axis.text.y = element_text(family = \"barlow\", size = 13, face = \"bold\"), # adjust x axis text\n        legend.position = c(0.88, 0.85), # specify legend position\n        legend.text = element_text(color = \"grey30\", face = \"bold\", size = 16, family = \"barlow\"), # adjust legend text\n        legend.title = element_blank(),\n        plot.title = element_text(family = \"merri sans\", size = 12.5, hjust = 0.5), # adjust plot title text and alignment\n        legend.background = element_rect(fill = \"#FEF6EC\", color = NA), # change legend background color\n        plot.background = element_rect(fill = \"#FEF6EC\", color = NA), # change plot background color\n        panel.background = element_rect(fill = \"#FEF6EC\", color = NA)) # change panel background color"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#making-infographic",
    "href": "blog/2024-3-12-post/index.html#making-infographic",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Making infographic",
    "text": "Making infographic\nTo create my infographic, I rendered my work in R to an HTML document and dragged the embedded plots onto a Canva document, which I then designed further and added text to as well. At the end of all my diligent work, I made the following infographic!\n\n\n\nInfographic on anthropogenic methane emissions in 2021"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#my-visualization-approach",
    "href": "blog/2024-3-12-post/index.html#my-visualization-approach",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "My visualization approach",
    "text": "My visualization approach\nWhen creating my plots in R and then my infographic in Canva, I thought through several aspects that are integral to effective data visualization practice. In this final section, I’ll go through each of these aspects and comment on my approach.\n\nGraphic form\nFor my first plot, I decided to do a treemap because it is a useful way to compare different parts of a ‘whole’, which in this case was total global emissions. Generally, treemaps are a better way to display this than a pie chart, as humans are much worse at understanding relative sizes that are part of a rounded object. In my second plot, I decided on scatterplot because I thought that seeing the distribution of per capita emissions among all countries, with the countries of focus highlighted, would be the easiest way to put understand how these countries compared to others. For my third plot, I made a dodged column plot because it seemed like a simple and effective way to communicate to my audience the nuances of how each of the countries of focus have emissions coming from different types of sources.\n\n\nText\nThis is a broad category, and I made a lot of decisions regarding the text used in my plots. Every word of text that I included was thoughtfully considered. My most major decisions were in my scatterplot, where I included labeled points (not only of focus countries but also other comparison countries), an annotation (for contextualizing emissions data), and a note in my caption to tell the audience directly that there were actually 8 countries with even higher per capita emissions than what was shown within the bounds of the plot.\n\n\nThemes\nI made a great deal of theme adjustments in each of my plots. For the first plot, the main theme choice was to orient my legend the way that I did, at the very top of the plot so the reader would read it immediately. In the second and third plot, I decided to get rid of vertical grid lines but keep some horizontal grid lines to help my audience to more easily see where countries lined up along the y-axis. I also moved the axis titled farther away from the axis in both of these plots, which I think is easier on the eyes.\n\n\nColors\nI made a custom color palette that I thought was unique, aesthetically pleasing, color-blind friendly (checked using the “let’s get color blind” Chrome Extension), and fit the variables that I was representing. I reused the colors from my first plot in my last plot, where they represented the same thing in each. I also reused the dark blue color quite a bit in my infographic, most notabley for shading the highlighted areas in my map and then to highlight these same countries as point in my scatterplot. All of the text that I wrote in Canva was also this color.\n\n\nTypography\nI chose to use Merriweather Sans for the title and captions of my plots and Barlow Condensed to use for all other text within my plots (labeling rectangles in plot 1, labeling points in plot 2, plot 2 annotation, legend in plot 1 and 2, all axis titles and text). Using a condensed typeface within my plots was nice because it allowed me to fit text more easily. I also think that it gave my visuals a more serious tone, especially since it was so thin that I had to bold it everywhere that I used it. I definetly spent more time selecting this typeface, and then I determined that Merriweather Sans was a good matching typeface for titles and captions of my plots. In Canva, I used the typeface Alike for most text, as it seemed both unique but still easy to read. I used Agrandir for my infographic title and other larger text in my infographic. Its a pretty basic typeface, but I couldn’t find anything that I liked better.\n\n\nGeneral design\nI definitely thought a lot about where I wanted my readers eyes to go. This is why I re-ordered factors so that the legends where in descending order in the first and third plot. I also re-ordered the factors my columns to be in descending order in my third plot. To avoid information overload in my first plot, I changed the name of many countries to empty strings. I also selected points to label carefully in my second plot for this reason. In addition, I also feel like I did a good job combining the plot and text elements in Canva so that the ideas flowed naturally using a visual hierarchy.\n\n\nContextualizing data\nAs previously mentioned, I used an annotation in my second plot to contextualize emissions to my audience. Recently, there have been a lot of news stories about the use of private jets among celebrities, so I felt like this was a good way to contextualize emissions, especially since the plot had to do with emissions per individual and flying a private jet is a very individualistic action. In my second plot, I also added the labels for other countries that weren’t the primary focus, like Venezuela, Congo, Mexico, and Bangladesh, as a way to provide more context for the emissions of countries around the world.\n\n\nCentering my primary message\nI think that the map that I included alongside the large text in the middle of my infographic was very effective at centering my message that there are some countries that have a disproportionately large amount of methane emissions relative to their population. Another point that I wanted to emphasize was how methane is mostly from fossil fuels, which is one reason why I put my treemap first. I also feel like the point I discussed in the second paragraph of text, right after my intro, emphasized this point by mentioning the 2021 study by McGill University scientists.\n\n\nConsidering accessibility\nI spent a great deal of time ensuring that the colors I chose were color-blind friendly using the “let’s get color blind” Chrome Extension. I tested using the simulate, daltonized, and simulate daltonized versions of Deuteranomaly, Protanomaly, and Tritanomaly. I also wrote alt text (embedded in images below) for all three of my plots (and my map) to ensure that blind users could still understand the figures in my infographic.\n\n\n\nTreemap (rectangle divided up into smaller rectangles) where each smaller rectangle represents anthropogenic methane emissions in 2021 from a specific country and sector (rectangles are colored by sector). Energy makes up 55% of global emissions, about half of which comes from the China, Russia, the U.S., Iran, and India. Agriculture makes up 29% of global emissions, waste makes up 14%, and 2% are from other sources.\n\n\n\n\n\nMap of the world where six countries (Canada, the U.S., Brazil, Russia, China, and Australia) and the 27 countries of the European Union are highlighted.\n\n\n\n\n\nScatterplot of many countries showing 2021 population on the x-axis and 2021 per-capita methane emissions (in tons of CO2eq) on the y-axis. Canada, the U.S., Brazil, Russia, China, and Australia are labeled and emphasized. Australia and Russia are in the top left of the plot, with per-capita emissions around 300 tons CO2eq. Australia’s population is about 25 million people, while Russia’s is about 200 million. Canada is around 200 tons CO2 eq, right below a dashed line indicating the carbon footprint of a typical private jet flying for 48 hours. Canada’s population is around 35 million people. The U.S. is at around 150 tons CO2eq and has a population of about 300 million people. Brazil is at around 100 tons CO2eq and has a population of about 250 million people. China is at around 55 tons CO2eq and has a population of about 1,400 million (1.4 billion) people. Latley, the EU is at around 45 tons CO2eq and has a population of about 450 million people.\n\n\n\n\n\nBar graph with 7 vertical columns, where the height represents the total methane emissions in 2021 (measured in million tons of CO2eq). From left to right (aligns with highest to lowest total emissions), the 7 vertical columns are China, the U.S. Russia, Brazil, the EU, Canada, and Australia. China is at about 80,000 million tons CO2eq, the U.S. and Russia are both close to 45,000 tons CO2eq, Brazil and the EU are both around 20,000 tons CO2eq, and Canada and Australia are both less than 10,000 tons CO2eq. The 7 columns are each seperated into four colored components, one for each type of emissions source (energy, agriculture, waste, and other). Russia’s energy sector (85%) and Brazil’s agricultural sector (65%) stand out as particularly high. Emissions from energy in the EU (29%) and Brazil (16%) make up a relatively low share of their total emissions, compared to about 60 to 70% in China, the U.S., Canada, and Australia.\n\n\n\n\nApplying a lense of Diversity, Equity, & Inclusion (DEI)\nOne decision that I thought about through a DEI lense was the decision of which countries to highlight in my plots, as I had some leeway in these decisions. I wanted to ensure that I wasn’t being biased towards any specific country when excludeing or singling-out specific countries in my analysis. This was somewhat difficult when highlighting countries because I was kind of singling them out, but I tried my best to highlight many examples of countries around the world to avoid really placing the blame exclusively on a certain type of country."
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#completed-infographic-where-we-are-heading",
    "href": "blog/2024-3-12-post/index.html#completed-infographic-where-we-are-heading",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "",
    "text": "Infographic on anthropogenic methane emissions in 2021"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#link-to-github-repository-coming-soon",
    "href": "blog/2024-3-12-post/index.html#link-to-github-repository-coming-soon",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Link to GitHub repository (coming soon!)",
    "text": "Link to GitHub repository (coming soon!)"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#link-to-github-repository",
    "href": "blog/2024-3-12-post/index.html#link-to-github-repository",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Link to GitHub repository",
    "text": "Link to GitHub repository"
  },
  {
    "objectID": "blog/2024-3-12-post/index.html#map-visualization",
    "href": "blog/2024-3-12-post/index.html#map-visualization",
    "title": "Creating an infographic on anthropogenic methane emissions in 2021",
    "section": "Map visualization",
    "text": "Map visualization\nI also want to add a world map that highlights the countries that I’m highlighting in the second and third visualizations (China, the U.S., Russia, the EU, Canada, and Australia), which requires two additional packages ({rnaturalearth} for basemap and {sf} for importing geometric objects).\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                       setup & data wrangling                             ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n# load additional packages\nlibrary(rnaturalearth)\nlibrary(sf)\n\n# get world map data\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# exclude Antarctica from the dataset\nworld &lt;- world[world$name != \"Antarctica\", ]\n\n# specify the countries to highlight\ncountries_to_highlight &lt;- c(\"China\", \"United States of America\", \"Russia\", \"Brazil\",\n                            \"Australia\", \"Canada\",\n                            \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\", \n                            \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \n                            \"Ireland\", \"Italy\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Netherlands\", \n                            \"Poland\", \"Portugal\", \"Romania\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\")\n\n# specify the countries that will receive a custom label (will use Denmark to label EU)\ncountries_to_label &lt;- c(\"China\", \"United States of America\", \"Russia\", \"Brazil\",\n                        \"Australia\", \"Canada\", \"Denmark\")\n\n# filter world data for highlighted and labeled countries\nhighlighted_countries &lt;- world[world$name %in% countries_to_highlight, ]\nlabeled_countries &lt;- world[world$name %in% countries_to_label, ]\n\n\n# calculate centroids for countries to label and store in data frame\ncentroids &lt;- st_centroid(labeled_countries$geometry)\ncentroids_df &lt;- data.frame(name = labeled_countries$name,\n                           lon = st_coordinates(centroids)[,1],\n                           lat = st_coordinates(centroids)[,2])\n\n# change 'United States of America' to 'U.S.' and 'Denmark' to 'EU*'\ncentroids_df$name &lt;- recode(centroids_df$name,\n                            'United States of America' = 'U.S.',\n                            'Denmark' = 'EU*')\n\n# adjust centroid longitude to move the labels left or right\ncentroids_df &lt;- centroids_df %&gt;%\n  mutate(lon = case_when(\n    name == \"Russia\" ~ lon + 50,\n    name == \"U.S.\" ~ lon + 60,\n    name == \"EU*\" ~ lon - 20,\n    name == \"Canada\" ~ lon - 1,\n    name == \"China\" ~ lon + 55,\n    name == \"Brazil\" ~ lon + 45,\n    TRUE ~ lon\n  ))\n\n# adjust centroid latitude to move the labels up or down\ncentroids_df &lt;- centroids_df %&gt;%\n  mutate(lat = case_when(\n    name == \"Russia\" ~ lat + 20,\n    name == \"Canada\" ~ lat + 24.5,\n    name == \"U.S.\" ~ lat - 10,\n    name == \"China\" ~ lat - 10,\n    name == \"Australia\" ~ lat - 20,\n    name == \"Brazil\" ~ lat - 20,\n    TRUE ~ lat\n  ))\n\n\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                              create map                                  ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nggplot(data = world) +\n  geom_sf(fill = \"gray\", color = \"grey90\", linewidth = 0.05) +\n  geom_sf(data = highlighted_countries, fill = \"#020122\", size = 0.5) +\n  geom_text(data = centroids_df, aes(x = lon, y = lat, label = name), hjust = \"right\", color = \"#020122\", family = \"barlow\", fontface = \"bold\", size = 7) +\n  labs(caption = \"*The EU is a group of 27 countries in Europe\") +\n  theme_minimal() +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n        axis.text.x = element_blank(), axis.ticks.x = element_blank(),\n        axis.title = element_blank(),\n        plot.background = element_rect(fill = \"#93B88E\", color = NA),\n        panel.background = element_rect(fill = \"#93B88E\", color = NA),\n        plot.caption = element_text(hjust = 1, size = 11, color = \"#020122\", family = \"merri sans\", margin = margin(20, 0, 0, 0)),)"
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#background",
    "href": "blog/2024-3-29-post/index.html#background",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Background",
    "text": "Background\nThe idea for this blog post comes from a group assignment in my machine learning class. For this assignment, my classmate Maxwell and I started by each using the Spotify Web API to access our recent liked songs data, and we each retrieved data on our 200 most recently liked songs (cite spotify web API). We then trained three decision tree models using 75% of the data (training set) and compared performance based on performance on the remaining 25% (testing set). Now, I’ve decided to go back and also build a model that uses Stochastic Gradient Boosted (SGB) decision trees and also update my model comparisons to include this SGB model."
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#setup-data-import",
    "href": "blog/2024-3-29-post/index.html#setup-data-import",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Setup & data import",
    "text": "Setup & data import\nAccess the Spotify Web API requires having an existing Spotify account and creating a Spotify for Developers account on the Spotify for Developers website. For the purposes of this blog, which focuses on the model-building process, I’ll skip over the API access steps. Instead, I’ll just start by importing the CSV files, which were written using information from the API.\n\n\nCode\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(baguette)\nlibrary(vip)\n\n# read in my data (CSV that was previously written)\nlinus_tracks &lt;- read.csv(here::here(\"data\", \"2024-3-29-post-data\", \"linus_tracks.csv\"))\n\n# read in partner data\nmaxwell_tracks &lt;- read.csv(here::here(\"data\", \"2024-3-29-post-data\", \"maxwell_songs.csv\")) %&gt;% \n  mutate(name = \"maxwell\")\n\n# bind my liked songs df with partner df\ncombined_tracks &lt;- rbind(linus_tracks, maxwell_tracks) %&gt;% \n  rename(time_sig = time_signature) %&gt;% \n  select(-track.name, -type, -id, -uri, -track_href, -analysis_url) # remove irrelevent columns"
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#data-exploration",
    "href": "blog/2024-3-29-post/index.html#data-exploration",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Data exploration",
    "text": "Data exploration\nOur data set contains 13 features that might be useful for predicting whether a song is in my collection or Maxwell’s. I’ll start by exploring what these 13 features are and how some of them vary between Maxwell’s liked songs and my own. Note that the first 13 columns contain the features we are looking at, and the 14th column contains our outcome variable ‘name’, which is either ‘linus’ or ‘maxwell’ depending on whose collection it is from.\nIn the following code, we look at a summarized breakdown of each column in the combined tracks data frame and then take a closer look at how Maxwell and I differ in terms of the tempo and danceability of our liked songs.\n\n\nCode\n# look at summary of columns\nsummary(combined_tracks)\n\n\n  danceability        energy            key           loudness      \n Min.   :0.1440   Min.   :0.0844   Min.   : 0.00   Min.   :-20.149  \n 1st Qu.:0.5570   1st Qu.:0.5350   1st Qu.: 2.00   1st Qu.: -9.371  \n Median :0.6580   Median :0.6865   Median : 5.00   Median : -7.524  \n Mean   :0.6428   Mean   :0.6608   Mean   : 5.27   Mean   : -8.053  \n 3rd Qu.:0.7642   3rd Qu.:0.8215   3rd Qu.: 8.00   3rd Qu.: -5.899  \n Max.   :0.9730   Max.   :0.9840   Max.   :11.00   Max.   : -2.421  \n      mode         speechiness       acousticness       instrumentalness   \n Min.   :0.0000   Min.   :0.02450   Min.   :0.0000075   Min.   :0.0000000  \n 1st Qu.:0.0000   1st Qu.:0.03610   1st Qu.:0.0121500   1st Qu.:0.0000229  \n Median :1.0000   Median :0.04685   Median :0.0721000   Median :0.0198500  \n Mean   :0.5975   Mean   :0.07576   Mean   :0.2068194   Mean   :0.2509544  \n 3rd Qu.:1.0000   3rd Qu.:0.07193   3rd Qu.:0.3255000   3rd Qu.:0.5235000  \n Max.   :1.0000   Max.   :0.51900   Max.   :0.9780000   Max.   :0.9670000  \n    liveness          valence           tempo         duration_ms    \n Min.   :0.02990   Min.   :0.0322   Min.   : 61.85   Min.   : 57877  \n 1st Qu.:0.09557   1st Qu.:0.2640   1st Qu.:112.08   1st Qu.:169776  \n Median :0.11900   Median :0.4530   Median :126.03   Median :210192  \n Mean   :0.16955   Mean   :0.4711   Mean   :125.03   Mean   :219639  \n 3rd Qu.:0.19250   3rd Qu.:0.6843   3rd Qu.:135.12   3rd Qu.:257514  \n Max.   :0.93300   Max.   :0.9810   Max.   :208.65   Max.   :627097  \n    time_sig         name          \n Min.   :1.000   Length:400        \n 1st Qu.:4.000   Class :character  \n Median :4.000   Mode  :character  \n Mean   :3.947                     \n 3rd Qu.:4.000                     \n Max.   :5.000                     \n\n\n\n\nCode\n# compare mean of tempo and danceability for Linus and Maxwell\ncombined_tracks %&gt;%\n  group_by(name) %&gt;%\n  summarise(mean_tempo = mean(tempo),\n            mean_danceability = mean(danceability),\n            mean_instrumentalness = mean(instrumentalness)) %&gt;% \n  ungroup()\n\n\n# A tibble: 2 × 4\n  name    mean_tempo mean_danceability mean_instrumentalness\n  &lt;chr&gt;        &lt;dbl&gt;             &lt;dbl&gt;                 &lt;dbl&gt;\n1 linus         125.             0.609                 0.157\n2 maxwell       125.             0.676                 0.344\n\n\n\n\nCode\n# compare distribution of tempo for Linus and Maxwell\nHmisc::histbackback(split(combined_tracks$tempo, combined_tracks$name),\n             main = \"Spotify liked songs comparison of tempo\", \n             ylab = \"tempo\",\n             xlab = c(\"linus\", \"maxwell\"))\n\n\n\n\n\nWhile the liked songs of Maxwell and I have a very similar mean tempo, the tempo of my liked songs exhibits a significantly wider distribution.\n\n\nCode\n# compare distribution of danceability for Linus and Maxwell\nHmisc::histbackback(split(combined_tracks$danceability, combined_tracks$name),\n             main = \"Spotify liked songs comparison of danceability\", \n             ylab = \"danceability\",\n             xlab = c(\"linus\", \"maxwell\"))\n\n\n\n\n\nMaxwell’s collection has a slightly higher mean danceability, and the distribution for his songs is more left skewed compared to mine.\n\n\nCode\n# compare distribution of instrumentalness for Linus and Maxwell\nHmisc::histbackback(split(combined_tracks$instrumentalness, combined_tracks$name),\n             main = \"Spotify liked songs comparison of instrumentalness\", \n             ylab = \"instrumentalness\",\n             xlab = c(\"linus\", \"maxwell\"))\n\n\n\n\n\nThe mean instrumentalness of Maxwell’s songs is more than twice that of the mean for my collection, and this is reflected in the histogram by the larger proportion of my songs with an instrumentalness of zero."
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#data-pre-processing",
    "href": "blog/2024-3-29-post/index.html#data-pre-processing",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Data pre-processing",
    "text": "Data pre-processing\nTo start, we’ll set the seed. This sets the randomization for creating our cross validation folds such that our results will be reproduced if ran on my local device again. We set the seed in its own code chunk because sometimes it can interfere with other process if included in a larger code chunk.\n\n\nCode\n# set seed\nset.seed(123)\n\n\nWe split our data in training and testing sets. We’ll use the training set to train the model during cross validation and the testing set to compare the performance of the different models. Next, we pre-process the data by specifying and prepping a recipe that converts all nominal features to dummy variables and normalizes all numeric features. We also create 10 folds of the training data to use for cross validation.\n\n\nCode\n# initial split of data into training and testing sets (default 75/25)\ntracks_split &lt;- initial_split(combined_tracks)\ntracks_test &lt;- testing(tracks_split)\ntracks_train &lt;- training(tracks_split)\n\n# specify recipe for model preprocessing\ntracks_recipe &lt;- recipe(name ~ ., data = tracks_train) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  prep() # prep recipe\n\n# create 10 folds of the training data set for CV\ncv_folds &lt;- tracks_train %&gt;% vfold_cv(v = 10)"
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#decision-tree-model",
    "href": "blog/2024-3-29-post/index.html#decision-tree-model",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Decision tree model",
    "text": "Decision tree model\nFor our first model, we’ll build just a single decision tree. A decision tree generates predictions by asking simple yes-or-no questions about the features. Which question to ask is determined by the partitioning objective. For our partitioning objective, we will be minimizing cross-entropy, which is the most common objective used for classification tasks.\n\nBuild preliminary model & tune hyperparameters\n\n\nCode\n# specify model for tuning hyperparameters\nsingle_tree_spec &lt;- decision_tree(\n  cost_complexity = tune(), # tune cost complexity for pruning tree\n  tree_depth = tune(), # tune maximum tree depth\n  min_n = tune()) %&gt;% # tune minimum n for a terminal node (minimum number of data points in a node that is required for the node to be split further)\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n# create tuning grid for hyperparameters\ntuning_grid &lt;- grid_latin_hypercube(cost_complexity(),\n                                    tree_depth(),\n                                    min_n(),\n                                    size = 10)\n\n# create workflow for tuning hyperparameters\nsingle_tree_wf &lt;- workflow() %&gt;%\n  add_recipe(tracks_recipe) %&gt;%\n  add_model(single_tree_spec)\n\n# tune hyperparameters using CV\nsingle_tree_tune &lt;- tune_grid(single_tree_spec, \n                              as.factor(name) ~ ., \n                              resamples = cv_folds,\n                              grid = tuning_grid,\n                              metrics = metric_set(accuracy))\n\n\n\n\nBuild final model & predict testing data\n\n\nCode\n# specify final model with optimized hyperparameters\nsingle_tree_final &lt;- finalize_model(single_tree_spec, select_best(single_tree_tune))\n\n# fit final model to training data\nsingle_tree_fit &lt;- fit(single_tree_final, as.factor(name)~., tracks_train)\n\n# predict testing data\nsingle_tree_predict &lt;- predict(single_tree_fit, tracks_test) %&gt;%\n  bind_cols(tracks_test) %&gt;%  # bind to testing df\n  mutate(name = as.factor(name))\n\n# get probabilities for predictions made on testing data (to calculate ROC AUC)\nsingle_tree_predict &lt;- predict(single_tree_fit, tracks_test, type = \"prob\") %&gt;%\n  bind_cols(single_tree_predict) %&gt;%  # bind to df that was just created\n  mutate(name = as.factor(name))\n\n# store confusion matrix for predictions made on testing data\nsingle_tree_conf_matrix &lt;- single_tree_predict %&gt;% \n  conf_mat(truth = name, estimate = .pred_class) %&gt;% \n  autoplot(type = \"heatmap\") +\n  ggtitle(\"Single DT\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n# store error metrics of testing data predictions\nsingle_tree_accuracy &lt;- accuracy(single_tree_predict, truth = name, estimate = .pred_class)\nsingle_tree_roc_auc &lt;- roc_auc(single_tree_predict, truth = name, .pred_linus)\nsingle_tree_sensitivity &lt;- sensitivity(single_tree_predict, truth = name, estimate = .pred_class)\nsingle_tree_specificity &lt;- specificity(single_tree_predict, truth = name, estimate = .pred_class)"
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#bagged-trees-model",
    "href": "blog/2024-3-29-post/index.html#bagged-trees-model",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Bagged trees model",
    "text": "Bagged trees model\nBagged, or “bootstrap aggregating”, prediction models train multiple shallow decision tree models and then combines them to generate an aggregated prediction. Compared to building a single deep decision tree, building multiple shallow decision trees greatly reduces the potential for overfitting. However, in a bagged decision tree model, there is concern about the trees being correlated with one another, meaning they may not provide a substantial improvement in predictive power.\n\nBuild final model & predict testing data (no tuning required)\n\n\nCode\n# specify model\nbagged_trees_spec &lt;- bag_tree() %&gt;%\n  set_engine(\"rpart\", times = 50) %&gt;% # specify number of trees (50-500 trees is usually sufficient)\n  set_mode(\"classification\")\n\n# create workflow\nbagged_trees_wf &lt;- workflow() %&gt;%\n  add_recipe(tracks_recipe) %&gt;%\n  add_model(bagged_trees_spec)\n\n# fit model to training data\nbagged_trees_fit &lt;- bagged_trees_wf %&gt;%\n  fit(data = tracks_train)\n\n# predict testing data\nbagged_trees_predict &lt;- predict(bagged_trees_fit, tracks_test) %&gt;% \n  bind_cols(tracks_test) %&gt;%  # bind to testing df\n  mutate(name = as.factor(name))\n\n# get probabilities for predictions made on testing data (to calculate ROC AUC)\nbagged_trees_predict &lt;- predict(bagged_trees_fit, tracks_test, type = \"prob\") %&gt;%\n  bind_cols(bagged_trees_predict) %&gt;%  # bind to df that was just created\n  mutate(name = as.factor(name))\n\n# store confusion matrix for predictions made on testing data\nbagged_trees_conf_matrix &lt;- bagged_trees_predict %&gt;% \n  conf_mat(truth = name, estimate = .pred_class) %&gt;% \n  autoplot(type = \"heatmap\") +\n  ggtitle(\"Bagged DTs\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n# store error metrics of testing data predictions\nbagged_trees_accuracy &lt;- accuracy(bagged_trees_predict, truth = name, estimate = .pred_class)\nbagged_trees_roc_auc &lt;- roc_auc(bagged_trees_predict, truth = name, .pred_linus)\nbagged_trees_sensitivity &lt;- sensitivity(bagged_trees_predict, truth = name, estimate = .pred_class)\nbagged_trees_specificity &lt;- specificity(bagged_trees_predict, truth = name, estimate = .pred_class)"
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#random-forest-model",
    "href": "blog/2024-3-29-post/index.html#random-forest-model",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Random forest model",
    "text": "Random forest model\nRandom forest models are a modification of bagged decision trees that builds a large collection of de-correlated trees to further improve predictive performance. Unlike with bagged decision trees, we now define an additional hyperparameter for the number of unique features that will be considered at each split in the decision tree. This hyperparameter, called mtry, makes it so we don’t have to worry about the trees being correlated with one another because we are only looking at a randomized subset of the features at each split in each tree. Having these un-correlated trees allows us to build many trees that are also deep, without overfitting to the training data. Because there are many trees in this model and these trees are also built to be deep based on a randomized set of features, they are referred to as a random forest.\n\nBuild preliminary model & tune hyperparameters\n\n\nCode\n# specify model for tuning hyperparameters\nrf_spec &lt;- rand_forest(trees = 500, # set number of trees to 500\n                       mtry = tune(), # tune mtry (number of unique feature variables that will be considered at each split)\n                       min_n = tune()) %&gt;% # tune minimum n for a terminal node (minimum number of data points in a node that is required for the node to be split further)\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"classification\")\n\n# create tuning grid for hyperparameters\n  tuning_grid &lt;- grid_latin_hypercube(mtry(range = c(2, 4)), \n                                      min_n(c(1, 10)),\n                                      size = 10)\n\n# create workflow for tuning hyperparameters\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(tracks_recipe) %&gt;%\n  add_model(rf_spec)\n\n# tune hyperparameters using CV\nrf_tune &lt;- tune_grid(rf_wf,\n                     resamples = cv_folds,\n                     grid = tuning_grid,\n                     metrics = metric_set(accuracy))\n\n\n\n\nBuild final model & predict testing data\n\n\nCode\n# specify final model with optimized hyperparameters\nrf_final &lt;- finalize_model(rf_spec, select_best(rf_tune))\n\n# create workflow for final version of model\nrf_final_wf &lt;- workflow() %&gt;%\n  add_recipe(tracks_recipe) %&gt;%\n  add_model(rf_final)\n\n# fit final workflow to training data\nrf_fit &lt;- rf_final_wf %&gt;%\n  fit(data = tracks_train)\n\n# predict testing data\nrf_predict &lt;- predict(rf_fit, tracks_test) %&gt;%\n  bind_cols(tracks_test) %&gt;%  # bind to testing df\n  mutate(name = as.factor(name))\n\n# get probabilities for predictions made on testing data (to calculate ROC AUC)\nrf_predict &lt;- predict(rf_fit, tracks_test, type = \"prob\") %&gt;%\n  bind_cols(rf_predict) %&gt;%  # bind to df that was just created\n  mutate(name = as.factor(name))\n\n# store confusion matrix for predictions made on testing data\nrf_conf_matrix &lt;- rf_predict %&gt;% \n  conf_mat(truth = name, estimate = .pred_class) %&gt;% \n  autoplot(type = \"heatmap\") +\n  ggtitle(\"Random Forest\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n# store error metrics of testing data predictions\nrf_accuracy &lt;- accuracy(rf_predict, truth = name, estimate = .pred_class)\nrf_roc_auc &lt;- roc_auc(rf_predict, truth = name, .pred_linus)\nrf_sensitivity &lt;- sensitivity(rf_predict, truth = name, estimate = .pred_class)\nrf_specificity &lt;- specificity(rf_predict, truth = name, estimate = .pred_class)"
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#stochastic-gradient-boosting-sgb-model",
    "href": "blog/2024-3-29-post/index.html#stochastic-gradient-boosting-sgb-model",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Stochastic Gradient Boosting (SGB) model",
    "text": "Stochastic Gradient Boosting (SGB) model\nBoosting is a general algorithm that is often applied to decision tree models as a way to improve predictive performance through introducing another form of randomization. Boosted models are built sequentially, as each version of the model is fit to the residuals from the previous version.\nSGB models use a large number of shallow decision trees as a base learner. These early versions of the model, which are called “weak models” are improved sequentially based on the residuals of the previous version. At each sequential step, these weak models are improved using the sequential fitting algorithm of stochastic gradient descent, which uses random sampling of features to optimize the defined loss function (for this classification problem, we will look to optimize accuracy) for each iteration based on the defined learning rate. We start by tuning the learning rate, which specifies the extent to which we want to change our weak models at each iteration. If we choose to low of a learning rate, it may require too many iterations for our model to improve at all, but if we choose a learning rate that is too high, we may accidently skip over a better performing version of the model.\n\nBuild preliminary model & tune learning rate\n\n\nCode\n# specify model for tuning learning rate\nsgb_lr_spec &lt;- boost_tree(mode = \"classification\",\n                      engine = \"xgboost\",\n                      learn_rate = tune())\n\n# create tuning grid for learning rate\ntuning_grid &lt;- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))\n\n# create workflow for tuning learning rate\nsgb_lr_wf &lt;- workflow() %&gt;%\n  add_model(sgb_lr_spec) %&gt;%\n  add_recipe(tracks_recipe)\n\n# tune learning rate using CV\nsgb_lr_tune &lt;- tune_grid(sgb_lr_wf,\n                         resamples = cv_folds,\n                         grid = tuning_grid,\n                         metrics = metric_set(accuracy))\n\n# store optimized learning rate\nbest_lr &lt;- select_best(sgb_lr_tune)\n\n\n\n\nBuild preliminary model & tune tree parameters\n\n\nCode\n# specify model for tuning tree parameters\nsgb_tree_spec &lt;- boost_tree(learn_rate = best_lr$learn_rate, # use optimized learning rate from previous step\n                            trees = 3000, # set number of trees to 3000\n                            tree_depth = tune(), # tune maximum tree depth\n                            min_n = tune(), # tune minimum n for a terminal node (minimum number of data points in a node that is required for the node to be split further)\n                            loss_reduction = tune(), # tune loss reduction (minimum loss required for further splits)\n                            mode = \"classification\",\n                            engine = \"xgboost\")\n\n# create tuning grid for tree parameters\ntuning_grid &lt;- grid_latin_hypercube(tree_depth(),\n                                    min_n(),\n                                    loss_reduction(),\n                                    size = 10)\n\n# create workflow for tuning tree parameters\nsgb_tree_wf &lt;- workflow() %&gt;%\n  add_model(sgb_tree_spec) %&gt;%\n  add_recipe(tracks_recipe)\n\n# tune tree parameters using CV\nsgb_tree_tune &lt;- tune_grid(sgb_tree_wf,\n                           resamples = cv_folds,\n                           grid = tuning_grid,\n                           metrics = metric_set(accuracy))\n\n# store optimized tree parameters\nbest_tree &lt;- select_best(sgb_tree_tune)\n\n\n\n\nBuild preliminary model & tune stochasticity parameters\n\n\nCode\n# specify model for tuning stochasticity parameters\nsgb_stochastic_spec &lt;- boost_tree(learn_rate = best_lr$learn_rate, # use optimized learning rate\n                                  trees = 3000, # set number of trees to 3000\n                                  tree_depth = best_tree$tree_depth, # use optimized maximum tree depth\n                                  min_n = best_tree$min_n, # use optimized minimum n for a terminal node (minimum number of data points in a node that is required for the node to be split further)\n                                  loss_reduction = best_tree$loss_reduction, # use optimized loss reduction (minimum loss required for further splits)\n                                  mtry = tune(), # tune mtry (number of unique feature variables in each subsample)\n                                  sample_size = tune(), # tune sample size (amount of randomly selected data exposed to the fitting routine when conducting stochastic gradient descent at each split)\n                                  mode = \"classification\",\n                                  engine = \"xgboost\")\n\n# specify mtry range based on the number of predictors\nmtry_final &lt;- finalize(mtry(), tracks_train)\n\n# create tuning grid for stochasticity parameters\ntuning_grid &lt;- grid_latin_hypercube(mtry_final,\n                                    sample_size = sample_prop(),\n                                    size = 10)\n\n# create workflow for tuning stochasticity parameters\nsgb_stochastic_wf &lt;- workflow() %&gt;%\n  add_model(sgb_stochastic_spec) %&gt;%\n  add_recipe(tracks_recipe)\n\n# tune stochasticity parameters using CV\nsgb_stochastic_tune &lt;- tune_grid(sgb_stochastic_wf,\n                                 resamples = cv_folds,\n                                 grid = tuning_grid,\n                                 metrics = metric_set(accuracy))\n\n# store optimized stochasticity parameters\nbest_stochastic &lt;- select_best(sgb_stochastic_tune)\n\n\n\n\nBuild final model & predict testing data\n\n\nCode\n# specify final model with optimized parameters\nsgb_final &lt;- finalize_model(sgb_stochastic_spec, best_stochastic)\n\n# fit final model to training data\nsgb_fit &lt;- fit(sgb_final, as.factor(name)~., tracks_train)\n\n# predict testing data\nsgb_predict &lt;- predict(sgb_fit, tracks_test) %&gt;%\n  bind_cols(tracks_test) %&gt;%  # bind to testing df\n  mutate(name = as.factor(name))\n\n# get probabilities for predictions made on testing data (to calculate ROC AUC)\nsgb_predict &lt;- predict(sgb_fit, tracks_test, type = \"prob\") %&gt;%\n  bind_cols(sgb_predict) %&gt;%  # bind to df that was just created\n  mutate(name = as.factor(name))\n\n# store confusion matrix for predictions made on testing data\nsgb_conf_matrix &lt;- sgb_predict %&gt;% \n  conf_mat(truth = name, estimate = .pred_class) %&gt;% \n  autoplot(type = \"heatmap\") +\n  ggtitle(\"SGB\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n# store error metrics of testing data predictions\nsgb_accuracy &lt;- accuracy(sgb_predict, truth = name, estimate = .pred_class)\nsgb_roc_auc &lt;- roc_auc(sgb_predict, truth = name, .pred_linus)\nsgb_sensitivity &lt;- sensitivity(sgb_predict, truth = name, estimate = .pred_class)\nsgb_specificity &lt;- specificity(sgb_predict, truth = name, estimate = .pred_class)"
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#compare-models",
    "href": "blog/2024-3-29-post/index.html#compare-models",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Compare models",
    "text": "Compare models\n\n\nCode\n# display confusion matrices of all four models\nsingle_tree_conf_matrix + bagged_trees_conf_matrix + rf_conf_matrix + sgb_conf_matrix +\n  plot_layout(nrow = 2, ncol = 2)\n\n\n\n\n\n\n\nCode\n# create tibble of accuracy and ROC AUC for all four models\nmetrics_tibble &lt;- tibble(\n  Method = factor(rep(c(\"Single DT\", \"Bagged DTs\", \"Random Forest\", \"SGB\"), times = 2),\n                  levels = c(\"Single DT\", \"Bagged DTs\", \"Random Forest\", \"SGB\")),\n  Metric = rep(c(\"Accuracy\", \"Area under Receiver Operating Characteristic (ROC) curve\"), each = 4),\n  Value = c(single_tree_accuracy$.estimate[1], bagged_trees_accuracy$.estimate[1],\n            rf_accuracy$.estimate[1], sgb_accuracy$.estimate[1],\n            single_tree_roc_auc$.estimate[1], bagged_trees_roc_auc$.estimate[1],\n            rf_roc_auc$.estimate[1], sgb_roc_auc$.estimate[1]))\n\n# create bar plot comparing accuracy and ROC AUC across all four models\nggplot(metrics_tibble, aes(x = Method, y = Value, fill = Metric)) + \n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.9)) +\n  geom_text(aes(label = sprintf(\"%.2f\", Value),\n                y = Value + 0.02),\n            position = position_dodge(width = 0.9),\n            vjust = 0,\n            size = 4) +\n  theme_minimal() +\n  labs(y = \"Metric Value\", x = \"Model\", title = \"Model Comparison\") +\n  scale_fill_brewer(palette = \"BuPu\") +\n  theme(plot.title = element_text(hjust = 0.5),\n        axis.title.x = element_blank(),\n        legend.position = \"top\",\n        legend.title = element_blank())\n\n\n\n\n\n\n\nCode\n# create tibble of accuracy and ROC AUC for all four models\nmetrics_tibble &lt;- tibble(\n  Method = factor(rep(c(\"Single DT\", \"Bagged DTs\", \"Random Forest\", \"SGB\"), times = 2),\n                  levels = c(\"Single DT\", \"Bagged DTs\", \"Random Forest\", \"SGB\")),\n  Metric = rep(c(\"Sensitivity\\n(Accuracy when truth was Linus)\", \"Specificity\\n(Accuracy when truth was Maxwell)\"), each = 4),\n  Value = c(single_tree_sensitivity$.estimate[1], bagged_trees_sensitivity$.estimate[1],\n            rf_sensitivity$.estimate[1], sgb_sensitivity$.estimate[1],\n            single_tree_specificity$.estimate[1], bagged_trees_specificity$.estimate[1],\n            rf_specificity$.estimate[1], sgb_specificity$.estimate[1]))\n\n\n# create bar plot comparing sensitivity and specificity across all four models\nggplot(metrics_tibble, aes(x = Method, y = Value, fill = Metric)) + \n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.9)) +\n  geom_text(aes(label = sprintf(\"%.2f\", Value),\n                y = Value + 0.02),\n            position = position_dodge(width = 0.9),\n            vjust = 0,\n            size = 4) +\n  theme_minimal() +\n  labs(y = \"Metric Value\", x = \"Model\", title = \"Model Comparison\") +\n  scale_fill_brewer(palette = \"Greens\") +\n  theme(plot.title = element_text(hjust = 0.5),\n        axis.title.x = element_blank(),\n        legend.position = \"top\",\n        legend.title = element_blank(),\n        legend.key.height = unit(10, \"mm\"))\n\n\n\n\n\nThe Stochastic Gradient Boosting (SGB) model performed the best at predicting the testing data, slightly outperforming the random forest model. While both the SGB and random forest models had the same accuracy for correctly classifying songs that were in my collection, the SGB model was slightly better at accurately classifying songs that were in Maxwell’s collection. When using a single decision tree, there was a significant drop-off in accuracy, largely due to difficulty classifying songs that were in Maxwell’s collection."
  },
  {
    "objectID": "blog/2024-3-29-post/index.html#compare-importance-of-predictor-variables",
    "href": "blog/2024-3-29-post/index.html#compare-importance-of-predictor-variables",
    "title": "Building predictive user classification models with data from Spotify Web API",
    "section": "Compare importance of predictor variables",
    "text": "Compare importance of predictor variables\n\n\nCode\n# compare importance of different predictor variables in best performing model\nvip(sgb_fit, method = \"model\", num_features = 13) +\n  ggtitle(\"Importance of features in SGB model\") +\n  labs(caption = \"Note: Importance of time_sig is &lt;0.01\") +\n  ylim(0.00, 0.20) +\n  geom_text(aes(label = sprintf(\"%.2f\", Importance), # label values\n                x = Variable,\n                y = Importance + 0.001),\n            hjust = 0,\n            color = \"black\",\n            size = 3.5) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        axis.text.y = element_text(color = \"black\", size = 12))\n\n\n\n\n\nIn the SGB model, which was the best performing model, tempo, valence, danceability, energy, and instrumentalness were the most important feature for predicting whether a song was in my collection or Maxwell’s."
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "The purpose of this analysis is to better understand and visualize biodiversity in Phoenix and highlight areas where biodiversity is declining. Specifically, the final map will show a map of Phoenix displayed on 100 meter grid-cells colored based on the area’s 2020 Biodiversity Intactness Index (BII), which is a score from 0 to 1. In addition, areas where BII declined from greater than 0.75 in 2017 to less than 0.75 in 2020 will be highlighted in a seperate color.\n\n\n\n\nAdd basemap with Contextily\nFetch items from Microsoft Planetary Computer (MPC) catalog using search criteria\nClip biodiversity raster based on polygon from shapefile of Arizona subdivisions\nCalculate percent of area with BII&gt;0.75 in 2017 and 2020\nVisualize 2020 biodiversity and changes from 2017\n\n\n\n\n\nThe primary dataset used in this analysis estimates terrestrial Biodiversity Intactness as a 100-meter gridded maps for years 2017 to 2020. The data contained in the dataset comes from Impact Observatory and Vizzuality, and they generated the data using a database of spatially referenced observations of biodiversity across 32,000 sites and over 750 studies. The data was accessed from the Microsoft Planetary Computer (MPC) catalog.\nA dataset from the U.S. Census Bureau was used to clip biodiversity raster.\n\n\n\n\n\nImpact Observatory & Vizzuality. 2022. “Biodiversity Intactness.” Accessed via Microsoft Planetary Computer (MPC) Catalog. https://planetarycomputer.microsoft.com/dataset/io-biodiversity#overview.\nU.S. Census Bureau. 2022. “2022 TIGER/Line Shapefiles: County Subdivision”. https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2022&layergroup=County+Subdivisions\n\n\n\n\n\n\n# Load libraries\nimport numpy as np\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.lines import Line2D\nfrom matplotlib.colors import ListedColormap\nfrom shapely.geometry import Polygon\n\nfrom pystac_client import Client\nimport planetary_computer\n\nimport rasterio\nfrom rasterio.plot import show\nimport contextily as ctx\n\n\n\n\n\n\n\n# Access catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n# Set temporal range of interest\ntime_range = \"2017-01-01/2020-01-01\"\n\n# Set Phoenix bounding box\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]\n\n# Search catalog\nsearch = catalog.search(\n    collections = ['io-biodiversity'],\n    bbox = bbox,\n    datetime = time_range)\n\n# Get items from search as list\nitems = search.item_collection()\nprint(f'There are {len(items)} items in the search.')\n\nThere are 4 items in the search.\n\n\n\n# Store individual items\nitem_2020 = items[0]\nitem_2017 = items[3]\n\n# Check CRS\nitem_2017.properties['proj:epsg']\n\n4326\n\n\n\n# Store raster data from items\nbii_2020 = rioxr.open_rasterio(item_2020.assets['data'].href)\nbii_2017 = rioxr.open_rasterio(item_2017.assets['data'].href)\n\n# Print original dimensions and coords\nprint('Original 2017 raster', bii_2017.dims, bii_2017.coords, '\\n')\n\n# Remove length band dimension\n# Print updated dimensions and coords\nbii_2020 = bii_2020.squeeze()\nbii_2017 = bii_2017.squeeze()\n\n# Remove coordinates associated to band\nbii_2020 = bii_2020.drop('band')\nbii_2017 = bii_2017.drop('band')\n\n# Print updated dimensions and coords\nprint('Updated 2017 raster', bii_2017.dims, bii_2017.coords, '\\n')\n\nOriginal 2017 raster ('band', 'y', 'x') Coordinates:\n  * band         (band) int64 1\n  * x            (x) float64 -115.4 -115.4 -115.4 ... -108.2 -108.2 -108.2\n  * y            (y) float64 34.74 34.74 34.74 34.74 ... 27.57 27.57 27.57 27.57\n    spatial_ref  int64 0 \n\nUpdated 2017 raster ('y', 'x') Coordinates:\n  * x            (x) float64 -115.4 -115.4 -115.4 ... -108.2 -108.2 -108.2\n  * y            (y) float64 34.74 34.74 34.74 34.74 ... 27.57 27.57 27.57 27.57\n    spatial_ref  int64 0 \n\n\n\n\n\n\n\n# Read in Arizona shapefile\narizona = gpd.read_file(\"data/tl_2022_04_cousub/tl_2022_04_cousub.shp\")\n\n# Select Phoenix subdivision\nphoenix = arizona[arizona['NAME'] == 'Phoenix']\n\n# Convert CRS to match MPC data\nphoenix = phoenix.to_crs('4326')\n\n# Check for matching CRS (should return True)\nitem_2017.properties['proj:epsg'] == phoenix.crs\n\nTrue\n\n\n\n\n\n\n\n# Set axis for Phoenix\nax = phoenix.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')\n\n# Add basemap from OpenStreetMap using Contextily\nctx.add_basemap(ax, crs=phoenix.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\n\n# Add title\nplt.title(\"Map of Phoenix subdivision\")\n\n# Display map\nplt.show()\n\n\n\n\n\n\n\n\n# Clip the rasters to Phoenix geometry\nbii_2017_clipped = bii_2017.rio.clip(phoenix.geometry, crs='4326')\nbii_2020_clipped = bii_2020.rio.clip(phoenix.geometry, crs='4326')\n\n# Calculate percent area with BII&gt;0.75\npercent_area_2017 = (np.sum(bii_2017_clipped &gt; 0.75) / np.sum(bii_2017_clipped &gt; 0)) * 100\npercent_area_2020 = (np.sum(bii_2020_clipped &gt; 0.75) / np.sum(bii_2020_clipped &gt; 0)) * 100\n\n# Print percents\nprint(f\"Percentage of area with BII&gt;0.75 in 2017: {percent_area_2017:.2f}%\")\nprint(f\"Percentage of area with BII&gt;0.75 in 2020: {percent_area_2020:.2f}%\")\n\nPercentage of area with BII&gt;0.75 in 2017: 7.13%\nPercentage of area with BII&gt;0.75 in 2020: 6.49%\n\n\n\n\n\n\n# Make raster representing the area with BII&gt;0.75 in 2017 that was lost by 2020\nlost_area = (bii_2017_clipped &gt; 0.75) & (bii_2020_clipped &lt; 0.75)\n\n# Check that lost area raster has same spatial reference dimension as original rasters (should return True)\nif lost_area.spatial_ref == bii_2017.spatial_ref == bii_2017.spatial_ref:\n    print('True')\n\nTrue\n\n\n\n# Convert bools to binary values\nlost_area_numeric = lost_area.astype(int)\n\n# Replace zeros with NaN\ncropped_lost_area = lost_area_numeric.where(lost_area_numeric == 1)\n\n# Define custom colormap for the lost area\ncustom_cmap = ListedColormap(['red'])\n\n# Plot figure and axis with custom colorbar\nfig, ax = plt.subplots()\nim = bii_2020_clipped.plot(ax=ax, cmap='Blues', add_colorbar=False)\ncropped_lost_area.plot(ax=ax, cmap=custom_cmap, add_colorbar=False)\ncbar = plt.colorbar(im, orientation='horizontal', pad=0.15)\ncbar.set_label('Biodiversity Intactness Index (BII)')\ncbar.outline.set_visible(False)\n\n# Create legend patch\nred_patch = Patch(color='red', label='Area where 2017 BII &gt; 0.75 but 2020 BII &lt; 0.75')\n\n# Add legend below the figure\nlegend_ax = fig.add_axes([0.80, 0.2, 0.02, 0.12])\nlegend_ax.legend(handles=[red_patch], ncol=1, frameon=False)\nlegend_ax.axis('off')\n\n# Add title\ntitle_text = 'Biodiversity in Phoenix, Arizona (2020)'\nax.set_title(title_text)\n\n# Remove axis labels and ticks\nax.set_xlabel('')\nax.set_ylabel('')\nax.set_xticks([])\nax.set_yticks([])\n\n# Remove frame around the entire figure\nax.set_frame_on(False)\n\n# Show the plot\nplt.show()\n\n\n\n\nFrom this map, we can see how the edges of certain areas in Phoenix, which had relatively high BII, decrease from greater than 0.75 to less than 0.75. In particular, this can be seen in the North East area of Phoenix, in addition to one spot in South Central Phoenix."
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#introduction",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#introduction",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "The purpose of this analysis is to better understand and visualize biodiversity in Phoenix and highlight areas where biodiversity is declining. Specifically, the final map will show a map of Phoenix displayed on 100 meter grid-cells colored based on the area’s 2020 Biodiversity Intactness Index (BII), which is a score from 0 to 1. In addition, areas where BII declined from greater than 0.75 in 2017 to less than 0.75 in 2020 will be highlighted in a seperate color.\n\n\n\n\nAdd basemap with Contextily\nFetch items from Microsoft Planetary Computer (MPC) catalog using search criteria\nClip biodiversity raster based on polygon from shapefile of Arizona subdivisions\nCalculate percent of area with BII&gt;0.75 in 2017 and 2020\nVisualize 2020 biodiversity and changes from 2017\n\n\n\n\n\nThe primary dataset used in this analysis estimates terrestrial Biodiversity Intactness as a 100-meter gridded maps for years 2017 to 2020. The data contained in the dataset comes from Impact Observatory and Vizzuality, and they generated the data using a database of spatially referenced observations of biodiversity across 32,000 sites and over 750 studies. The data was accessed from the Microsoft Planetary Computer (MPC) catalog.\nA dataset from the U.S. Census Bureau was used to clip biodiversity raster.\n\n\n\n\n\nImpact Observatory & Vizzuality. 2022. “Biodiversity Intactness.” Accessed via Microsoft Planetary Computer (MPC) Catalog. https://planetarycomputer.microsoft.com/dataset/io-biodiversity#overview.\nU.S. Census Bureau. 2022. “2022 TIGER/Line Shapefiles: County Subdivision”. https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2022&layergroup=County+Subdivisions"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#import-packages-and-functions",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#import-packages-and-functions",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "Code\n# Import packages and functions\nimport numpy as np\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.lines import Line2D\nfrom matplotlib.colors import ListedColormap\nfrom shapely.geometry import Polygon\n\nfrom pystac_client import Client\nimport planetary_computer\n\nimport rasterio\nfrom rasterio.plot import show\nimport contextily as ctx"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#read-in-data",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#read-in-data",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "# Access catalog\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n# Set temporal range of interest\ntime_range = \"2017-01-01/2020-01-01\"\n\n# Set Phoenix bounding box\nbbox = [-112.826843, 32.974108, -111.184387, 33.863574]\n\n# Search catalog\nsearch = catalog.search(\n    collections = ['io-biodiversity'],\n    bbox = bbox,\n    datetime = time_range)\n\n# Get items from search as list\nitems = search.item_collection()\nprint(f'There are {len(items)} items in the search.')\n\nThere are 4 items in the search.\n\n\n\n# Store individual items\nitem_2020 = items[0]\nitem_2017 = items[3]\n\n# Check CRS\nitem_2017.properties['proj:epsg']\n\n4326\n\n\n\n# Store raster data from items\nbii_2020 = rioxr.open_rasterio(item_2020.assets['data'].href)\nbii_2017 = rioxr.open_rasterio(item_2017.assets['data'].href)\n\n# Print original dimensions and coords\nprint('Original 2017 raster', bii_2017.dims, bii_2017.coords, '\\n')\n\n# Remove length band dimension\n# Print updated dimensions and coords\nbii_2020 = bii_2020.squeeze()\nbii_2017 = bii_2017.squeeze()\n\n# Remove coordinates associated to band\nbii_2020 = bii_2020.drop('band')\nbii_2017 = bii_2017.drop('band')\n\n# Print updated dimensions and coords\nprint('Updated 2017 raster', bii_2017.dims, bii_2017.coords, '\\n')\n\nOriginal 2017 raster ('band', 'y', 'x') Coordinates:\n  * band         (band) int64 1\n  * x            (x) float64 -115.4 -115.4 -115.4 ... -108.2 -108.2 -108.2\n  * y            (y) float64 34.74 34.74 34.74 34.74 ... 27.57 27.57 27.57 27.57\n    spatial_ref  int64 0 \n\nUpdated 2017 raster ('y', 'x') Coordinates:\n  * x            (x) float64 -115.4 -115.4 -115.4 ... -108.2 -108.2 -108.2\n  * y            (y) float64 34.74 34.74 34.74 34.74 ... 27.57 27.57 27.57 27.57\n    spatial_ref  int64 0 \n\n\n\n\n\n\n\n# Read in Arizona shapefile\narizona = gpd.read_file(\"data/tl_2022_04_cousub/tl_2022_04_cousub.shp\")\n\n# Select Phoenix subdivision\nphoenix = arizona[arizona['NAME'] == 'Phoenix']\n\n# Convert CRS to match MPC data\nphoenix = phoenix.to_crs('4326')\n\n# Check for matching CRS (should return True)\nitem_2017.properties['proj:epsg'] == phoenix.crs\n\nTrue"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#data-exploration",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#data-exploration",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "Code\n# Set axis for Phoenix\nax = phoenix.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')\n\n# Add basemap from OpenStreetMap using Contextily\nctx.add_basemap(ax, crs=phoenix.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\n\n# Add title\nplt.title(\"Map of Phoenix subdivision\")\n\n# Display map\nplt.show()"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#analysis",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#analysis",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "Code\n# Clip the rasters to Phoenix geometry\nbii_2017_clipped = bii_2017.rio.clip(phoenix.geometry, crs='4326')\nbii_2020_clipped = bii_2020.rio.clip(phoenix.geometry, crs='4326')\n\n# Calculate percent area with BII&gt;0.75\npercent_area_2017 = (np.sum(bii_2017_clipped &gt; 0.75) / np.sum(bii_2017_clipped &gt; 0)) * 100\npercent_area_2020 = (np.sum(bii_2020_clipped &gt; 0.75) / np.sum(bii_2020_clipped &gt; 0)) * 100\n\n# Print percents\nprint(f\"Percentage of area with BII&gt;0.75 in 2017: {percent_area_2017:.2f}%\")\nprint(f\"Percentage of area with BII&gt;0.75 in 2020: {percent_area_2020:.2f}%\")\n\n\nPercentage of area with BII&gt;0.75 in 2017: 7.13%\nPercentage of area with BII&gt;0.75 in 2020: 6.49%\n\n\n\n\n\n\n\nCode\n# Make raster representing the area with BII&gt;0.75 in 2017 that was lost by 2020\nlost_area = (bii_2017_clipped &gt; 0.75) & (bii_2020_clipped &lt; 0.75)\n\n# Check that lost area raster has same spatial reference dimension as original rasters (should return True)\nif lost_area.spatial_ref == bii_2017.spatial_ref == bii_2017.spatial_ref:\n    print('True')\n\n\nTrue\n\n\n\n\nCode\n# Convert bools to binary values\nlost_area_numeric = lost_area.astype(int)\n\n# Replace zeros with NaN\ncropped_lost_area = lost_area_numeric.where(lost_area_numeric == 1)\n\n# Define custom colormap for the lost area\ncustom_cmap = ListedColormap(['red'])\n\n# Plot figure and axis with custom colorbar\nfig, ax = plt.subplots()\nim = bii_2020_clipped.plot(ax=ax, cmap='Blues', add_colorbar=False)\ncropped_lost_area.plot(ax=ax, cmap=custom_cmap, add_colorbar=False)\ncbar = plt.colorbar(im, orientation='horizontal', pad=0.15)\ncbar.set_label('Biodiversity Intactness Index (BII)')\ncbar.outline.set_visible(False)\n\n# Create legend patch\nred_patch = Patch(color='red', label='Area where 2017 BII &gt; 0.75 but 2020 BII &lt; 0.75')\n\n# Add legend below the figure\nlegend_ax = fig.add_axes([0.80, 0.2, 0.02, 0.12])\nlegend_ax.legend(handles=[red_patch], ncol=1, frameon=False)\nlegend_ax.axis('off')\n\n# Add title\ntitle_text = 'Biodiversity in Phoenix, Arizona (2020)'\nax.set_title(title_text)\n\n# Remove axis labels and ticks\nax.set_xlabel('')\nax.set_ylabel('')\nax.set_xticks([])\nax.set_yticks([])\n\n# Remove frame around the entire figure\nax.set_frame_on(False)\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#import-libraries",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#import-libraries",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "# Load libraries\nimport numpy as np\nimport geopandas as gpd\nimport xarray as xr\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom matplotlib.lines import Line2D\nfrom matplotlib.colors import ListedColormap\nfrom shapely.geometry import Polygon\n\nfrom pystac_client import Client\nimport planetary_computer\n\nimport rasterio\nfrom rasterio.plot import show\nimport contextily as ctx"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#create-basic-map-of-phoenix-subdivision",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#create-basic-map-of-phoenix-subdivision",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "# Set axis for Phoenix\nax = phoenix.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')\n\n# Add basemap from OpenStreetMap using Contextily\nctx.add_basemap(ax, crs=phoenix.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\n\n# Add title\nplt.title(\"Map of Phoenix subdivision\")\n\n# Display map\nplt.show()"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#clip-rasters-and-calculate-percent-area-with-bii-0.75-for-2017-and-2020",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#clip-rasters-and-calculate-percent-area-with-bii-0.75-for-2017-and-2020",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "# Clip the rasters to Phoenix geometry\nbii_2017_clipped = bii_2017.rio.clip(phoenix.geometry, crs='4326')\nbii_2020_clipped = bii_2020.rio.clip(phoenix.geometry, crs='4326')\n\n# Calculate percent area with BII&gt;0.75\npercent_area_2017 = (np.sum(bii_2017_clipped &gt; 0.75) / np.sum(bii_2017_clipped &gt; 0)) * 100\npercent_area_2020 = (np.sum(bii_2020_clipped &gt; 0.75) / np.sum(bii_2020_clipped &gt; 0)) * 100\n\n# Print percents\nprint(f\"Percentage of area with BII&gt;0.75 in 2017: {percent_area_2017:.2f}%\")\nprint(f\"Percentage of area with BII&gt;0.75 in 2020: {percent_area_2020:.2f}%\")\n\nPercentage of area with BII&gt;0.75 in 2017: 7.13%\nPercentage of area with BII&gt;0.75 in 2020: 6.49%"
  },
  {
    "objectID": "blog/2023-12-13-post/phoenix_biodiversity.html#visualize-2020-bii-and-changes-from-2017",
    "href": "blog/2023-12-13-post/phoenix_biodiversity.html#visualize-2020-bii-and-changes-from-2017",
    "title": "Visualizing biodiversity changes from 2017 to 2020 in Phoenix, Arizona",
    "section": "",
    "text": "# Make raster representing the area with BII&gt;0.75 in 2017 that was lost by 2020\nlost_area = (bii_2017_clipped &gt; 0.75) & (bii_2020_clipped &lt; 0.75)\n\n# Check that lost area raster has same spatial reference dimension as original rasters (should return True)\nif lost_area.spatial_ref == bii_2017.spatial_ref == bii_2017.spatial_ref:\n    print('True')\n\nTrue\n\n\n\n# Convert bools to binary values\nlost_area_numeric = lost_area.astype(int)\n\n# Replace zeros with NaN\ncropped_lost_area = lost_area_numeric.where(lost_area_numeric == 1)\n\n# Define custom colormap for the lost area\ncustom_cmap = ListedColormap(['red'])\n\n# Plot figure and axis with custom colorbar\nfig, ax = plt.subplots()\nim = bii_2020_clipped.plot(ax=ax, cmap='Blues', add_colorbar=False)\ncropped_lost_area.plot(ax=ax, cmap=custom_cmap, add_colorbar=False)\ncbar = plt.colorbar(im, orientation='horizontal', pad=0.15)\ncbar.set_label('Biodiversity Intactness Index (BII)')\ncbar.outline.set_visible(False)\n\n# Create legend patch\nred_patch = Patch(color='red', label='Area where 2017 BII &gt; 0.75 but 2020 BII &lt; 0.75')\n\n# Add legend below the figure\nlegend_ax = fig.add_axes([0.80, 0.2, 0.02, 0.12])\nlegend_ax.legend(handles=[red_patch], ncol=1, frameon=False)\nlegend_ax.axis('off')\n\n# Add title\ntitle_text = 'Biodiversity in Phoenix, Arizona (2020)'\nax.set_title(title_text)\n\n# Remove axis labels and ticks\nax.set_xlabel('')\nax.set_ylabel('')\nax.set_xticks([])\nax.set_yticks([])\n\n# Remove frame around the entire figure\nax.set_frame_on(False)\n\n# Show the plot\nplt.show()\n\n\n\n\nFrom this map, we can see how the edges of certain areas in Phoenix, which had relatively high BII, decrease from greater than 0.75 to less than 0.75. In particular, this can be seen in the North East area of Phoenix, in addition to one spot in South Central Phoenix."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html",
    "href": "blog/2024-4-3-post/dic-ml.html",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "In this blog post, I’ll build three different models that predict dissolved inorganic carbon (DIC) content in water samples. The features being used to make these predictions will be other ocean chemistry measurements that were also measured during water sampling. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast.\nThe first of the three models, which I’m including just for the sake of comparison, uses only a single decision tree. The other two models will use a random forest and stochastic gradient boosted (SGB) trees.\n\n\n\n::: {.cell _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ papermill=‘{“duration”:13.016035,“end_time”:“2024-03-22T06:59:03.675508”,“exception”:false,“start_time”:“2024-03-22T06:58:50.659473”,“status”:“completed”}’ tags=‘[]’ execution_count=34}\n\nCode\nimport pandas as pd\nimport numpy as np\n\n# functions from sklearn\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# data viz libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n:::\n\n\n\n\n\nCode\n# import data\ndf = pd.read_csv('../../data/2024-4-3-post-data/water_samples.csv')\n\n# inspect data\nprint(df.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   Lat_Dec            1454 non-null   float64\n 2   Lon_Dec            1454 non-null   float64\n 3   NO2uM              1454 non-null   float64\n 4   NO3uM              1454 non-null   float64\n 5   NH3uM              1454 non-null   float64\n 6   R_TEMP             1454 non-null   float64\n 7   R_Depth            1454 non-null   int64  \n 8   R_Sal              1454 non-null   float64\n 9   R_DYNHT            1454 non-null   float64\n 10  R_Nuts             1454 non-null   float64\n 11  R_Oxy_micromol.Kg  1454 non-null   float64\n 12  Unnamed: 12        0 non-null      float64\n 13  PO4uM              1454 non-null   float64\n 14  SiO3uM             1454 non-null   float64\n 15  TA1.x              1454 non-null   float64\n 16  Salinity1          1454 non-null   float64\n 17  Temperature_degC   1454 non-null   float64\n 18  DIC                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n\nCode\n# remove 'id' and 'unnamed:_12' columns\ndf = df.drop(df.columns[[0, 12]], axis=1)\n\n\n\n\n\n\n\nCode\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n\n\n\nI’ll use this correlation heatmap to conduct feature selection, removing features that are highly correlated with other features. Specifically, I’ll remove ‘Temperature_degC’ (correlation with ‘R_TEMP’ is 1) and ‘R_Nuts’ (correlation with ‘NH3uM’ is 1).\n\n\nCode\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['Temperature_degC', 'R_Nuts']\n\n# define feature matrix and target vector\nX = df.drop(['DIC'] + columns_to_remove, axis=1)\ny = df['DIC']\n\n# split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n\n# check shapes of training and testing sets\nprint(f'X_train : {X_train.shape}')\nprint(f'y_train : {y_train.shape}')\nprint(f'X_test : {X_test.shape}')\nprint(f'y_test : {y_test.shape}')\n\n\nX_train : (1163, 14)\ny_train : (1163,)\nX_test : (291, 14)\ny_test : (291,)\n\n\n\n\n\nFor our first model, we’ll build just a single decision tree. A decision tree generates predictions by asking simple yes-or-no questions about the features. Which question to ask is determined by the partitioning objective. For our partitioning objective, we’ll be minimizing mean squared error (MSE), which is the most common objective used for regression tasks. After we build all four models, we’ll compare them based on root mean squared error (RMSE).\n\n\nCode\n# define tree model\ntree_regressor = DecisionTreeRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'decisiontreeregressor__max_depth': [None, 10, 20, 30, 40, 50], # max depth of tree\n    'decisiontreeregressor__min_samples_split': [2, 10, 20], # min number of samples required to split an internal node\n    'decisiontreeregressor__min_samples_leaf': [1, 5, 10] # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('decisiontreeregressor', tree_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_tree = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_tree.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\ntree_rmse = np.sqrt(mse)\nprint(f'RMSE: {tree_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nRMSE: 8.20\nBest parameters: {'decisiontreeregressor__max_depth': 20, 'decisiontreeregressor__min_samples_leaf': 5, 'decisiontreeregressor__min_samples_split': 2}\n\n\n\n\n\nRandom forest models build a large collection of de-correlated trees to improve predictive performance. We now define an additional hyperparameter for the number of unique features that will be considered at each split in the decision tree. This hyperparameter, called mtry, makes it so we don’t have to worry about the trees being correlated with one another because we are only looking at a randomized subset of the features at each split in each tree. Having these un-correlated trees allows us to build many trees that are also deep, without overfitting to the training data. Because there are many trees in this model and these trees are also built to be deep based on a randomized set of features, they are referred to as a random forest.\n\n\nCode\n# define RF model\nrandom_forest_regressor = RandomForestRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'randomforestregressor__n_estimators': [100],  # number of trees in forest\n    'randomforestregressor__max_depth': [None, 15, 30],  # max depth of each tree\n    'randomforestregressor__min_samples_split': [2, 5, 10],  # min number of samples required to split an internal node\n    'randomforestregressor__min_samples_leaf': [1, 2, 4]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('randomforestregressor', random_forest_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_forest = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_forest.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nrf_rmse = np.sqrt(mse)\nprint(f'RMSE: {rf_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nKeyboardInterrupt: \n\n\n\n\n\nBoosting is a general algorithm that is often applied to decision tree models as a way to improve predictive performance through introducing another form of randomization. Boosted models are built sequentially, as each version of the model is fit to the residuals from the previous version.\nSGB models use a large number of shallow decision trees as a base learner. These early versions of the model, which are called “weak models” are improved sequentially based on the residuals of the previous version. At each sequential step, these “weak models” are improved using the sequential fitting algorithm of stochastic gradient descent, which uses random sampling of features to optimize the defined loss function (in this case, MSE) for each iteration based on the defined learning rate. If we choose to low of a learning rate, it may require too many iterations for our model to improve at all, but if we choose a learning rate that is too high, we may accidently skip over a better performing version of the model.\nAnother important thing to note is that even though SGB models use decision trees, we actually don’t tune for the number of trees. While number of trees served as the base estimator in each of the three previous models, the base estimator for SGB models is the number of iterations of the sequential fitting algorithm (i.e., boosting stages) to perform. The number of trees is no longer a hyperparameter, but it instead is just an “ordinary” parameter being set based on the results of the sequential fitting algorithm.\n\n\nCode\n# define SGB model\ngradient_boosting_regressor = GradientBoostingRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'gradientboostingregressor__n_estimators': [3000],  # number of boosting stages to perform\n    'gradientboostingregressor__learning_rate': [0.01, 0.1, 0.2],  # learning rate\n    'gradientboostingregressor__max_depth': [3, 5, 10],  # max depth of individual regression estimators\n    'gradientboostingregressor__min_samples_split': [2, 5],  # min number of samples required to split an internal node\n    'gradientboostingregressor__min_samples_leaf': [1, 3]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('gradientboostingregressor', gradient_boosting_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_gradient_boosting = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_gradient_boosting.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nsgb_rmse = np.sqrt(mse)\nprint(f'RMSE: {sgb_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nKeyboardInterrupt: \n\n\n\n\n\n\n\nCode\n# create lists of RMSE values and models\nrmse_values = [sgb_rmse, rf_rmse, tree_rmse]\nmodels = ['SG Boosted Trees\\n(n=3000)', 'Random Forest\\n(n=100)', 'Single Tree\\n(n=1)']\n\n# create bar plot\nplt.figure(figsize=(10, 6))\nbars = plt.bar(models, rmse_values, color=['cornflowerblue'])\nplt.title('Model Comparison')\nplt.xlabel('Models')\nplt.ylabel('RMSE')\n\n# add value labels on top of each bar\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n\nplt.show()\n\n\n\n\n\nOur best performing model was the SGB model, with a RMSE of 6.599. In normal English, a RMSE of 6.599 means that, on average, the predictions made by this model deviate from the actual DIC values by 6.599 micromoles per kilogram.\n\n\n\n\n\nCode\n# extract importance of each feature from best version of model\nimportances = best_gradient_boosting.named_steps['gradientboostingregressor'].feature_importances_\n\n# create df to hold feature names and their importance\nimportance_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': importances\n})\n\n# sort by importance in descending order\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# create plot\nplt.figure(figsize=(12, 8))\nplt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\nplt.gca().invert_yaxis()\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.title('Feature Importances in SG Boosted Trees Model')\nplt.grid(True, which='both', axis = 'x', linestyle='--', linewidth=0.5)\n\nplt.show()\n\n\n\n\n\nHere, we see that the most important feature for predicting DIC in the SG Boosted Trees model was ‘SiO3uM’, with a feature importance over 0.70. This was significantly higher than the second most important feature, ‘PO4uM’, which had a feature importance of about 0.15."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#background",
    "href": "blog/2024-4-3-post/dic-ml.html#background",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "In this blog post, I’ll build three different models that predict dissolved inorganic carbon (DIC) content in water samples. The features being used to make these predictions will be other ocean chemistry measurements that were also measured during water sampling. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast.\nThe first of the three models, which I’m including just for the sake of comparison, uses only a single decision tree. The other two models will use a random forest and stochastic gradient boosted (SGB) trees."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#setup",
    "href": "blog/2024-4-3-post/dic-ml.html#setup",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "::: {.cell _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ papermill=‘{“duration”:13.016035,“end_time”:“2024-03-22T06:59:03.675508”,“exception”:false,“start_time”:“2024-03-22T06:58:50.659473”,“status”:“completed”}’ tags=‘[]’ execution_count=34}\n\nCode\nimport pandas as pd\nimport numpy as np\n\n# functions from sklearn\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# data viz libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n:::"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#data-import-basic-pre-processing",
    "href": "blog/2024-4-3-post/dic-ml.html#data-import-basic-pre-processing",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "Code\n# import data\ndf = pd.read_csv('../../data/2024-4-3-post-data/water_samples.csv')\n\n# inspect data\nprint(df.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   Lat_Dec            1454 non-null   float64\n 2   Lon_Dec            1454 non-null   float64\n 3   NO2uM              1454 non-null   float64\n 4   NO3uM              1454 non-null   float64\n 5   NH3uM              1454 non-null   float64\n 6   R_TEMP             1454 non-null   float64\n 7   R_Depth            1454 non-null   int64  \n 8   R_Sal              1454 non-null   float64\n 9   R_DYNHT            1454 non-null   float64\n 10  R_Nuts             1454 non-null   float64\n 11  R_Oxy_micromol.Kg  1454 non-null   float64\n 12  Unnamed: 12        0 non-null      float64\n 13  PO4uM              1454 non-null   float64\n 14  SiO3uM             1454 non-null   float64\n 15  TA1.x              1454 non-null   float64\n 16  Salinity1          1454 non-null   float64\n 17  Temperature_degC   1454 non-null   float64\n 18  DIC                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n\nCode\n# remove 'id' and 'unnamed:_12' columns\ndf = df.drop(df.columns[[0, 12]], axis=1)"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#data-exploration-additional-pre-processing",
    "href": "blog/2024-4-3-post/dic-ml.html#data-exploration-additional-pre-processing",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "Code\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n\n\n\nI’ll use this correlation heatmap to conduct feature selection, removing features that are highly correlated with other features. Specifically, I’ll remove ‘Temperature_degC’ (correlation with ‘R_TEMP’ is 1) and ‘R_Nuts’ (correlation with ‘NH3uM’ is 1).\n\n\nCode\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['Temperature_degC', 'R_Nuts']\n\n# define feature matrix and target vector\nX = df.drop(['DIC'] + columns_to_remove, axis=1)\ny = df['DIC']\n\n# split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n\n# check shapes of training and testing sets\nprint(f'X_train : {X_train.shape}')\nprint(f'y_train : {y_train.shape}')\nprint(f'X_test : {X_test.shape}')\nprint(f'y_test : {y_test.shape}')\n\n\nX_train : (1163, 14)\ny_train : (1163,)\nX_test : (291, 14)\ny_test : (291,)"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#model-using-single-decision-tree",
    "href": "blog/2024-4-3-post/dic-ml.html#model-using-single-decision-tree",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "For our first model, we’ll build just a single decision tree. A decision tree generates predictions by asking simple yes-or-no questions about the features. Which question to ask is determined by the partitioning objective. For our partitioning objective, we’ll be minimizing mean squared error (MSE), which is the most common objective used for regression tasks. After we build all four models, we’ll compare them based on root mean squared error (RMSE).\n\n\nCode\n# define tree model\ntree_regressor = DecisionTreeRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'decisiontreeregressor__max_depth': [None, 10, 20, 30, 40, 50], # max depth of tree\n    'decisiontreeregressor__min_samples_split': [2, 10, 20], # min number of samples required to split an internal node\n    'decisiontreeregressor__min_samples_leaf': [1, 5, 10] # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('decisiontreeregressor', tree_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_tree = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_tree.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\ntree_rmse = np.sqrt(mse)\nprint(f'RMSE: {tree_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nRMSE: 8.20\nBest parameters: {'decisiontreeregressor__max_depth': 20, 'decisiontreeregressor__min_samples_leaf': 5, 'decisiontreeregressor__min_samples_split': 2}"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#model-using-random-forest",
    "href": "blog/2024-4-3-post/dic-ml.html#model-using-random-forest",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "Random forest models build a large collection of de-correlated trees to improve predictive performance. We now define an additional hyperparameter for the number of unique features that will be considered at each split in the decision tree. This hyperparameter, called mtry, makes it so we don’t have to worry about the trees being correlated with one another because we are only looking at a randomized subset of the features at each split in each tree. Having these un-correlated trees allows us to build many trees that are also deep, without overfitting to the training data. Because there are many trees in this model and these trees are also built to be deep based on a randomized set of features, they are referred to as a random forest.\n\n\nCode\n# define RF model\nrandom_forest_regressor = RandomForestRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'randomforestregressor__n_estimators': [100],  # number of trees in forest\n    'randomforestregressor__max_depth': [None, 15, 30],  # max depth of each tree\n    'randomforestregressor__min_samples_split': [2, 5, 10],  # min number of samples required to split an internal node\n    'randomforestregressor__min_samples_leaf': [1, 2, 4]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('randomforestregressor', random_forest_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_forest = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_forest.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nrf_rmse = np.sqrt(mse)\nprint(f'RMSE: {rf_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nKeyboardInterrupt:"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#model-using-stochastic-gradient-boosted-trees",
    "href": "blog/2024-4-3-post/dic-ml.html#model-using-stochastic-gradient-boosted-trees",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "Boosting is a general algorithm that is often applied to decision tree models as a way to improve predictive performance through introducing another form of randomization. Boosted models are built sequentially, as each version of the model is fit to the residuals from the previous version.\nSGB models use a large number of shallow decision trees as a base learner. These early versions of the model, which are called “weak models” are improved sequentially based on the residuals of the previous version. At each sequential step, these “weak models” are improved using the sequential fitting algorithm of stochastic gradient descent, which uses random sampling of features to optimize the defined loss function (in this case, MSE) for each iteration based on the defined learning rate. If we choose to low of a learning rate, it may require too many iterations for our model to improve at all, but if we choose a learning rate that is too high, we may accidently skip over a better performing version of the model.\nAnother important thing to note is that even though SGB models use decision trees, we actually don’t tune for the number of trees. While number of trees served as the base estimator in each of the three previous models, the base estimator for SGB models is the number of iterations of the sequential fitting algorithm (i.e., boosting stages) to perform. The number of trees is no longer a hyperparameter, but it instead is just an “ordinary” parameter being set based on the results of the sequential fitting algorithm.\n\n\nCode\n# define SGB model\ngradient_boosting_regressor = GradientBoostingRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'gradientboostingregressor__n_estimators': [3000],  # number of boosting stages to perform\n    'gradientboostingregressor__learning_rate': [0.01, 0.1, 0.2],  # learning rate\n    'gradientboostingregressor__max_depth': [3, 5, 10],  # max depth of individual regression estimators\n    'gradientboostingregressor__min_samples_split': [2, 5],  # min number of samples required to split an internal node\n    'gradientboostingregressor__min_samples_leaf': [1, 3]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('gradientboostingregressor', gradient_boosting_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_gradient_boosting = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_gradient_boosting.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nsgb_rmse = np.sqrt(mse)\nprint(f'RMSE: {sgb_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nKeyboardInterrupt:"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#compare-models",
    "href": "blog/2024-4-3-post/dic-ml.html#compare-models",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "Code\n# create lists of RMSE values and models\nrmse_values = [sgb_rmse, rf_rmse, tree_rmse]\nmodels = ['SG Boosted Trees\\n(n=3000)', 'Random Forest\\n(n=100)', 'Single Tree\\n(n=1)']\n\n# create bar plot\nplt.figure(figsize=(10, 6))\nbars = plt.bar(models, rmse_values, color=['cornflowerblue'])\nplt.title('Model Comparison')\nplt.xlabel('Models')\nplt.ylabel('RMSE')\n\n# add value labels on top of each bar\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n\nplt.show()\n\n\n\n\n\nOur best performing model was the SGB model, with a RMSE of 6.599. In normal English, a RMSE of 6.599 means that, on average, the predictions made by this model deviate from the actual DIC values by 6.599 micromoles per kilogram."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml.html#compare-feature-importance",
    "href": "blog/2024-4-3-post/dic-ml.html#compare-feature-importance",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "Code\n# extract importance of each feature from best version of model\nimportances = best_gradient_boosting.named_steps['gradientboostingregressor'].feature_importances_\n\n# create df to hold feature names and their importance\nimportance_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': importances\n})\n\n# sort by importance in descending order\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# create plot\nplt.figure(figsize=(12, 8))\nplt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\nplt.gca().invert_yaxis()\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.title('Feature Importances in SG Boosted Trees Model')\nplt.grid(True, which='both', axis = 'x', linestyle='--', linewidth=0.5)\n\nplt.show()\n\n\n\n\n\nHere, we see that the most important feature for predicting DIC in the SG Boosted Trees model was ‘SiO3uM’, with a feature importance over 0.70. This was significantly higher than the second most important feature, ‘PO4uM’, which had a feature importance of about 0.15."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html",
    "href": "blog/2024-4-3-post/dic-ml-models.html",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "",
    "text": "In this blog post, I’ll build three different models that predict dissolved inorganic carbon (DIC) content in water samples. The features being used to make these predictions will be other ocean chemistry measurements that were also measured during water sampling. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast.\nThe first of the three models, which I’m including just for the sake of comparison, uses only a single decision tree. The other two models will be a random forest model and a stochastic gradient boosted (SGB) trees model.\n\n\n\n::: {.cell _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ papermill=‘{“duration”:13.016035,“end_time”:“2024-03-22T06:59:03.675508”,“exception”:false,“start_time”:“2024-03-22T06:58:50.659473”,“status”:“completed”}’ tags=‘[]’ execution_count=55}\n\nCode\nimport pandas as pd\nimport numpy as np\n\n# functions from sklearn\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# data viz libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n:::\n\n\n\n\n\nCode\n# import training data\ndf = pd.read_csv('data/train.csv')\n\n# inspect data\nprint(df.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   Lat_Dec            1454 non-null   float64\n 2   Lon_Dec            1454 non-null   float64\n 3   NO2uM              1454 non-null   float64\n 4   NO3uM              1454 non-null   float64\n 5   NH3uM              1454 non-null   float64\n 6   R_TEMP             1454 non-null   float64\n 7   R_Depth            1454 non-null   int64  \n 8   R_Sal              1454 non-null   float64\n 9   R_DYNHT            1454 non-null   float64\n 10  R_Nuts             1454 non-null   float64\n 11  R_Oxy_micromol.Kg  1454 non-null   float64\n 12  Unnamed: 12        0 non-null      float64\n 13  PO4uM              1454 non-null   float64\n 14  SiO3uM             1454 non-null   float64\n 15  TA1.x              1454 non-null   float64\n 16  Salinity1          1454 non-null   float64\n 17  Temperature_degC   1454 non-null   float64\n 18  DIC                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n\nCode\n# remove 'id' and 'unnamed:_12' columns\ndf = df.drop(df.columns[[0, 12]], axis=1)\n\n\n\n\n\n\n\nCode\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n\n\n\nI’ll use this correlation heatmap to conduct feature selection, removing features that are highly correlated with other features. Specifically, I’ll remove ‘Temperature_degC’ (correlation with ‘R_TEMP’ is 1) and ‘R_Nuts’ (correlation with ‘NH3uM’ is 1).\n\n\nCode\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['Temperature_degC', 'R_Nuts']\n\n# define feature matrix and target vector\nX = df.drop(['DIC'] + columns_to_remove, axis=1)\ny = df['DIC']\n\n# split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n\n# check shapes of training and testing sets\nprint(f'X_train : {X_train.shape}')\nprint(f'y_train : {y_train.shape}')\nprint(f'X_test : {X_test.shape}')\nprint(f'y_test : {y_test.shape}')\n\n\nX_train : (1163, 14)\ny_train : (1163,)\nX_test : (291, 14)\ny_test : (291,)\n\n\n\n\n\nFor our first model, we’ll build just a single decision tree. A decision tree generates predictions by asking simple yes-or-no questions about the features. Which question to ask is determined by the partitioning objective. For our partitioning objective, we’ll be minimizing mean squared error (MSE), which is the most common objective used for regression tasks. After we build all three models, we’ll compare them based on root mean squared error (RMSE).\n\n\nCode\n# define tree model\ntree_regressor = DecisionTreeRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'decisiontreeregressor__max_depth': [None, 10, 20, 30, 40, 50], # max depth of tree\n    'decisiontreeregressor__min_samples_split': [2, 10, 20], # min number of samples required to split an internal node\n    'decisiontreeregressor__min_samples_leaf': [1, 5, 10] # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('decisiontreeregressor', tree_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_tree = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_tree.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\ntree_rmse = np.sqrt(mse)\nprint(f'RMSE: {tree_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nRMSE: 8.21\nBest parameters: {'decisiontreeregressor__max_depth': None, 'decisiontreeregressor__min_samples_leaf': 5, 'decisiontreeregressor__min_samples_split': 10}\n\n\n\n\n\nRandom forest models build a large collection of de-correlated trees to improve predictive performance. We now define an additional hyperparameter for the number of unique features that will be considered at each split in the decision tree. This hyperparameter, called mtry, makes it so we don’t have to worry about the trees being correlated with one another because we are only looking at a randomized subset of the features at each split in each tree. Having these un-correlated trees allows us to build many trees that are also deep, without overfitting to the training data. Because there are many trees in this model and these trees are also built to be deep based on a randomized set of features, they are referred to as a random forest.\n\n\nCode\n# define RF model\nrandom_forest_regressor = RandomForestRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'randomforestregressor__n_estimators': [100],  # number of trees in forest\n    'randomforestregressor__max_depth': [30],  # max depth of each tree\n    'randomforestregressor__min_samples_split': [10],  # min number of samples required to split an internal node\n    'randomforestregressor__min_samples_leaf': [5]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('randomforestregressor', random_forest_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_forest = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_forest.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nrf_rmse = np.sqrt(mse)\nprint(f'RMSE: {rf_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nRMSE: 6.86\nBest parameters: {'randomforestregressor__max_depth': 30, 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10, 'randomforestregressor__n_estimators': 100}\n\n\n\n\n\nBoosting is a general algorithm that is often applied to decision tree models as a way to improve predictive performance through introducing another form of randomization. Boosted models are built sequentially, as each version of the model is fit to the residuals from the previous version.\nBoosted tree models use a large number of shallow decision trees as a base learner. These early versions of the model, which are called “weak models” are improved sequentially based on the residuals of the previous version.\nIn SGB tree models, these “weak models” are improved using the sequential fitting algorithm of stochastic gradient descent, which uses random sampling of features to optimize the defined loss function (in this case, MSE) for each iteration based on the defined learning rate. If we choose too low of a learning rate, it may require too many iterations for our model to improve at all, but if we choose a learning rate that is too high, we may accidently skip over a better performing version of the model.\nAnother important thing to note is that even though SGB models use decision trees, the number of trees is no longer a hyperparameter. While number of trees served as the base estimator in each of the three previous models, the base estimator for SGB models is the number of iterations of the sequential fitting algorithm (i.e., boosting stages) to perform. In SGB models, the number of trees is just an “ordinary” parameter being set based on the results of the sequential fitting algorithm.\n\n\nCode\n# define SGB model\ngradient_boosting_regressor = GradientBoostingRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'gradientboostingregressor__n_estimators': [3000],  # number of boosting stages to perform\n    'gradientboostingregressor__learning_rate': [0.01, 0.1],  # learning rate\n    'gradientboostingregressor__max_depth': [10],  # max depth of individual regression estimators\n    'gradientboostingregressor__min_samples_split': [10],  # min number of samples required to split an internal node\n    'gradientboostingregressor__min_samples_leaf': [5]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('gradientboostingregressor', gradient_boosting_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_gradient_boosting = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_gradient_boosting.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nsgb_rmse = np.sqrt(mse)\nprint(f'RMSE: {sgb_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\n\nRMSE: 6.91\nBest parameters: {'gradientboostingregressor__learning_rate': 0.1, 'gradientboostingregressor__max_depth': 10, 'gradientboostingregressor__min_samples_leaf': 5, 'gradientboostingregressor__min_samples_split': 10, 'gradientboostingregressor__n_estimators': 3000}\n\n\n\n\n\n\n\nCode\n# create lists of RMSE values and models\nrmse_values = [sgb_rmse, rf_rmse, tree_rmse]\nmodels = ['SG Boosted Trees\\n(n=3000)', 'Random Forest\\n(n=100)', 'Single Tree\\n(n=1)']\n\n# create bar plot\nplt.figure(figsize=(10, 6))\nbars = plt.bar(models, rmse_values, color=['cornflowerblue'])\nplt.title('Model Comparison')\nplt.xlabel('Models')\nplt.ylabel('RMSE')\n\n# add value labels on top of each bar\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n\nplt.show()\n\n\n\n\n\nOur best performing model was the random forest model, with a RMSE of 6.856. In normal English, a RMSE of 6.856 means that, on average, the predictions made by this model deviate from the actual DIC values by 6.856 micromoles per kilogram.\n\n\n\n\n\nCode\n# extract importance of each feature from best version of model\nimportances = best_forest.named_steps['randomforestregressor'].feature_importances_\n\n# create df to hold feature names and their importance\nimportance_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': importances\n})\n\n# sort by importance in descending order\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# create plot\nplt.figure(figsize=(12, 8))\nplt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\nplt.gca().invert_yaxis()\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.title('Feature Importances in RF Model')\nplt.grid(True, which='both', axis = 'x', linestyle='--', linewidth=0.5)\n\nplt.show()\n\n\n\n\n\nHere, we see that the most important feature for predicting DIC in the random forest model was ‘SiO3uM’, with a feature importance over 0.70. This was significantly higher than the second most important feature, ‘PO4uM’, which had a feature importance of close to 0.2."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#background",
    "href": "blog/2024-4-3-post/dic-ml-models.html#background",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Background",
    "text": "Background\nIn this blog post, I’ll build three different models that predict dissolved inorganic carbon (DIC) content in water samples. The features being used to make these predictions will be other ocean chemistry measurements that were also measured during water sampling. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast.\nThe first of the three models, which I’m including just for the sake of comparison, uses only a single decision tree. The other two models will be a random forest model and a stochastic gradient boosted (SGB) trees model."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#setup",
    "href": "blog/2024-4-3-post/dic-ml-models.html#setup",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\nimport numpy as np\n\n# functions from sklearn\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# data viz libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#data-import-basic-pre-processing",
    "href": "blog/2024-4-3-post/dic-ml-models.html#data-import-basic-pre-processing",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Data import & basic pre-processing",
    "text": "Data import & basic pre-processing\n\n# import training data\ndf = pd.read_csv('data/train.csv')\n\n# inspect data\nprint(df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   Lat_Dec            1454 non-null   float64\n 2   Lon_Dec            1454 non-null   float64\n 3   NO2uM              1454 non-null   float64\n 4   NO3uM              1454 non-null   float64\n 5   NH3uM              1454 non-null   float64\n 6   R_TEMP             1454 non-null   float64\n 7   R_Depth            1454 non-null   int64  \n 8   R_Sal              1454 non-null   float64\n 9   R_DYNHT            1454 non-null   float64\n 10  R_Nuts             1454 non-null   float64\n 11  R_Oxy_micromol.Kg  1454 non-null   float64\n 12  Unnamed: 12        0 non-null      float64\n 13  PO4uM              1454 non-null   float64\n 14  SiO3uM             1454 non-null   float64\n 15  TA1.x              1454 non-null   float64\n 16  Salinity1          1454 non-null   float64\n 17  Temperature_degC   1454 non-null   float64\n 18  DIC                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n# remove 'id' and 'unnamed:_12' columns\ndf = df.drop(df.columns[[0, 12]], axis=1)"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#data-exploration-additional-pre-processing",
    "href": "blog/2024-4-3-post/dic-ml-models.html#data-exploration-additional-pre-processing",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Data exploration & additional pre-processing",
    "text": "Data exploration & additional pre-processing\n\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n\n\nI’ll use this correlation heatmap to conduct feature selection, removing features that are highly correlated with other features. Specifically, I’ll remove ‘Temperature_degC’ (correlation with ‘R_TEMP’ is 1) and ‘R_Nuts’ (correlation with ‘NH3uM’ is 1).\n\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['Temperature_degC', 'R_Nuts']\n\n# define feature matrix and target vector\nX = df.drop(['DIC'] + columns_to_remove, axis=1)\ny = df['DIC']\n\n# split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n\n# check shapes of training and testing sets\nprint(f'X_train : {X_train.shape}')\nprint(f'y_train : {y_train.shape}')\nprint(f'X_test : {X_test.shape}')\nprint(f'y_test : {y_test.shape}')\n\nX_train : (1163, 14)\ny_train : (1163,)\nX_test : (291, 14)\ny_test : (291,)"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#model-using-single-decision-tree",
    "href": "blog/2024-4-3-post/dic-ml-models.html#model-using-single-decision-tree",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Model using single decision tree",
    "text": "Model using single decision tree\nFor our first model, we’ll build just a single decision tree. A decision tree generates predictions by asking simple yes-or-no questions about the features. Which question to ask is determined by the partitioning objective. For our partitioning objective, we’ll be minimizing mean squared error (MSE), which is the most common objective used for regression tasks. After we build all three models, we’ll compare them based on root mean squared error (RMSE).\n\n# define tree model\ntree_regressor = DecisionTreeRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'decisiontreeregressor__max_depth': [None, 10, 20, 30, 40, 50], # max depth of tree\n    'decisiontreeregressor__min_samples_split': [2, 10, 20], # min number of samples required to split an internal node\n    'decisiontreeregressor__min_samples_leaf': [1, 5, 10] # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('decisiontreeregressor', tree_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_tree = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_tree.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\ntree_rmse = np.sqrt(mse)\nprint(f'RMSE: {tree_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nRMSE: 8.21\nBest parameters: {'decisiontreeregressor__max_depth': None, 'decisiontreeregressor__min_samples_leaf': 5, 'decisiontreeregressor__min_samples_split': 10}"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#model-using-random-forest",
    "href": "blog/2024-4-3-post/dic-ml-models.html#model-using-random-forest",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Model using random forest",
    "text": "Model using random forest\nRandom forest models build a large collection of de-correlated trees to improve predictive performance. We now define an additional hyperparameter for the number of unique features that will be considered at each split in the decision tree. This hyperparameter, called mtry, makes it so we don’t have to worry about the trees being correlated with one another because we are only looking at a randomized subset of the features at each split in each tree. Having these un-correlated trees allows us to build many trees that are also deep, without overfitting to the training data. Because there are many trees in this model and these trees are also built to be deep based on a randomized set of features, they are referred to as a random forest.\n\n# define RF model\nrandom_forest_regressor = RandomForestRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'randomforestregressor__n_estimators': [100],  # number of trees in forest\n    'randomforestregressor__max_depth': [30],  # max depth of each tree\n    'randomforestregressor__min_samples_split': [10],  # min number of samples required to split an internal node\n    'randomforestregressor__min_samples_leaf': [5]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('randomforestregressor', random_forest_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_forest = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_forest.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nrf_rmse = np.sqrt(mse)\nprint(f'RMSE: {rf_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nRMSE: 6.86\nBest parameters: {'randomforestregressor__max_depth': 30, 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10, 'randomforestregressor__n_estimators': 100}"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#model-using-stochastic-gradient-boosted-trees",
    "href": "blog/2024-4-3-post/dic-ml-models.html#model-using-stochastic-gradient-boosted-trees",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Model using stochastic gradient boosted trees",
    "text": "Model using stochastic gradient boosted trees\nBoosting is a general algorithm that is often applied to decision tree models as a way to improve predictive performance through introducing another form of randomization. Boosted models are built sequentially, as each version of the model is fit to the residuals from the previous version.\nBoosted tree models use a large number of shallow decision trees as a base learner. These early versions of the model, which are called “weak models” are improved sequentially based on the residuals of the previous version.\nIn SGB tree models, these “weak models” are improved using the sequential fitting algorithm of stochastic gradient descent, which uses random sampling of features to optimize the defined loss function (in this case, MSE) for each iteration based on the defined learning rate. If we choose too low of a learning rate, it may require too many iterations for our model to improve at all, but if we choose a learning rate that is too high, we may accidently skip over a better performing version of the model.\nAnother important thing to note is that even though SGB models use decision trees, the number of trees is no longer a hyperparameter. While number of trees served as the base estimator in each of the three previous models, the base estimator for SGB models is the number of iterations of the sequential fitting algorithm (i.e., boosting stages) to perform. In SGB models, the number of trees is just an “ordinary” parameter being set based on the results of the sequential fitting algorithm.\n\n# define SGB model\ngradient_boosting_regressor = GradientBoostingRegressor()\n\n# create tuning grid for hyperparameters\nparam_grid = {\n    'gradientboostingregressor__n_estimators': [3000],  # number of boosting stages to perform\n    'gradientboostingregressor__learning_rate': [0.01, 0.1],  # learning rate\n    'gradientboostingregressor__max_depth': [10],  # max depth of individual regression estimators\n    'gradientboostingregressor__min_samples_split': [10],  # min number of samples required to split an internal node\n    'gradientboostingregressor__min_samples_leaf': [5]  # min number of samples required to be at a leaf node\n}\n\n# setup for Pipeline and GridSearchCV\npipeline = Pipeline([\n    ('gradientboostingregressor', gradient_boosting_regressor)\n])\ngrid_search = GridSearchCV(pipeline,\n                           param_grid,\n                           cv=5, # split data into 5 folds for CV\n                           scoring='neg_mean_squared_error') # determine best version of model based on MSE\n\n# fit model to training data and extract best version\ngrid_search.fit(X_train, y_train)\nbest_gradient_boosting = grid_search.best_estimator_\n\n# predict testing data\ny_pred = best_gradient_boosting.predict(X_test)\n\n# show RMSE and best parameters\nmse = mean_squared_error(y_test, y_pred)\nsgb_rmse = np.sqrt(mse)\nprint(f'RMSE: {sgb_rmse:.2f}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nRMSE: 6.91\nBest parameters: {'gradientboostingregressor__learning_rate': 0.1, 'gradientboostingregressor__max_depth': 10, 'gradientboostingregressor__min_samples_leaf': 5, 'gradientboostingregressor__min_samples_split': 10, 'gradientboostingregressor__n_estimators': 3000}"
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#compare-models",
    "href": "blog/2024-4-3-post/dic-ml-models.html#compare-models",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Compare models",
    "text": "Compare models\n\n# create lists of RMSE values and models\nrmse_values = [sgb_rmse, rf_rmse, tree_rmse]\nmodels = ['SG Boosted Trees\\n(n=3000)', 'Random Forest\\n(n=100)', 'Single Tree\\n(n=1)']\n\n# create bar plot\nplt.figure(figsize=(10, 6))\nbars = plt.bar(models, rmse_values, color=['cornflowerblue'])\nplt.title('Model Comparison')\nplt.xlabel('Models')\nplt.ylabel('RMSE')\n\n# add value labels on top of each bar\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n\nplt.show()\n\n\n\n\nOur best performing model was the random forest model, with a RMSE of 6.856. In normal English, a RMSE of 6.856 means that, on average, the predictions made by this model deviate from the actual DIC values by 6.856 micromoles per kilogram."
  },
  {
    "objectID": "blog/2024-4-3-post/dic-ml-models.html#compare-feature-importance",
    "href": "blog/2024-4-3-post/dic-ml-models.html#compare-feature-importance",
    "title": "Building regression models to predict dissolved inorganic carbon in water samples",
    "section": "Compare feature importance",
    "text": "Compare feature importance\n\n# extract importance of each feature from best version of model\nimportances = best_forest.named_steps['randomforestregressor'].feature_importances_\n\n# create df to hold feature names and their importance\nimportance_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': importances\n})\n\n# sort by importance in descending order\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# create plot\nplt.figure(figsize=(12, 8))\nplt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\nplt.gca().invert_yaxis()\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.title('Feature Importances in RF Model')\nplt.grid(True, which='both', axis = 'x', linestyle='--', linewidth=0.5)\n\nplt.show()\n\n\n\n\nHere, we see that the most important feature for predicting DIC in the random forest model was ‘SiO3uM’, with a feature importance over 0.70. This was significantly higher than the second most important feature, ‘PO4uM’, which had a feature importance of close to 0.2."
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#background",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#background",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "Using the online platform Kaggle, my machine learning class is having a competition to see who can create the best predictive model (goal is to build model with lowest MSE for testing data). Our task is to build a model that predicts dissolved inorganic carbon (DIC) content in water samples based on other ocean chemistry features that are also measured in the same sample. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast."
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#my-approach",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#my-approach",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "For this competition, I’ll be experimenting with deep learning techniques that we have only briefly covered in the class. I’m skeptical that this approach will yield better results than a technique based on decision trees, but I’m curious to gain some experience building artificial neural networks and see how the tuning process compares to the other techniques we have practiced in class."
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#setup",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#setup",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "::: {.cell _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ papermill=‘{“duration”:13.016035,“end_time”:“2024-03-22T06:59:03.675508”,“exception”:false,“start_time”:“2024-03-22T06:58:50.659473”,“status”:“completed”}’ tags=‘[]’ execution_count=21}\n# load libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras_tuner import HyperModel, RandomSearch\nfrom sklearn.model_selection import KFold\nimport itertools\n\n# Set the environment variable to change the log level\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = default, 1 = no INFO, 2 = no INFO and WARNING, 3 = no INFO, WARNING, and ERROR\n:::"
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#import-pre-process-training-data",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#import-pre-process-training-data",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# import training data\ntrain_df = pd.read_csv('data/train.csv')\ntrain_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# inspect data\nprint(train_df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   lat_dec            1454 non-null   float64\n 2   lon_dec            1454 non-null   float64\n 3   no2um              1454 non-null   float64\n 4   no3um              1454 non-null   float64\n 5   nh3um              1454 non-null   float64\n 6   r_temp             1454 non-null   float64\n 7   r_depth            1454 non-null   int64  \n 8   r_sal              1454 non-null   float64\n 9   r_dynht            1454 non-null   float64\n 10  r_nuts             1454 non-null   float64\n 11  r_oxy_micromol.kg  1454 non-null   float64\n 12  unnamed:_12        0 non-null      float64\n 13  po4um              1454 non-null   float64\n 14  sio3um             1454 non-null   float64\n 15  ta1.x              1454 non-null   float64\n 16  salinity1          1454 non-null   float64\n 17  temperature_degc   1454 non-null   float64\n 18  dic                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n# remove 'id' and 'unnamed:_12' columns\ntrain_df = train_df.drop(train_df.columns[[0, 12]], axis=1)\n\n\n# define feature matrix for training data\nX_train = train_df.drop('dic', axis=1).values\n\n# define target vector for training data\ny_train = train_df['dic'].values"
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#build-train-model",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#build-train-model",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# initialize new HyperModel object\nclass MyHyperModel:\n    \n    def build(self, hp):\n        model = Sequential()\n        \n        # add dense layer with ReLU (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='relu', # select ReLU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dense layer with ELU activator (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='elu', # select ELU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dropout layer\n        model.add(Dropout(rate=hp['dropout_1'])) # tune dropout rate\n\n        # add additional dense layer(s)\n        for i in range(1, hp['num_layers']):\n            model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                            activation=hp['activation'], # tune activation function\n                            kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add output layer with linear activation\n        model.add(Dense(1, activation='linear', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n        \n        # configure tuning for optimizer\n        optimizer = Adam(learning_rate=hp['learning_rate'], beta_1=hp['beta_1'])\n        \n        # compile hypermodel and set MSE as loss function\n        model.compile(optimizer=optimizer, loss='mean_squared_error')\n        \n        return model\n    \n# store HyperModel object with specified input shape based on number of columns in feature matrix\nhypermodel = MyHyperModel()\n\n\n# create hyperparameter grid for tuning\nhyperparameter_grid = {\n    'neurons_0': [128],\n    'dropout_1': [0.0],\n    'num_layers': [2],\n    'activation': ['elu'],\n    'learning_rate': [1e-3],\n    'beta_1': [0.8]\n}\n\n# define function that creates all combinations of values stored in a dictionary\ndef generate_combinations(grid):\n    keys, values = zip(*grid.items())\n    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n    return combinations\n\n# store all combinations of hyperparameter values from grid\ncombinations = generate_combinations(hyperparameter_grid)\n\n\n# create EarlyStopping object to use when tuning hypermodel\nearly_stopping = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=10, # stop trial early if no improvement over 10 iterations\n    verbose=0, # disable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# define custom function for performing a CV trial\ndef cross_validate_combination(X, y, combination):\n    kf = KFold(n_splits=5) # initialize CV fold with 5 splits\n    val_scores = [] # initialize empty vector for validation scores\n    \n    for train_index, val_index in kf.split(X):\n        \n        # build model with combination of hyperparameters\n        model = hypermodel.build(combination)\n        \n        # build CV fold (with 10 splits) using all of training data\n        X_train_fold, X_val_fold = X[train_index], X[val_index]\n        y_train_fold, y_val_fold = y[train_index], y[val_index]\n        \n        # fit model to CV fold\n        model.fit(X_train_fold,\n                  y_train_fold,\n                  callbacks=[early_stopping], # use early stopping\n                  epochs=50, # set number of epochs for each trial\n                  verbose=0) # disable verbose\n        \n        # evaluate model performance\n        val_score = model.evaluate(X_val_fold,\n                                   y_val_fold,\n                                   verbose=0)\n        val_scores.append(val_score)\n    \n    # return average validation score across all 10 splits of CV fold\n    return np.mean(val_scores)\n\n# initialize objects for storing best CV score and best hyperparameter combination\nbest_score = float('inf')\nbest_combination = None\n\n\n# determine best hyperparameter combination based on CV score\nfor combination in combinations:\n    score = cross_validate_combination(X_train,\n                                       y_train,\n                                       combination)\n    if score &lt; best_score:\n        best_score = score\n        best_combination = combination\nprint(\"Best Hyperparameters:\", best_combination)\nprint(\"Best Score:\", best_score)\n\nBest Hyperparameters: {'neurons_0': 128, 'dropout_1': 0.0, 'num_layers': 2, 'activation': 'elu', 'learning_rate': 0.001, 'beta_1': 0.8}\nBest Score: 150.6020065307617\n\n\n\n# create EarlyStopping object to use when finalizing fit\nearly_stopping_final = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=100, # stop trial early if no improvement over 100 iterations\n    verbose=1, # enable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# build version of hypermodel with best combination of hyperparameters\nbest_model = hypermodel.build(best_combination)\n\n# fit model to training data\nbest_model.fit(X_train,\n               y_train,\n               callbacks=[early_stopping_final],\n               epochs=500,\n               verbose=0)\n\nRestoring model weights from the end of the best epoch: 37.\nEpoch 137: early stopping\n\n\n&lt;keras.callbacks.History at 0x7f22f5884850&gt;\n\n\n\nloss = best_model.evaluate(X_train, y_train, verbose=0)\nprint(f\"Total loss (MSE for all training data): {loss}\")\n\nTotal loss (MSE for all training data): 90.12106323242188"
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#import-process-testing-data",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#import-process-testing-data",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# import testing data\ntest_df = pd.read_csv('data/test.csv')\ntest_df.columns = test_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# remove 'id' and 'unnamed:_12' columns\ntest_df = test_df.drop(test_df.columns[[0]], axis=1)\n\n# define feature matrix for testing data\nX_test = test_df"
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#predict-dic-for-testing-data-export-submission",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#predict-dic-for-testing-data-export-submission",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# generate predictions for testing data\npredictions = best_model.predict(X_test)\n\n# import submission template\nsubmission_df = pd.read_csv('data/sample_submission.csv')\nsubmission_df.columns = submission_df.columns.str.lower().str.replace(' ', '_')\n\n# bind predictions to 'dic' column\nsubmission_df['dic'] = predictions\n\n16/16 [==============================] - 0s 2ms/step\n\n\n\n# export submission\n# submission_df.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#conclusion",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#conclusion",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "Deep learning does not seem to have been the best choice for this specific problem, at least given my time and computer power constraints. It is interesting to me how deep learning techniques represent the most innovative machine learning approach at this moment, yet they still certainly seem to have their limits when it comes to certain problems. While the neural network architecture works really well when it comes to building models where the features are visual images or text/sentiment, building an effective deep learning model with these features proved to be difficult."
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "Using the online platform Kaggle, my machine learning class is having a competition to see who can create the best predictive model (goal is to build model with lowest MSE for testing data). Our task is to build a model that predicts dissolved inorganic carbon (DIC) content in water samples based on other ocean chemistry features that are also measured in the same sample. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast.\n\n\n\nFor this competition, I’ll be experimenting with deep learning techniques that we have only briefly covered in the class. I’m skeptical that this approach will yield better results than a technique based on decision trees, but I’m curious to gain some experience building artificial neural networks and see how the tuning process compares to the other techniques we have practiced in class.\n\n\n\n::: {.cell _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ papermill=‘{“duration”:13.016035,“end_time”:“2024-03-22T06:59:03.675508”,“exception”:false,“start_time”:“2024-03-22T06:58:50.659473”,“status”:“completed”}’ tags=‘[]’ execution_count=21}\n# load libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras_tuner import HyperModel, RandomSearch\nfrom sklearn.model_selection import KFold\nimport itertools\n\n# Set the environment variable to change the log level\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = default, 1 = no INFO, 2 = no INFO and WARNING, 3 = no INFO, WARNING, and ERROR\n:::\n\n\n\n\n# import training data\ntrain_df = pd.read_csv('data/train.csv')\ntrain_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# inspect data\nprint(train_df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   lat_dec            1454 non-null   float64\n 2   lon_dec            1454 non-null   float64\n 3   no2um              1454 non-null   float64\n 4   no3um              1454 non-null   float64\n 5   nh3um              1454 non-null   float64\n 6   r_temp             1454 non-null   float64\n 7   r_depth            1454 non-null   int64  \n 8   r_sal              1454 non-null   float64\n 9   r_dynht            1454 non-null   float64\n 10  r_nuts             1454 non-null   float64\n 11  r_oxy_micromol.kg  1454 non-null   float64\n 12  unnamed:_12        0 non-null      float64\n 13  po4um              1454 non-null   float64\n 14  sio3um             1454 non-null   float64\n 15  ta1.x              1454 non-null   float64\n 16  salinity1          1454 non-null   float64\n 17  temperature_degc   1454 non-null   float64\n 18  dic                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n# remove 'id' and 'unnamed:_12' columns\ntrain_df = train_df.drop(train_df.columns[[0, 12]], axis=1)\n\n\n\n\n\nplt.figure(figsize=(12, 10))\nsns.pairplot(data, diag_kind='kde')\nplt.title('Pairwise Scatter Plots')\nplt.show()\n\n\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['Temperature_degC', 'R_Nuts']\n\n# define feature matrix for training data\nX_train = train_df.drop(['DIC'] + columns_to_remove, axis=1)\n\n# define target vector for training data\ny_train = train_df['dic'].values\n\n\n\n\n\n# initialize new HyperModel object\nclass MyHyperModel:\n    \n    def build(self, hp):\n        model = Sequential()\n        \n        # add dense layer with ReLU (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='relu', # select ReLU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dense layer with ELU activator (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='elu', # select ELU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dropout layer\n        model.add(Dropout(rate=hp['dropout_1'])) # tune dropout rate\n\n        # add additional dense layer(s)\n        for i in range(1, hp['num_layers']):\n            model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                            activation=hp['activation'], # tune activation function\n                            kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add output layer with linear activation\n        model.add(Dense(1, activation='linear', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n        \n        # configure tuning for optimizer\n        optimizer = Adam(learning_rate=hp['learning_rate'], beta_1=hp['beta_1'])\n        \n        # compile hypermodel and set MSE as loss function\n        model.compile(optimizer=optimizer, loss='mean_squared_error')\n        \n        return model\n    \n# store HyperModel object with specified input shape based on number of columns in feature matrix\nhypermodel = MyHyperModel()\n\n\n# create hyperparameter grid for tuning\nhyperparameter_grid = {\n    'neurons_0': [128],\n    'dropout_1': [0.0],\n    'num_layers': [2],\n    'activation': ['elu'],\n    'learning_rate': [1e-3],\n    'beta_1': [0.8]\n}\n\n# define function that creates all combinations of values stored in a dictionary\ndef generate_combinations(grid):\n    keys, values = zip(*grid.items())\n    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n    return combinations\n\n# store all combinations of hyperparameter values from grid\ncombinations = generate_combinations(hyperparameter_grid)\n\n\n# create EarlyStopping object to use when tuning hypermodel\nearly_stopping = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=10, # stop trial early if no improvement over 10 iterations\n    verbose=0, # disable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# define custom function for performing a CV trial\ndef cross_validate_combination(X, y, combination):\n    kf = KFold(n_splits=5) # initialize CV fold with 5 splits\n    val_scores = [] # initialize empty vector for validation scores\n    \n    for train_index, val_index in kf.split(X):\n        \n        # build model with combination of hyperparameters\n        model = hypermodel.build(combination)\n        \n        # build CV fold (with 10 splits) using all of training data\n        X_train_fold, X_val_fold = X[train_index], X[val_index]\n        y_train_fold, y_val_fold = y[train_index], y[val_index]\n        \n        # fit model to CV fold\n        model.fit(X_train_fold,\n                  y_train_fold,\n                  callbacks=[early_stopping], # use early stopping\n                  epochs=50, # set number of epochs for each trial\n                  verbose=0) # disable verbose\n        \n        # evaluate model performance\n        val_score = model.evaluate(X_val_fold,\n                                   y_val_fold,\n                                   verbose=0)\n        val_scores.append(val_score)\n    \n    # return average validation score across all 10 splits of CV fold\n    return np.mean(val_scores)\n\n# initialize objects for storing best CV score and best hyperparameter combination\nbest_score = float('inf')\nbest_combination = None\n\n\n# determine best hyperparameter combination based on CV score\nfor combination in combinations:\n    score = cross_validate_combination(X_train,\n                                       y_train,\n                                       combination)\n    if score &lt; best_score:\n        best_score = score\n        best_combination = combination\nprint(\"Best Hyperparameters:\", best_combination)\nprint(\"Best Score:\", best_score)\n\nBest Hyperparameters: {'neurons_0': 128, 'dropout_1': 0.0, 'num_layers': 2, 'activation': 'elu', 'learning_rate': 0.001, 'beta_1': 0.8}\nBest Score: 150.6020065307617\n\n\n\n# create EarlyStopping object to use when finalizing fit\nearly_stopping_final = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=100, # stop trial early if no improvement over 100 iterations\n    verbose=1, # enable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# build version of hypermodel with best combination of hyperparameters\nbest_model = hypermodel.build(best_combination)\n\n# fit model to training data\nbest_model.fit(X_train,\n               y_train,\n               callbacks=[early_stopping_final],\n               epochs=500,\n               verbose=0)\n\nRestoring model weights from the end of the best epoch: 37.\nEpoch 137: early stopping\n\n\n&lt;keras.callbacks.History at 0x7f22f5884850&gt;\n\n\n\nloss = best_model.evaluate(X_train, y_train, verbose=0)\nprint(f\"Total loss (MSE for all training data): {loss}\")\n\nTotal loss (MSE for all training data): 90.12106323242188\n\n\n\n\n\n\n# import testing data\ntest_df = pd.read_csv('data/test.csv')\ntest_df.columns = test_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# remove 'id' and 'unnamed:_12' columns\ntest_df = test_df.drop(test_df.columns[[0]], axis=1)\n\n# define feature matrix for testing data\nX_test = test_df\n\n\n\n\n\n# generate predictions for testing data\npredictions = best_model.predict(X_test)\n\n# import submission template\nsubmission_df = pd.read_csv('data/sample_submission.csv')\nsubmission_df.columns = submission_df.columns.str.lower().str.replace(' ', '_')\n\n# bind predictions to 'dic' column\nsubmission_df['dic'] = predictions\n\n16/16 [==============================] - 0s 2ms/step\n\n\n\n# export submission\n# submission_df.to_csv('submission.csv', index=False)\n\n\n\n\nDeep learning does not seem to have been the best choice for this specific problem, at least given my time and computer power constraints. It is interesting to me how deep learning techniques represent the most innovative machine learning approach at this moment, yet they still certainly seem to have their limits when it comes to certain problems. While the neural network architecture works really well when it comes to building models where the features are visual images or text/sentiment, building an effective deep learning model with these features proved to be difficult."
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#data-import-basic-pre-processing",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#data-import-basic-pre-processing",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# import training data\ntrain_df = pd.read_csv('data/train.csv')\ntrain_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# inspect data\nprint(train_df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   lat_dec            1454 non-null   float64\n 2   lon_dec            1454 non-null   float64\n 3   no2um              1454 non-null   float64\n 4   no3um              1454 non-null   float64\n 5   nh3um              1454 non-null   float64\n 6   r_temp             1454 non-null   float64\n 7   r_depth            1454 non-null   int64  \n 8   r_sal              1454 non-null   float64\n 9   r_dynht            1454 non-null   float64\n 10  r_nuts             1454 non-null   float64\n 11  r_oxy_micromol.kg  1454 non-null   float64\n 12  unnamed:_12        0 non-null      float64\n 13  po4um              1454 non-null   float64\n 14  sio3um             1454 non-null   float64\n 15  ta1.x              1454 non-null   float64\n 16  salinity1          1454 non-null   float64\n 17  temperature_degc   1454 non-null   float64\n 18  dic                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n# remove 'id' and 'unnamed:_12' columns\ntrain_df = train_df.drop(train_df.columns[[0, 12]], axis=1)"
  },
  {
    "objectID": "blog/2024-4-10-post/ml-kaggle-competition.html#data-exploration-additional-pre-processing",
    "href": "blog/2024-4-10-post/ml-kaggle-competition.html#data-exploration-additional-pre-processing",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "plt.figure(figsize=(12, 10))\nsns.pairplot(data, diag_kind='kde')\nplt.title('Pairwise Scatter Plots')\nplt.show()\n\n\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['Temperature_degC', 'R_Nuts']\n\n# define feature matrix for training data\nX_train = train_df.drop(['DIC'] + columns_to_remove, axis=1)\n\n# define target vector for training data\ny_train = train_df['dic'].values"
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "Using the online platform Kaggle, my machine learning class is having a competition to see who can create the best predictive model (goal is to build model with lowest MSE for testing data). Our task is to build a model that predicts dissolved inorganic carbon (DIC) content in water samples based on other ocean chemistry features that are also measured in the same sample. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast.\n\n\n\nFor this competition, I’ll be experimenting with deep learning techniques that we have only briefly covered in the class. I’m skeptical that this approach will yield better results than a technique based on decision trees, but I’m curious to gain some experience building artificial neural networks and see how the tuning process compares to the other techniques we have practiced in class.\n\n\n\n\n# load libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# load ML libraries\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras_tuner import HyperModel, RandomSearch\nfrom sklearn.model_selection import KFold\nimport itertools\n\n# Set the environment variable to change the log level\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = default, 1 = no INFO, 2 = no INFO and WARNING, 3 = no INFO, WARNING, and ERROR\n\n\n\n\n\n# import training data\ntrain_df = pd.read_csv('../../data/train.csv')\ntrain_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# inspect data\nprint(train_df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   lat_dec            1454 non-null   float64\n 2   lon_dec            1454 non-null   float64\n 3   no2um              1454 non-null   float64\n 4   no3um              1454 non-null   float64\n 5   nh3um              1454 non-null   float64\n 6   r_temp             1454 non-null   float64\n 7   r_depth            1454 non-null   int64  \n 8   r_sal              1454 non-null   float64\n 9   r_dynht            1454 non-null   float64\n 10  r_nuts             1454 non-null   float64\n 11  r_oxy_micromol.kg  1454 non-null   float64\n 12  unnamed:_12        0 non-null      float64\n 13  po4um              1454 non-null   float64\n 14  sio3um             1454 non-null   float64\n 15  ta1.x              1454 non-null   float64\n 16  salinity1          1454 non-null   float64\n 17  temperature_degc   1454 non-null   float64\n 18  dic                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n# remove 'id' and 'unnamed:_12' columns\ntrain_df = train_df.drop(train_df.columns[[0, 12]], axis=1)\n\n\n\n\n\nplt.figure(figsize=(12, 10))\nsns.pairplot(train_df, diag_kind='kde')\nplt.title('Pairwise Scatter Plots')\nplt.show()\n\n&lt;Figure size 1200x1000 with 0 Axes&gt;\n\n\n\n\n\n\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(train_df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n\n\n\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['temperature_degc', 'r_nuts']\n\n# define feature matrix for training data\nX_train = train_df.drop(['dic'] + columns_to_remove, axis=1)\n\n# define target vector for training data\ny_train = train_df['dic'].values\n\n\n\n\n\n# initialize new HyperModel object\nclass MyHyperModel:\n    \n    def build(self, hp):\n        model = Sequential()\n        \n        # add dense layer with ReLU (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='relu', # select ReLU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dense layer with ELU activator (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='elu', # select ELU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dropout layer\n        model.add(Dropout(rate=hp['dropout_1'])) # tune dropout rate\n\n        # add additional dense layer(s)\n        for i in range(1, hp['num_layers']):\n            model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                            activation=hp['activation'], # tune activation function\n                            kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add output layer with linear activation\n        model.add(Dense(1, activation='linear', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n        \n        # configure tuning for optimizer\n        optimizer = Adam(learning_rate=hp['learning_rate'], beta_1=hp['beta_1'])\n        \n        # compile hypermodel and set MSE as loss function\n        model.compile(optimizer=optimizer, loss='mean_squared_error')\n        \n        return model\n    \n# store HyperModel object with specified input shape based on number of columns in feature matrix\nhypermodel = MyHyperModel()\n\n\n# create hyperparameter grid for tuning\nhyperparameter_grid = {\n    'neurons_0': [128],\n    'dropout_1': [0.0],\n    'num_layers': [2],\n    'activation': ['elu'],\n    'learning_rate': [1e-3],\n    'beta_1': [0.8]\n}\n\n# define function that creates all combinations of values stored in a dictionary\ndef generate_combinations(grid):\n    keys, values = zip(*grid.items())\n    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n    return combinations\n\n# store all combinations of hyperparameter values from grid\ncombinations = generate_combinations(hyperparameter_grid)\n\n\n# create EarlyStopping object to use when tuning hypermodel\nearly_stopping = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=10, # stop trial early if no improvement over 10 iterations\n    verbose=0, # disable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# define custom function for performing a CV trial\ndef cross_validate_combination(X, y, combination):\n    kf = KFold(n_splits=5) # initialize CV fold with 5 splits\n    val_scores = [] # initialize empty vector for validation scores\n    \n    for train_index, val_index in kf.split(X):\n        \n        # build model with combination of hyperparameters\n        model = hypermodel.build(combination)\n        \n        # build CV fold (with 10 splits) using all of training data\n        X_train_fold, X_val_fold = X[train_index], X[val_index]\n        y_train_fold, y_val_fold = y[train_index], y[val_index]\n        \n        # fit model to CV fold\n        model.fit(X_train_fold,\n                  y_train_fold,\n                  callbacks=[early_stopping], # use early stopping\n                  epochs=50, # set number of epochs for each trial\n                  verbose=0) # disable verbose\n        \n        # evaluate model performance\n        val_score = model.evaluate(X_val_fold,\n                                   y_val_fold,\n                                   verbose=0)\n        val_scores.append(val_score)\n    \n    # return average validation score across all 10 splits of CV fold\n    return np.mean(val_scores)\n\n# initialize objects for storing best CV score and best hyperparameter combination\nbest_score = float('inf')\nbest_combination = None\n\n\n# determine best hyperparameter combination based on CV score\nfor combination in combinations:\n    score = cross_validate_combination(X_train,\n                                       y_train,\n                                       combination)\n    if score &lt; best_score:\n        best_score = score\n        best_combination = combination\nprint(\"Best Hyperparameters:\", best_combination)\nprint(\"Best Score:\", best_score)\n\nBest Hyperparameters: {'neurons_0': 128, 'dropout_1': 0.0, 'num_layers': 2, 'activation': 'elu', 'learning_rate': 0.001, 'beta_1': 0.8}\nBest Score: 150.6020065307617\n\n\n\n# create EarlyStopping object to use when finalizing fit\nearly_stopping_final = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=100, # stop trial early if no improvement over 100 iterations\n    verbose=1, # enable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# build version of hypermodel with best combination of hyperparameters\nbest_model = hypermodel.build(best_combination)\n\n# fit model to training data\nbest_model.fit(X_train,\n               y_train,\n               callbacks=[early_stopping_final],\n               epochs=500,\n               verbose=0)\n\nRestoring model weights from the end of the best epoch: 37.\nEpoch 137: early stopping\n\n\n&lt;keras.callbacks.History at 0x7f22f5884850&gt;\n\n\n\nloss = best_model.evaluate(X_train, y_train, verbose=0)\nprint(f\"Total loss (MSE for all training data): {loss}\")\n\nTotal loss (MSE for all training data): 90.12106323242188\n\n\n\n\n\n\n# import testing data\ntest_df = pd.read_csv('data/test.csv')\ntest_df.columns = test_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# remove 'id' and 'unnamed:_12' columns\ntest_df = test_df.drop(test_df.columns[[0]], axis=1)\n\n# define feature matrix for testing data\nX_test = test_df\n\n\n\n\n\n# generate predictions for testing data\npredictions = best_model.predict(X_test)\n\n# import submission template\nsubmission_df = pd.read_csv('data/sample_submission.csv')\nsubmission_df.columns = submission_df.columns.str.lower().str.replace(' ', '_')\n\n# bind predictions to 'dic' column\nsubmission_df['dic'] = predictions\n\n16/16 [==============================] - 0s 2ms/step\n\n\n\n# export submission\n# submission_df.to_csv('submission.csv', index=False)\n\n\n\n\nDeep learning does not seem to have been the best choice for this specific problem, at least given my time and computer power constraints. It is interesting to me how deep learning techniques represent the most innovative machine learning approach at this moment, yet they still certainly seem to have their limits when it comes to certain problems. While the neural network architecture works really well when it comes to building models where the features are visual images or text/sentiment, building an effective deep learning model with these features proved to be difficult."
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#background",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#background",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "Using the online platform Kaggle, my machine learning class is having a competition to see who can create the best predictive model (goal is to build model with lowest MSE for testing data). Our task is to build a model that predicts dissolved inorganic carbon (DIC) content in water samples based on other ocean chemistry features that are also measured in the same sample. Our data set comes from the California Cooperative Oceanic Fisheries Investigations (CalCOFI), an oceanographic and marine ecosystem research program located in California (link to data set source). All water samples were taken off the California coast."
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#my-approach",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#my-approach",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "For this competition, I’ll be experimenting with deep learning techniques that we have only briefly covered in the class. I’m skeptical that this approach will yield better results than a technique based on decision trees, but I’m curious to gain some experience building artificial neural networks and see how the tuning process compares to the other techniques we have practiced in class."
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#setup",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#setup",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# load libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# load ML libraries\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras_tuner import HyperModel, RandomSearch\nfrom sklearn.model_selection import KFold\nimport itertools\n\n# Set the environment variable to change the log level\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = default, 1 = no INFO, 2 = no INFO and WARNING, 3 = no INFO, WARNING, and ERROR"
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#data-import-basic-pre-processing",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#data-import-basic-pre-processing",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# import training data\ntrain_df = pd.read_csv('../../data/train.csv')\ntrain_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# inspect data\nprint(train_df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1454 entries, 0 to 1453\nData columns (total 19 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   id                 1454 non-null   int64  \n 1   lat_dec            1454 non-null   float64\n 2   lon_dec            1454 non-null   float64\n 3   no2um              1454 non-null   float64\n 4   no3um              1454 non-null   float64\n 5   nh3um              1454 non-null   float64\n 6   r_temp             1454 non-null   float64\n 7   r_depth            1454 non-null   int64  \n 8   r_sal              1454 non-null   float64\n 9   r_dynht            1454 non-null   float64\n 10  r_nuts             1454 non-null   float64\n 11  r_oxy_micromol.kg  1454 non-null   float64\n 12  unnamed:_12        0 non-null      float64\n 13  po4um              1454 non-null   float64\n 14  sio3um             1454 non-null   float64\n 15  ta1.x              1454 non-null   float64\n 16  salinity1          1454 non-null   float64\n 17  temperature_degc   1454 non-null   float64\n 18  dic                1454 non-null   float64\ndtypes: float64(17), int64(2)\nmemory usage: 216.0 KB\nNone\n\n\n\n# remove 'id' and 'unnamed:_12' columns\ntrain_df = train_df.drop(train_df.columns[[0, 12]], axis=1)"
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#data-exploration-additional-pre-processing",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#data-exploration-additional-pre-processing",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "plt.figure(figsize=(12, 10))\nsns.pairplot(train_df, diag_kind='kde')\nplt.title('Pairwise Scatter Plots')\nplt.show()\n\n&lt;Figure size 1200x1000 with 0 Axes&gt;\n\n\n\n\n\n\n# heatmap of correlation between features\nplt.figure(figsize=(12, 10))\nsns.heatmap(train_df.corr(), annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Heatmap')\nplt.show()\n\n\n\n\n\n# define highly correlated features to remove when creating feature matrix\ncolumns_to_remove = ['temperature_degc', 'r_nuts']\n\n# define feature matrix for training data\nX_train = train_df.drop(['dic'] + columns_to_remove, axis=1)\n\n# define target vector for training data\ny_train = train_df['dic'].values"
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#build-train-model",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#build-train-model",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# initialize new HyperModel object\nclass MyHyperModel:\n    \n    def build(self, hp):\n        model = Sequential()\n        \n        # add dense layer with ReLU (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='relu', # select ReLU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dense layer with ELU activator (based on preliminary training results)\n        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                        activation='elu', # select ELU activator (based on preliminary training results)\n                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add dropout layer\n        model.add(Dropout(rate=hp['dropout_1'])) # tune dropout rate\n\n        # add additional dense layer(s)\n        for i in range(1, hp['num_layers']):\n            model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n                            activation=hp['activation'], # tune activation function\n                            kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n        \n        # add output layer with linear activation\n        model.add(Dense(1, activation='linear', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n        \n        # configure tuning for optimizer\n        optimizer = Adam(learning_rate=hp['learning_rate'], beta_1=hp['beta_1'])\n        \n        # compile hypermodel and set MSE as loss function\n        model.compile(optimizer=optimizer, loss='mean_squared_error')\n        \n        return model\n    \n# store HyperModel object with specified input shape based on number of columns in feature matrix\nhypermodel = MyHyperModel()\n\n\n# create hyperparameter grid for tuning\nhyperparameter_grid = {\n    'neurons_0': [128],\n    'dropout_1': [0.0],\n    'num_layers': [2],\n    'activation': ['elu'],\n    'learning_rate': [1e-3],\n    'beta_1': [0.8]\n}\n\n# define function that creates all combinations of values stored in a dictionary\ndef generate_combinations(grid):\n    keys, values = zip(*grid.items())\n    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n    return combinations\n\n# store all combinations of hyperparameter values from grid\ncombinations = generate_combinations(hyperparameter_grid)\n\n\n# create EarlyStopping object to use when tuning hypermodel\nearly_stopping = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=10, # stop trial early if no improvement over 10 iterations\n    verbose=0, # disable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# define custom function for performing a CV trial\ndef cross_validate_combination(X, y, combination):\n    kf = KFold(n_splits=5) # initialize CV fold with 5 splits\n    val_scores = [] # initialize empty vector for validation scores\n    \n    for train_index, val_index in kf.split(X):\n        \n        # build model with combination of hyperparameters\n        model = hypermodel.build(combination)\n        \n        # build CV fold (with 10 splits) using all of training data\n        X_train_fold, X_val_fold = X[train_index], X[val_index]\n        y_train_fold, y_val_fold = y[train_index], y[val_index]\n        \n        # fit model to CV fold\n        model.fit(X_train_fold,\n                  y_train_fold,\n                  callbacks=[early_stopping], # use early stopping\n                  epochs=50, # set number of epochs for each trial\n                  verbose=0) # disable verbose\n        \n        # evaluate model performance\n        val_score = model.evaluate(X_val_fold,\n                                   y_val_fold,\n                                   verbose=0)\n        val_scores.append(val_score)\n    \n    # return average validation score across all 10 splits of CV fold\n    return np.mean(val_scores)\n\n# initialize objects for storing best CV score and best hyperparameter combination\nbest_score = float('inf')\nbest_combination = None\n\n\n# determine best hyperparameter combination based on CV score\nfor combination in combinations:\n    score = cross_validate_combination(X_train,\n                                       y_train,\n                                       combination)\n    if score &lt; best_score:\n        best_score = score\n        best_combination = combination\nprint(\"Best Hyperparameters:\", best_combination)\nprint(\"Best Score:\", best_score)\n\nBest Hyperparameters: {'neurons_0': 128, 'dropout_1': 0.0, 'num_layers': 2, 'activation': 'elu', 'learning_rate': 0.001, 'beta_1': 0.8}\nBest Score: 150.6020065307617\n\n\n\n# create EarlyStopping object to use when finalizing fit\nearly_stopping_final = EarlyStopping(\n    monitor='loss', # monitor loss function\n    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n    patience=100, # stop trial early if no improvement over 100 iterations\n    verbose=1, # enable verbose\n    mode='min', # specify that objective is to minimize function being monitored\n    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n\n# build version of hypermodel with best combination of hyperparameters\nbest_model = hypermodel.build(best_combination)\n\n# fit model to training data\nbest_model.fit(X_train,\n               y_train,\n               callbacks=[early_stopping_final],\n               epochs=500,\n               verbose=0)\n\nRestoring model weights from the end of the best epoch: 37.\nEpoch 137: early stopping\n\n\n&lt;keras.callbacks.History at 0x7f22f5884850&gt;\n\n\n\nloss = best_model.evaluate(X_train, y_train, verbose=0)\nprint(f\"Total loss (MSE for all training data): {loss}\")\n\nTotal loss (MSE for all training data): 90.12106323242188"
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#import-process-testing-data",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#import-process-testing-data",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# import testing data\ntest_df = pd.read_csv('data/test.csv')\ntest_df.columns = test_df.columns.str.lower().str.replace(' ', '_') # clean column names\n\n# remove 'id' and 'unnamed:_12' columns\ntest_df = test_df.drop(test_df.columns[[0]], axis=1)\n\n# define feature matrix for testing data\nX_test = test_df"
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#predict-dic-for-testing-data-export-submission",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#predict-dic-for-testing-data-export-submission",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "# generate predictions for testing data\npredictions = best_model.predict(X_test)\n\n# import submission template\nsubmission_df = pd.read_csv('data/sample_submission.csv')\nsubmission_df.columns = submission_df.columns.str.lower().str.replace(' ', '_')\n\n# bind predictions to 'dic' column\nsubmission_df['dic'] = predictions\n\n16/16 [==============================] - 0s 2ms/step\n\n\n\n# export submission\n# submission_df.to_csv('submission.csv', index=False)"
  },
  {
    "objectID": "blog/2024-4-2-post/ml-kaggle-competition.html#conclusion",
    "href": "blog/2024-4-2-post/ml-kaggle-competition.html#conclusion",
    "title": "Using deep learning to predict dissolved inorganic carbon (DIC) in water samples",
    "section": "",
    "text": "Deep learning does not seem to have been the best choice for this specific problem, at least given my time and computer power constraints. It is interesting to me how deep learning techniques represent the most innovative machine learning approach at this moment, yet they still certainly seem to have their limits when it comes to certain problems. While the neural network architecture works really well when it comes to building models where the features are visual images or text/sentiment, building an effective deep learning model with these features proved to be difficult."
  },
  {
    "objectID": "blog/2024-4-1-post/index.html",
    "href": "blog/2024-4-1-post/index.html",
    "title": "Clustering analysis of biological contaminating algae based on metal content",
    "section": "",
    "text": "To practice clustering analysis, we’ll use data from Roberts et al. 2008 on biological contaminants in Port Jackson Bay (located in Sydney, Australia). The data are measurements of metal content in two types of co-occurring algae at 10 sample sites around the bay."
  },
  {
    "objectID": "blog/2024-4-1-post/index.html#background",
    "href": "blog/2024-4-1-post/index.html#background",
    "title": "Clustering analysis of biological contaminating algae based on metal content",
    "section": "Background",
    "text": "Background\nTo practice clustering analysis, we’ll use data from Roberts et al. 2008 on biological contaminants in Port Jackson Bay (located in Sydney, Australia). The data are measurements of metal content in two types of co-occurring algae at 10 sample sites around the bay."
  },
  {
    "objectID": "blog/2024-4-1-post/index.html#setup-import-data",
    "href": "blog/2024-4-1-post/index.html#setup-import-data",
    "title": "Clustering analysis of biological contaminating algae based on metal content",
    "section": "Setup & import data",
    "text": "Setup & import data\n\n# set seed\nset.seed(123)\n\n\n# load packages\nlibrary(tidyverse) \nlibrary(tidymodels)\nlibrary(cluster) # cluster analysis\nlibrary(factoextra) # cluster visualization\n\n\n# load data\nmetals_df &lt;- readr::read_csv(\"../../data/2024-4-1-post-data/harbour_metals.csv\")\n\n# select only columns for pollutant variables\nmetals_df &lt;- metals_df[, 4:8]"
  },
  {
    "objectID": "blog/2024-4-1-post/index.html#k-means-clustering",
    "href": "blog/2024-4-1-post/index.html#k-means-clustering",
    "title": "Clustering analysis of biological contaminating algae based on metal content",
    "section": "K-means clustering",
    "text": "K-means clustering\n\nFind optimal k value & build model\n\n# find optimal number of clusters using elbow method\nfviz_nbclust(metals_df, kmeans, method = \"wss\")\n\n\n\n\nThe elbow method indicates that k=3 is the ideal number of clusters, as at this point, we see a very significant drop in the Total Within Sum of Square compared to k=2, followed by a very insignificant drop at k=4.\n\n# build k-means cluster model with optimal number of clusters (3)\nkmeans_model &lt;- kmeans(metals_df, centers = 3, nstart = 25)\n\n\n\nInspect clustering model\n\n# plot the clusters\nfviz_cluster(kmeans_model, geom = \"point\", data = metals_df) + ggtitle(\"k=3\")\n\n\n\n\nWhen we connect the outermost points in each cluster, we see that there is overlap between the far right side of cluster 2 and the far left side of cluster 3. The points near this boundary might have been assigned this way just because of the other nearby points that belonged to each cluster, or this could indicate that we should have chosen a larger number of clusters.\n\n# inspect model object\nkmeans_model\n\nK-means clustering with 3 clusters of sizes 10, 22, 28\n\nCluster means:\n        Cd       Cr        Cu        Mn    Ni\n1 0.796000 6.530000 127.09000 126.28200 2.304\n2 1.076818 6.180455  70.28455  66.79864 2.385\n3 1.593214 3.462857  22.39893  18.85250 1.870\n\nClustering vector:\n [1] 2 2 1 1 1 1 3 2 2 2 2 2 2 2 1 2 2 1 3 3 3 3 3 3 3 3 2 2 2 2 3 3 3 3 3 3 1 3\n[39] 2 3 2 2 3 3 3 3 3 3 2 1 1 2 1 2 2 3 3 3 3 3\n\nWithin cluster sum of squares by cluster:\n[1] 13159.695 22633.706  7511.094\n (between_SS / total_SS =  80.4 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nLooking at the specific values, ‘size’, which give the number of points allocated to each of the three clusters, stands out because cluster 2 and cluster 3 both have more than double the number of points as cluster 1. In addition, our ‘withinss’ values, which give the within-cluster variation for each of the three clusters, stands out because cluster 3 has over five times more variation than cluster 1 and over three times more variation than cluster 2."
  },
  {
    "objectID": "blog/2024-4-1-post/index.html#hierarchical-clustering",
    "href": "blog/2024-4-1-post/index.html#hierarchical-clustering",
    "title": "Clustering analysis of biological contaminating algae based on metal content",
    "section": "Hierarchical clustering",
    "text": "Hierarchical clustering\n\nCalculate Euclidean distance matrix & build model\n\n# calculate distance matrix\ndist_matrix &lt;- dist(metals_df, method = \"euclidean\")\n\nEach value in this matrix tells us the Euclidean distance between a set of two points in our data. There are 1770 rows in the table, one for each unique set of points.\n\n# build clustering model\nhc_model &lt;- hclust(dist_matrix)\n\n\n\nInspect clustering model\n\n# plot the dendrogram of clustering model\nplot(as.dendrogram(hc_model), main = \"Hierarchical Clustering Dendrogram\")\n\n\n\n\nThe dendrogram looks as expected. 51 is clearly an outlier point because starting from the bottom of the dendrogram and moving up, it is by far the last point to be assigned to a cluster that includes any other points besides itself, and when this assignment does occur, the point is about 80 distance units away from the centroid of the cluster it is assigned to. Comparatively, the point with the next highest distance away from the centroid of its initial assignment to a cluster containing more than just itself is 15, at about 40 distance units."
  },
  {
    "objectID": "blog/2024-4-1-post/index.html#conclusion",
    "href": "blog/2024-4-1-post/index.html#conclusion",
    "title": "Clustering analysis of biological contaminating algae based on metal content",
    "section": "Conclusion",
    "text": "Conclusion\nOur clustering analysis indicates that there are 3 major clusters of biological contaminating algae. For each cluster of algae, there are differing expected ranges of metal content across the five types of metal looked at (Cd, Cr, Cu, Mn, and Ni)."
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#link-to-github-repository",
    "href": "blog/2024-3-11-post/index.html#link-to-github-repository",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Link to GitHub repository",
    "text": "Link to GitHub repository"
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#question",
    "href": "blog/2024-3-11-post/index.html#question",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Question",
    "text": "Question\nFrom 1990 to 2012, what was the average treatment effect on the treated (ATT) and average treatment effect (ATE) of implementing an Individual Transferable Quota (ITQ) on the share of years that a fishery was collapsed? For our purposes, “collapsed” is defined as harvest being more than 10% below maximum recorded harvest."
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#background",
    "href": "blog/2024-3-11-post/index.html#background",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Background",
    "text": "Background\nAccording to a 2020 article published in the journal Marine Policy, Individual Transferable Quotas (ITQs) involve the allocation of shares or portions of a total allowable catch (TAC) to individual fishers, vessels, communities or others with an interest in the fishery, such as processors. A number of fisheries around the world have introduced ITQs as a way to regulate fisheries in a sustainable manner, preserving important natural resources while also allowing for increased economic productivity."
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#data",
    "href": "blog/2024-3-11-post/index.html#data",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Data",
    "text": "Data\nWe will use synthetically generated data to simplify things for our purposes (i.e., data is fake so results have no real implications). Our data contains the variables on 11,135 hypothetical fisheries (only cross sectional, no time observations). These fisheries were either regulated by an Individual Transferable Quota (ITQ) for all years between 1990 and 2012 or in none of those years.\nThe outcome and treatment variables are:\n\nCOLL_SHARE = share of years a fishery is collapsed between 1990 and 2012 (collapse defined as harvest being more than 10% below maximum recorded harvest).\nITQ = dummy variable indicating ‘treatment’ with an ITQ (equal to 1 if the fishery has been regulated by an ITQ and 0 otherwise).\n\nThe control variables are:\n\nMET1, MET2, ….MET6 = Dummy variables indicating to which Marine Ecosystem Type (MET) the fishery belongs to (coral reefs, kelp forests, seagrass meadows, open ocean, deep sea, mangrove forests). This type does not change over the relevant time period and does not depend on human influence.\nIND_SR = Index of species richness in 1980 with values between 0 and 100 indicating the biodiversity with respect to species in the fishery. Bounds of 0 and 100 are the lowest and highest observed values of species diversity across all fisheries in 1980, respectively.\nCOMM_VAL = Commercial value of fisheries in 1980 in million US-$"
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#setup",
    "href": "blog/2024-3-11-post/index.html#setup",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Setup",
    "text": "Setup\n\n\nCode\n# Import packages\nlibrary(tidyverse)\nlibrary(plm)\nlibrary(lmtest)\nlibrary(estimatr)\nlibrary(Hmisc)\nlibrary(RItools)\nlibrary(MatchIt)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\n\n\nCode\n## Load Data\nfisheries_df &lt;- read.csv(here::here(\"data\",\"2024-3-11-post-data\",\"final_fisheries_data.csv\"))\n\n## Prepare Data\n# Change all column names to lowercase\ncolnames(fisheries_df) &lt;- tolower(colnames(fisheries_df))"
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#comparison-of-pre-treatment-ecosystem-characteristics-in-the-treatment-and-control-groups",
    "href": "blog/2024-3-11-post/index.html#comparison-of-pre-treatment-ecosystem-characteristics-in-the-treatment-and-control-groups",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Comparison of pre-treatment ecosystem characteristics in the treatment and control groups",
    "text": "Comparison of pre-treatment ecosystem characteristics in the treatment and control groups\n\nMarine Ecosystem Type (MET)\n\n\nCode\n# Create MET column\nfisheries_df &lt;- fisheries_df %&gt;%\n  mutate(met = case_when(\n    met1 == 1 ~ 1,\n    met2 == 1 ~ 2,\n    met3 == 1 ~ 3,\n    met4 == 1 ~ 4,\n    met5 == 1 ~ 5,\n    met6 == 1 ~ 6))\n\n# Convert MET to factors\nfisheries_df$met &lt;- as.factor(fisheries_df$met)\n\n# Aggregate data and negate count for control\nfisheries_summary &lt;- fisheries_df %&gt;%\n  count(met, itq) %&gt;%\n  spread(key = itq, value = n) %&gt;%\n  gather(key = itq, value = 'count', -met) %&gt;% \n  mutate(count = if_else(itq == '0', -count, count))\n\n# Create histograms\nggplot(fisheries_summary, aes(x = met, y = count, fill = as.factor(itq))) +\n  geom_col() +\n  scale_y_continuous(labels = function(x) abs(x), limits = c(-2000, 2000)) +\n  coord_flip() +\n  labs(title = \"Covariates comparison\", x = \"MET\", y = \"Count\") +\n  scale_fill_brewer(palette = \"Set2\", name = \"ITQ\",\n                    labels = c(\"0\" = \"control\", \"1\" = \"treatment\")) +\n  theme_minimal()\n\n\n\n\n\nCompared to fisheries in the control group (not regulated by an ITQ), fisheries in the treatment group (regulated by an ITQ) were less likely to be coral reefs or mangrove forests and more likely to be kelp forests, seagrass meadows, open ocean, or deep sea (these differences are particularly pronounced for open ocean and deep sea).\n\n\nSpecies Richness Index\n\n\nCode\n# Calculate mean difference for IND_SR\nmean_diff_ind_sr &lt;- mean(fisheries_df$ind_sr[fisheries_df$itq == 1]) - mean(fisheries_df$ind_sr[fisheries_df$itq == 0])\nmean_diff_ind_sr\n\n\n[1] -8.825477\n\n\n\n\nCode\n# Mean difference t-test for IND_SR\nt.test(ind_sr ~ itq, data = fisheries_df)\n\n\n\n    Welch Two Sample t-test\n\ndata:  ind_sr by itq\nt = 41.826, df = 10839, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n 8.411868 9.239086\nsample estimates:\nmean in group 0 mean in group 1 \n       57.38515        48.55968 \n\n\nFor species richness (SR) index in 1980, we reject the null hypothesis, at an alpha level of &lt;0.001, that the difference in the mean SR index between the control (not regulated by an ITQ) and treatment (regulated by an ITQ) groups is zero. We estimate this mean difference to be about 8.83 index units (where the mean SR index is lower in the treatment group), and our 95% confidence interval for the mean difference is from 8.41 to 9.24 index units.\n\n\nCommercial value\n\n\nCode\n# Calculate mean difference for COMM_VAL\nmean_diff_comm_val &lt;- mean(fisheries_df$comm_val[fisheries_df$itq == 1]) - mean(fisheries_df$comm_val[fisheries_df$itq == 0])\nmean_diff_comm_val\n\n\n[1] -32.34931\n\n\n\n\nCode\n# Mean difference t-test for COMM_VAL\nt.test(comm_val ~ itq, data = fisheries_df)\n\n\n\n    Welch Two Sample t-test\n\ndata:  comm_val by itq\nt = 39.507, df = 9334.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n 30.74425 33.95437\nsample estimates:\nmean in group 0 mean in group 1 \n      117.22839        84.87908 \n\n\nRegarding the commercial value of fisheries in 1980, we also reject the null hypothesis, at an alpha level of &lt;0.001, that the difference in the mean SR index between the control (not regulated by an ITQ) and treatment (regulated by an ITQ) groups is zero. We estimate this mean difference to be about 32.35 million USD (where the mean commercial value is lower in the treatment group), and our 95% confidence interval for the mean difference is from 30.74 to 33.95 million USD.\n\n\nImplications for treatment ignorability assumption\nI do see a problem with just comparing the outcome variable (share of years between 1990 and 2012 with fishery collapse, meaning harvest was more than 10% below maximum recorded harvest) means between the treated (regulated by an ITQ) and untreated (not regulated by an ITQ) fisheries because of the statistically significant differences in the covariates between these two groups that we would not be controlling for. Our histograms from Part A show differences in the count of fisheries in the treated and untreated groups across the six marine ecosystem types, and these differences were particularly pronounced for ecosystems that were classified as open ocean or deep sea (both appear to be statistically significant). In addition, our two t-tests from Part B indicate, with high statistical significance (p&lt;0.001), mean differences between the two groups for both the biodiversity in 1980 and commercial value in 1980. These covariates are likely to be determinants of whether a fishery collapses, so it would be very misleading to just compare the outcome variable means of the treatment and untreated fisheries, since there are likely to be effects from the differences in covariate variables that will be misrepresented as effects from the treatment variable."
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#estimating-propensity-scores",
    "href": "blog/2024-3-11-post/index.html#estimating-propensity-scores",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Estimating propensity scores",
    "text": "Estimating propensity scores\n\n\nCode\n# Estimation of propensity scores with the glm function and logit model\nps_reg &lt;- glm(itq ~ met1 + met2 + met3 + met4 + met5 + ind_sr + comm_val,\n          data = fisheries_df, family = binomial())\n\n# Attach the predicted propensity score to the data frame\nfisheries_df$psvalue &lt;- predict(ps_reg, type    = \"response\")\n\n# Drawing back to back histograms for propensity scores for treated and non-treated before matching\nhistbackback(split(fisheries_df$psvalue, fisheries_df$itq),\n             main = \"Propensity score before matching\", xlab = c(\"control\", \"treatment\"), xlim = c(-600, 800))\n\n\n\n\n\nThere is some overlap in the distributions of our histograms, mainly for fisheries that have propensity scores between 0.4 and 0.6. I’m concerned about the lack of overlap for fisheries with high propensity scores, as this may lead to issues when we do nearest-neighbor matching. During nearest-neighbor matching, treated units are assigned to the non-treated unit with the closest propensity score as a match, and we want the resulting set of fisheries to have a great deal of overlap in their propensity scores to ensure a balance in covariates, since they are also likely to have an influence on our outcome variable. However, since there are very few fisheries in the control group with high propensity scores, I’m concerned that even after nearest-neighbor matching occurs, there will still be a lack of overlap in the distributions of our histograms."
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#estimating-average-treatment-effect-on-the-treated-att-with-nearest-neighbor-matching",
    "href": "blog/2024-3-11-post/index.html#estimating-average-treatment-effect-on-the-treated-att-with-nearest-neighbor-matching",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Estimating Average Treatment Effect on the Treated (ATT) with Nearest Neighbor Matching",
    "text": "Estimating Average Treatment Effect on the Treated (ATT) with Nearest Neighbor Matching\n\n\nCode\n## Nearest Neighbor Matching\n\n# Match using nearest-neighbor approach (treated units are assigned the non-treated unit with the closest propensity score as match)\nnn_matching &lt;- matchit(itq ~ met1 + met2 + met3 + met4 + met5 + ind_sr + comm_val,\n                       data = fisheries_df, method = \"nearest\", ratio = 1)\nmatch_data = match.data(nn_matching)\n\n## Estimate ATT\n\n# Calculate sum of the differences of outcomes between matches\nsumdiff_data &lt;- match_data %&gt;%\n  group_by(subclass) %&gt;%\n  mutate(diff = coll_share[itq==1] - coll_share[itq==0])\nsumdiff &lt;- sum(sumdiff_data$diff)/2\n\n# Divide sum of the difference by the number treated to generate ATT estimate\nATT_nn = sumdiff / sum(match_data$itq)\nATT_nn\n\n\n[1] -0.07132623\n\n\nUsing the matched data, we estimate the average effect of an ITQ on a fishery that had an ITQ to be a 7.13 percentage-point decrease in the share of years between 1990 and 2012 where the fishery experienced collapse. This estimated effect size only applies to fisheries that were regulated by an ITQ because we only defined counterfactuals for these fisheries. Thus, our average outcome only demonstrates the effect of an ITQ on fishery collapse as it pertains to fisheries that were regulated by an ITQ."
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#calculating-average-treatment-effect-ate-with-the-weight-least-squares-wls-estimator",
    "href": "blog/2024-3-11-post/index.html#calculating-average-treatment-effect-ate-with-the-weight-least-squares-wls-estimator",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Calculating Average Treatment Effect (ATE) with the Weight Least Squares (WLS) estimator",
    "text": "Calculating Average Treatment Effect (ATE) with the Weight Least Squares (WLS) estimator\n\n\nCode\n## WLS Matching\n\n# calculation of the weights (see slide 25 of lecture 5)\nPS &lt;- fisheries_df$psvalue\nD &lt;- fisheries_df$itq\n\n# add weights to data frame\nfisheries_df$wgt = (D/PS + (1-D)/(1-PS))\n\n# run WLS regression\nreg_wls &lt;- lm(coll_share ~ itq + met1 + met2 + met3 + met4 + met5 + ind_sr + comm_val,\n               data = fisheries_df, weights = wgt)\n\n## Estimate ATE\n\n# Extracting the coefficients table\nsummary_reg &lt;- summary(reg_wls)\nsummary_reg$coefficients %&gt;% \n  kbl(caption = \"WLS estimates\") %&gt;%  # Generate table\n  kable_classic(full_width = FALSE)\n\n\n\nWLS estimates\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n0.3748451\n0.0030280\n123.79136\n0\n\n\nitq\n-0.0766783\n0.0009902\n-77.43563\n0\n\n\nmet1\n-0.1119518\n0.0019244\n-58.17396\n0\n\n\nmet2\n-0.1285996\n0.0022096\n-58.20071\n0\n\n\nmet3\n-0.0968933\n0.0018096\n-53.54421\n0\n\n\nmet4\n-0.0634837\n0.0022391\n-28.35257\n0\n\n\nmet5\n-0.0323470\n0.0019230\n-16.82119\n0\n\n\nind_sr\n-0.0014749\n0.0000412\n-35.80433\n0\n\n\ncomm_val\n0.0003786\n0.0000112\n33.94403\n0\n\n\n\n\n\n\n\nUsing the WLS estimator, we estimate the average effect of an ITQ on a fishery to be a 7.67 percentage-point decrease in the share of years between 1990 and 2012 where the fishery experienced collapse, with a standard error of 0.099 percentage-points. The very low p-value means we reject the null hypothesis that the average effect of an ITQ is zero at an alpha level of &lt;0.001. Our estimated effect size, as calculated here, applies to all fisheries because we did not remove any fisheries from our sample, like we did when estimating effect size based on matching."
  },
  {
    "objectID": "blog/2024-3-11-post/index.html#conclusion",
    "href": "blog/2024-3-11-post/index.html#conclusion",
    "title": "Using propensity scores, matching, and the Weighted Least Squares (WLS) estimator to analyze the impact of catch shares policy",
    "section": "Conclusion",
    "text": "Conclusion\nOur comparison of pre-treatment ecosystem characteristics showed that fisheries regulated with an ITQ between 1990 and 2012 had significant differences in Species Richness Index and commercial value compared to ones not regulated by an ITQ. For this reason, the treatment ignorability seemed like it would be a bad assumption to make, so we estimated propensity scores in order to calculate ATT using Nearest Neighbor Matching and ATE using the WLS estimator.\nUsing the matched data, we estimated the ATT to be a 7.13 percentage-point decrease in the share of years between 1990 and 2012 where the fishery experienced collapse. Then, using the WLS estimator, we estimated the ATE to be a 7.67 percentage-point decrease in the share of years between 1990 and 2012 where the fishery experienced collapse, with a standard error of 0.099 percentage-points.\nOverall, our most useful finding here is the very low standard error when estimating ATE with the WLS estimator, indicating that we are 95% confident that the true ATE is between a 7.57 and 7.77 percentage-point decrease in share of years with a fishery collapse. In addition, the very low p-value corresponding to the low standard error means we reject the null hypothesis that the average effect of an ITQ is zero at an alpha level of &lt;0.001."
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#question",
    "href": "blog/2024-3-6-post/index.html#question",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Question",
    "text": "Question\nWhat was the average treatment effect (ATE) of the 1998 Progresa cash-transfer program on the value of animals owned by a household?"
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#background",
    "href": "blog/2024-3-6-post/index.html#background",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Background",
    "text": "Background\nAccording to the World Health Organization, cash-transfer programs are a form of social assistance assisting beneficiaries who are vulnerable to impoverishment without support. These programs assist beneficiaries through providing re-occurring cash payments, which can either be provided unconditionally or conditional to certain requirements (e.g., periodic health visits). Through boosting household income, the goal of cash-transfer programs is usually to improve the food security of families and provide them the resources to get medical care and prioritize childhood education."
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#data",
    "href": "blog/2024-3-6-post/index.html#data",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Data",
    "text": "Data\nOur data comes from a 2012 research paper published in the American Economic Journal, which looks at the Progresa cash-transfer program, which was implemented in rural Mexico villages in 1998. Eligible households that were randomly selected to be part of the program were provided bi-monthly cash-transfers of up to 550 pesos per month. These cash-transfers were conditional on children attending school, family members obtaining preventive medical care, and attending health-related education talks. In total, over 17,000 households were part of the Progresa program.\nThe outcome and treatment variables are:\n\nvani = value of animals owned by household (in 1997 USD)\ntreatment = dummy variable indicating whether an individual was part of the cash-transfer program (equal to 1 if the individual was part of the program)\n\nThere are 55 control variables, including:\n\ndirtfloor97 = dummy variable indicating whether a household had a dirt floor in 1997\nelectricity97 = dummy variable indicating whether a household had electricity in 1997\nhomeown97 = dummy variable indicating whether a household owned a house in 1997\nfemale_hh = dummy variable indicating whether a household has a female head of household\nage_hh = head of household age\neduc_hh = head of household years of education"
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#setup",
    "href": "blog/2024-3-6-post/index.html#setup",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Setup",
    "text": "Setup\n\n\nCode\n# Import packages\nlibrary(tidyverse)\nlibrary(plm)\nlibrary(lmtest)\nlibrary(estimatr)\nlibrary(Hmisc)\nlibrary(RItools)\nlibrary(MatchIt)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\n\n\nCode\n## Load the datasets\nprogresa_pre_1997 &lt;- read_csv(here::here(\"data\", \"2024-3-6-post-data\", \"progresa_pre_1997.csv\"))\nprogresa_post_1999 &lt;- read_csv(here::here(\"data\", \"2024-3-6-post-data\", \"progresa_post_1999.csv\"))\n\n## Append post to pre dataset \nprogresa &lt;- rbind(progresa_pre_1997, progresa_post_1999)\n\n# Remove all families who were treated/controls in the program, but did not get measured in the second year\nprogresa &lt;- progresa %&gt;%\n  group_by(hhid) %&gt;% filter(n() == 2) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#comparison-of-pre-treatment-characteristics-in-the-treatment-and-control-groups",
    "href": "blog/2024-3-6-post/index.html#comparison-of-pre-treatment-characteristics-in-the-treatment-and-control-groups",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Comparison of pre-treatment characteristics in the treatment and control groups",
    "text": "Comparison of pre-treatment characteristics in the treatment and control groups\n\nDirt floor in 1997 (dummy variable)\n\n\nCode\n# Subset data for treatment and control groups\ntreatment_group &lt;- progresa[progresa$treatment == 1, ]\ncontrol_group &lt;- progresa[progresa$treatment == 0, ]\n\n# Compare proportion of units that had dirt floor in 1997 (binary variable) between treatment and control group\nprop.test(x = c(sum(treatment_group$dirtfloor97, na.rm = TRUE), sum(control_group$dirtfloor97, na.rm = TRUE)),\n          n &lt;- c(length(treatment_group$dirtfloor97), length(control_group$dirtfloor97)))\n\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  c(sum(treatment_group$dirtfloor97, na.rm = TRUE), sum(control_group$dirtfloor97, na.rm = TRUE)) out of n &lt;- c(length(treatment_group$dirtfloor97), length(control_group$dirtfloor97))\nX-squared = 99.041, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.04486458 0.06704500\nsample estimates:\n   prop 1    prop 2 \n0.6394000 0.5834452 \n\n\n\n\nElectricity in 1997 (dummy variable)\n\n\nCode\n# Compare proportion of units that had electricity in 1997 (binary variable) between treatment and control group\nprop.test(x = c(sum(treatment_group$electricity97, na.rm = TRUE), sum(control_group$electricity97, na.rm = TRUE)),\n          n &lt;- c(length(treatment_group$electricity97), length(control_group$electricity97)))\n\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  c(sum(treatment_group$electricity97, na.rm = TRUE), sum(control_group$electricity97, na.rm = TRUE)) out of n &lt;- c(length(treatment_group$electricity97), length(control_group$electricity97))\nX-squared = 147.97, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.08027241 -0.05800589\nsample estimates:\n   prop 1    prop 2 \n0.5583031 0.6274422 \n\n\n\n\nOwned home in 1997 (dummy variable)\n\n\nCode\n# Compare proportion of units that owned home in 1997 (binary variable) between treatment and control group\nprop.test(x = c(sum(treatment_group$homeown97, na.rm = TRUE), sum(control_group$homeown97, na.rm = TRUE)),\n          n &lt;- c(length(treatment_group$homeown97), length(control_group$homeown97)))\n\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  c(sum(treatment_group$homeown97, na.rm = TRUE), sum(control_group$homeown97, na.rm = TRUE)) out of n &lt;- c(length(treatment_group$homeown97), length(control_group$homeown97))\nX-squared = 51.805, df = 1, p-value = 6.128e-13\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.02251224 0.03967849\nsample estimates:\n   prop 1    prop 2 \n0.8460096 0.8149142 \n\n\n\n\nFemale head of house (dummy variable)\n\n\nCode\n# Compare proportion of units that had female head of house (binary variable) between treatment and control group\nprop.test(x = c(sum(treatment_group$female_hh, na.rm = TRUE), sum(control_group$female_hh, na.rm = TRUE)),\n          n &lt;- c(length(treatment_group$female_hh), length(control_group$female_hh)))\n\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  c(sum(treatment_group$female_hh, na.rm = TRUE), sum(control_group$female_hh, na.rm = TRUE)) out of n &lt;- c(length(treatment_group$female_hh), length(control_group$female_hh))\nX-squared = 9.0087, df = 1, p-value = 0.002687\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.016058579 -0.003296729\nsample estimates:\n    prop 1     prop 2 \n0.07980780 0.08948546 \n\n\n\n\nHead of house age\n\n\nCode\n# Mean difference t-test for head of house age\nt.test(age_hh ~ treatment, data = progresa)\n\n\n\n    Welch Two Sample t-test\n\ndata:  age_hh by treatment\nt = 12.657, df = 24438, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n 2.008817 2.744967\nsample estimates:\nmean in group 0 mean in group 1 \n       46.70221        44.32532 \n\n\n\n\nHead of house years of education\n\n\nCode\n# Mean difference t-test for head of house years of education\nt.test(educ_hh ~ treatment, data = progresa)\n\n\n\n    Welch Two Sample t-test\n\ndata:  educ_hh by treatment\nt = -1.2186, df = 25414, p-value = 0.223\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.10171053  0.02372436\nsample estimates:\nmean in group 0 mean in group 1 \n       2.658340        2.697333 \n\n\n\n\nFindings\nFor several of the covariates, there are statistically significant differences between the pre-treatment characteristics of the treated and untreated groups. This indicates that there were likely systemic differences between the pre-treatment characteristics of individuals that were part of the cash-transfer program and those that were not, and if this is the case, simply controlling for all covariates is an insufficient method to estimate the ATE, since systemic differences means that there are differences between the groups that extend beyond what we can control for.\nBecause there seem to be systemic differences between the pre-treatment characteristics of the treated and untreated group, we will use more advanced techniques to estimate the ATE. Since we are working with panel data, our options for advanced techniques include the FD, FE, or DiD estimators."
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#estimating-ate-with-the-first-difference-fd-estimator",
    "href": "blog/2024-3-6-post/index.html#estimating-ate-with-the-first-difference-fd-estimator",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Estimating ATE with the First-Difference (FD) estimator",
    "text": "Estimating ATE with the First-Difference (FD) estimator\nBecause a FD model controls for the differences in the explanatory variables between two time periods, the estimator is effective at removing bias from omitted variables that result from differences between time periods. If we think that the potential ommited variables (i.e., a variable that is influencing our outcome variable but is not included as a covariate) that are most important are likely to vary over different time periods, then using the FD estimator is the best approach for estimating ATE. For example, if the head of house having to deal with a family emergency was by far the most influential omitted variable, the FD estimator would likely be the best approach for estimating ATE, since having to deal with a family emergency is something that would likely vary over different time periods.\n\n\nCode\n# i. Sort the panel data in the order in which you want to take differences, i.e. by household and time.\nprogresa_sorted &lt;- progresa %&gt;% \n  arrange(hhid, year) %&gt;%\n  group_by(hhid) %&gt;%\n  \n  # ii. Calculate the first difference using the lag function from the dplyr package.\n  mutate(vani_fd = vani - dplyr::lag(vani)) \n\n# iii. Estimate manual first-difference regression (Estimate the regression using the newly created variables.)\nfd_manual &lt;- lm(vani_fd ~ treatment, data = progresa_sorted)\n\n# Extracting the coefficients table\nsummary_reg &lt;- summary(fd_manual)\nsummary_reg$coefficients %&gt;% \n  kbl(caption = \"FD estimator\") %&gt;%  # Generate table\n  kable_classic(full_width = FALSE)\n\n\n\nFD estimator\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n-1156.752\n64.4938\n-17.935859\n0.0000000\n\n\ntreatment\n287.905\n85.6020\n3.363297\n0.0007723\n\n\n\n\n\n\n\nOur FD regression tells us that program participants experienced a change in the value of their animal holdings that was, on average, 287.90 dollars greater than the change experienced by non-participants from 1997 to 1999. Our standard error is 85.60 dollars, and our low p-value means we reject the null hypothesis that the difference is zero at an alpha level of 0.01."
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#estimating-ate-with-the-fixed-effects-fe-estimator",
    "href": "blog/2024-3-6-post/index.html#estimating-ate-with-the-fixed-effects-fe-estimator",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Estimating ATE with the Fixed-Effects (FE) estimator",
    "text": "Estimating ATE with the Fixed-Effects (FE) estimator\nA FE model directly controls for omitted variables that do no change over time, so the estimator is effective at removing bias that comes from time-invariant characteristics. If we think that the potential ommited variables (i.e., a variable that is influencing our outcome variable but is not included as a covariate) that are most important are likely stay constant over different time periods, then using the FE estimator is the best approach for estimating ATE. For example, if the head of house being an only child was by far the most influential omitted variable, the FE estimator would likely be the best approach for estimating ATE, since being an only child as an adult is unlikely to be something that would change over time periods.\n\n\nCode\n# ESTIMATE THE BASIC 'WITHIN' FIXED EFFECTS REGRESSION\n# NOTE \"plm\" ONLY PRODUCES CLUSTER-ROBUST STANDARD ERRORS\nwithin_reg &lt;- plm(vani ~ treatment, index = c(\"state\", \"year\"), model = c(\"within\"), effect = c(\"twoways\"), data = progresa)\n\n# Extracting the coefficients table\nsummary_reg &lt;- summary(within_reg)\nsummary_reg$coefficients %&gt;% \n  kbl(caption = \"FE estimator\") %&gt;%  # Generate table\n  kable_classic(full_width = FALSE)\n\n\n\nFE estimator\n\n\n\nEstimate\nStd. Error\nt-value\nPr(&gt;|t|)\n\n\n\n\ntreatment\n-234.0142\n56.65699\n-4.130368\n3.63e-05\n\n\n\n\n\n\n\nOur FE regression tells us that program participants experienced a change in the value of their animal holdings that was, on average, 234.01 dollars less than the change experienced by non-participants within each State from 1997 to 1999. Our cluster-standard error is 56.66 dollars, and our low p-value means we reject the null hypothesis that the difference is zero at an alpha level of &lt;0.01. The standard error being cluster-robust means that it accounts for the fact that observations in the same State as one another will have results that are not entirely independent of one another."
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#estimating-ate-with-the-difference-in-difference-did-estimator",
    "href": "blog/2024-3-6-post/index.html#estimating-ate-with-the-difference-in-difference-did-estimator",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Estimating ATE with the Difference-in-Difference (DiD) estimator",
    "text": "Estimating ATE with the Difference-in-Difference (DiD) estimator\nIf we think that our omitted variables are likely to be a mix of variables that stay constant and change across time periods (and treatment occurs only at a single point in time), we are best off using the DiD estimator, which calculates ATE as the difference in the mean outcome variable in the treated group before and after the time of treatment minus the difference in the mean outcome variable in the untreated group before and after the time of treatment.\n\n\nCode\n# Create the dummy variables\nprogresa$treatment_dummy &lt;- ifelse(progresa$treatment == 1, 1, 0)\nprogresa$post_treatment_time_dummy &lt;- ifelse(progresa$year == 1999, 1, 0)\nprogresa$interaction_dummy &lt;- progresa$treatment_dummy * progresa$post_treatment_time_dummy\n\n# OLS regression\nols_reg &lt;- lm(vani ~ treatment_dummy + post_treatment_time_dummy + interaction_dummy, data = progresa)\n\n# Present Regressions in Table\nsummary_reg &lt;- summary(ols_reg)\nsummary_reg$coefficients %&gt;% \n  kbl(caption = \"DiD estimator\") %&gt;%  # Generate table\n  kable_classic(full_width = FALSE)\n\n\n\nDiD estimator\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n2848.2175\n60.61455\n46.989010\n0.0000000\n\n\ntreatment_dummy\n-237.6927\n80.45311\n-2.954425\n0.0031352\n\n\npost_treatment_time_dummy\n-1156.7517\n85.72191\n-13.494235\n0.0000000\n\n\ninteraction_dummy\n287.9050\n113.77788\n2.530413\n0.0113985\n\n\n\n\n\n\n\nFrom our regression, we estimate the average effect of the cash transfer program on value of animal holdings to be about 287.91 USD (where program participants had a higher average value of animal holdings at the end of the program), with a standard error of about 113.78 USD. To interpret this result as the ATE, we have to assume that the control group (units that did not participate in program) provides a valid counterfactual for what would have happened to units in our treatment group (program participants) had they not participated in the program. Furthermore, our p-value of 0.011 tells us that, at an alpha level of 0.05, we reject the null hypothesis that there was no average effect of the cash transfer program on value of animal holdings.\nThe coefficient on our treatment dummy variable tells us that we estimate the mean difference in the outcome variable (value of animal holdings) between the treatment group (program participants) and the control group (non-participants) before the program started to have been 237.69 USD (where program participants had a lower average value of animal holdings than non-participants prior to the start of the program), with a standard error of 80.45 USD. Our p-value of &lt;0.01 tells us that, at an alpha level of 0.01, we reject the null hypothesis that there was a mean difference of zero.\nThe coefficient on our post treatment time dummy variable tells us that we estimate the mean change in the outcome variable (value of animal holdings) between the beginning and end of the program for the control group (non-participants in program) to be 1,156.75 USD (where non-participants had a lower average value of animal holdings when the program ended than when it started), with a standard error of 85.72 USD. Our p-value of 0.003 tells us that, at an alpha level of 0.01, we reject the null hypothesis that there was a mean change of zero."
  },
  {
    "objectID": "blog/2024-3-6-post/index.html#conclusion",
    "href": "blog/2024-3-6-post/index.html#conclusion",
    "title": "Using the First-Difference (FD), Fixed-Effects (FE), and Difference-in-Difference (DiD) estimators to analyze the impact of a cash-transfer program",
    "section": "Conclusion",
    "text": "Conclusion\nOverall, the cash-transfer program appears to have been quite successful at boosting the value of animals owned by a household. In this cash-transfer program, all treatment occurred at the same time and we expect our omitted variables to be a mix of variable that change and stay constant across time periods, so the DiD estimator is likely the best method for estimating ATE in our situation. Using the DiD estimator, we estimated the average effect of the cash transfer program on value of animal holdings to be about 287.91 USD (where program participants had a higher average value of animal holdings at the end of the program), with a standard error of about 113.78 USD. For this to be interpreted as the ATE, we have to assume that the control group (units that did not participate in program) provides a valid counterfactual for what would have happened to units in our treatment group (program participants) had they not participated in the program."
  }
]